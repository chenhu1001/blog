{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"cc6d477bb6833926869ecc7f5690c284da46f791","modified":1525869766545},{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1525869644128},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1525869644128},{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1525869644128},{"_id":"themes/landscape/_config.yml","hash":"79ac6b9ed6a4de5a21ea53fc3f5a3de92e2475ff","modified":1525869644129},{"_id":"themes/landscape/README.md","hash":"37fae88639ef60d63bd0de22314d7cc4c5d94b07","modified":1525869644129},{"_id":"themes/landscape/package.json","hash":"544f21a0b2c7034998b36ae94dba6e3e0f39f228","modified":1525869644137},{"_id":"source/_posts/ARC下内存泄露总结.md","hash":"74bcc198a6409b04941bd5a532bf3862e969b9fb","modified":1525695785000},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1525869778070},{"_id":"source/_posts/Github-Hexo搭建免费个人博客.md","hash":"5902a9e2bd5d9759182eb4fd80f7bc2a70884946","modified":1525695785000},{"_id":"source/_posts/Realm，一个跨平台、高性能的数据库.md","hash":"7622824ede8a2421c2ec9e0a74a7b42b8c31c4a2","modified":1525695785000},{"_id":"source/_posts/iOS判断一个库是否包含bitcode.md","hash":"c14864c526bcb5e64a7de3210e4f4936c455c183","modified":1525695785000},{"_id":"source/_posts/iOS播放动态gif图片.md","hash":"f8c3f1ba3d054a78e43aa2c04d6e856a8710aece","modified":1525695785000},{"_id":"source/_posts/iOS新的依赖管理工具：Carthage.md","hash":"1600b54a172efb359d842392bde1e322efb50cf3","modified":1525695785000},{"_id":"source/_posts/iOS直播技术分享-直播播放器（六）.md","hash":"0c73d8a09d57331f036cd964be27f2cd11e40b92","modified":1525695785000},{"_id":"source/_posts/iOS直播技术分享-延迟优化（五）.md","hash":"09c33feb2fe82b06913392b62fb82bf5022dc254","modified":1525695785000},{"_id":"source/_posts/iOS直播技术分享-音频编码（二）.md","hash":"3af3aae993d64224ef72b087f611d4c99f3895d9","modified":1525695785000},{"_id":"source/_posts/iOS直播技术分享-音视频采集（一）.md","hash":"41d100d44305749f6849c011421dc9cc47f9b821","modified":1525695785000},{"_id":"source/_posts/macOS下如何编译FFmpeg-for-macOS-APP.md","hash":"748f481dc624de881398f07189b1e506ca543b7c","modified":1525695785000},{"_id":"source/_posts/iOS直播技术分享-视频编码（三）.md","hash":"6cb422693dbf9c68f60e93aa14426e8c8bfa7791","modified":1525695785000},{"_id":"themes/landscape/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1525869644129},{"_id":"source/_posts/链式编程思想理解.md","hash":"e2117564713d69fc1c18048f83314de47b396cbe","modified":1525695785000},{"_id":"themes/landscape/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1525869644130},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1525869644129},{"_id":"source/_posts/函数式响应式编程（FRP）的基本理解.md","hash":"aaee73bc02997eff82f84012decdb74d634e1e00","modified":1525695785000},{"_id":"themes/landscape/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1525869644130},{"_id":"themes/landscape/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1525869644130},{"_id":"themes/landscape/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1525869644130},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1525869644130},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1525869644130},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1525869644131},{"_id":"themes/landscape/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1525869644130},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1525869644131},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1525869644135},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1525869644131},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1525869644136},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1525869644135},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1525869644136},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1525869644136},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1525869644136},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1525869644137},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1525869644137},{"_id":"source/_posts/iOS直播技术分享-推流和传输（四）.md","hash":"7bbe6e1135aabbee23f3afc924a50170342bb021","modified":1525695785000},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"950ddd91db8718153b329b96dc14439ab8463ba5","modified":1525869644131},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1525869644131},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"d0d753d39038284d52b10e5075979cc97db9cd20","modified":1525869644131},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1525869644131},{"_id":"themes/landscape/layout/_partial/gauges-analytics.ejs","hash":"aad6312ac197d6c5aaf2104ac863d7eba46b772a","modified":1525869644132},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1525869644132},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"5abf77aec957d9445fc71a8310252f0013c84578","modified":1525869644132},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"7e749050be126eadbc42decfbea75124ae430413","modified":1525869644132},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1525869644133},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1525869644134},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1525869644134},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1525869644134},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1525869644134},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1525869644135},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1525869644135},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1525869644138},{"_id":"themes/landscape/source/css/_variables.styl","hash":"628e307579ea46b5928424313993f17b8d729e92","modified":1525869644141},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1525869644148},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1525869644148},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1525869644149},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1525869644149},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1525869644150},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1525869644150},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1525869644150},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1525869644152},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1525869644132},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1525869644154},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1525869644133},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1525869644133},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1525869644153},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1525869644133},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1525869644153},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1525869644133},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1525869644134},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1525869644138},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1525869644138},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1525869644138},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1525869644139},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1525869644139},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1525869644139},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1525869644139},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1525869644140},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1525869644140},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1525869644140},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1525869644140},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1525869644141},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1525869644133},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1525869644145},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1525869644150},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1525869644151},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1525869644151},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1525869644151},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1525869644151},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1525869644152},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1525869644142},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1525869644142},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1525869644145},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1525869644144},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1525869644147},{"_id":"public/2017/08/11/macOS下如何编译FFmpeg-for-macOS-APP/index.html","hash":"c361550dfaa13908d8550083079be5ac3c76cfb0","modified":1525870110529},{"_id":"public/2016/10/25/iOS直播技术分享-直播播放器（六）/index.html","hash":"164ac0a0352da35c90b8e32f93180e850750861d","modified":1525870110529},{"_id":"public/2016/10/25/iOS直播技术分享-延迟优化（五）/index.html","hash":"5ee002f12c95efe3cfffb3e8f33fde77c63d1299","modified":1525870110530},{"_id":"public/2016/10/25/iOS直播技术分享-推流和传输（四）/index.html","hash":"1f9424e977509051443c397beeabcfc11fa64daf","modified":1525870110530},{"_id":"public/2016/07/01/iOS判断一个库是否包含bitcode/index.html","hash":"6165b598a007746501e4d9896923100b3c054066","modified":1525870110530},{"_id":"public/2016/06/21/iOS新的依赖管理工具：Carthage/index.html","hash":"59bf753e5542c9c2830d13206a489440eaac6191","modified":1525870110530},{"_id":"public/2016/06/20/iOS播放动态gif图片/index.html","hash":"8eae66b4d4ae739216460400864c69e898a0673e","modified":1525870110530},{"_id":"public/2016/06/20/链式编程思想理解/index.html","hash":"55c366f637f0d4fc40bbe03c974290a5581be1aa","modified":1525870110530},{"_id":"public/archives/index.html","hash":"b322181d288329e65906e16f74d3e66c9e385455","modified":1525870110530},{"_id":"public/archives/page/2/index.html","hash":"d2eedbea8a6df8963ba54a93495b3f56de40e778","modified":1525870110530},{"_id":"public/archives/2016/index.html","hash":"aeb80daf5b6420e73235e41a47c13ed2994063b8","modified":1525870110530},{"_id":"public/archives/2016/page/2/index.html","hash":"0f7550aa845c6eb74cc221abfa40a6fda212f653","modified":1525870110530},{"_id":"public/archives/2016/06/index.html","hash":"12bf865a5223da75b3a24ccb60246d1a3d23ce0d","modified":1525870110530},{"_id":"public/archives/2016/07/index.html","hash":"490ff7621c0278a791f50289ea3c89529290bf12","modified":1525870110530},{"_id":"public/archives/2016/10/index.html","hash":"46fa9b144a131c623c2844bbd6583ea12b74316c","modified":1525870110530},{"_id":"public/archives/2017/index.html","hash":"221d70e8b469441308f32cf760ebe47e4d2f8d02","modified":1525870110530},{"_id":"public/archives/2017/08/index.html","hash":"8307ef2dac8068ff3b4793651fe31363db2b3f36","modified":1525870110531},{"_id":"public/page/2/index.html","hash":"9f55af290a8e8837ec4e952377cbbe75b695a3ce","modified":1525870110531},{"_id":"public/categories/iOS/index.html","hash":"cd6a531c065fce534a76e50d0b7513711d047714","modified":1525870110531},{"_id":"public/categories/随笔/index.html","hash":"d14388f75213404c70d498e22bccba8b376918d0","modified":1525870110531},{"_id":"public/categories/音视频/index.html","hash":"0ef0c1b46d5503904d1f63beea13e0d23655d68b","modified":1525870110531},{"_id":"public/tags/iOS/index.html","hash":"cc6f5c30a4adecf57e79ccb87796df7c386fcd48","modified":1525870110531},{"_id":"public/tags/随笔/index.html","hash":"bd112124791044ecb2f4c7f9d8a419a5fdb73af8","modified":1525870110531},{"_id":"public/tags/音视频/index.html","hash":"8ad46a29d581ad16f70f35fb78bb18edc6a542b6","modified":1525870110531},{"_id":"public/2016/07/11/iOS直播技术分享-视频编码（三）/index.html","hash":"59ce666a045267506a1129523f776d0bdb41b43e","modified":1525870110531},{"_id":"public/2016/07/11/iOS直播技术分享-音频编码（二）/index.html","hash":"2937aebbecd14ea8fc31723a79d5e0bacdcc0441","modified":1525870110531},{"_id":"public/2016/07/02/iOS直播技术分享-音视频采集（一）/index.html","hash":"bcf8192fdee0b10ca2d2a03c3a892065aabfd056","modified":1525870110531},{"_id":"public/2016/06/21/函数式响应式编程（FRP）的基本理解/index.html","hash":"6120e8ab8883d72d255047efebac2c578ca427db","modified":1525870110531},{"_id":"public/2016/06/20/Realm，一个跨平台、高性能的数据库/index.html","hash":"d2ddaf43946407d204e3142a32e9eed49a669f49","modified":1525870110531},{"_id":"public/2016/06/20/ARC下内存泄露总结/index.html","hash":"18532e925191ab8d41aa177e62c320faa0528faa","modified":1525870110531},{"_id":"public/2016/06/10/Github-Hexo搭建免费个人博客/index.html","hash":"3f8ff86283d39add842c5eb4780be182107c0a20","modified":1525870110531},{"_id":"public/index.html","hash":"b6cefd59d07feb10aa90f525e3ed17e38b5ee676","modified":1525870110532},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1525870110534},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1525870110534},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1525870110535},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1525870110535},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1525870110535},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1525870110535},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1525870110535},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1525870110535},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1525870110535},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1525870110535},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1525870110970},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1525870110973},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1525870110973},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1525870110973},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1525870110974},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1525870110974},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1525870110974},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1525870110974},{"_id":"public/css/style.css","hash":"5f8dadd37d0052c557061018fe6f568f64fced9b","modified":1525870110974},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1525870110974},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1525870110974},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1525870110977},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1525870110977}],"Category":[{"name":"iOS","_id":"cjgz3hh0x0002n5xfyvsmjkgu"},{"name":"随笔","_id":"cjgz3hh18000en5xf4x0q9i7y"},{"name":"音视频","_id":"cjgz3hh1d000mn5xf7o2ic4u8"}],"Data":[],"Page":[],"Post":[{"title":"ARC下内存泄露总结","date":"2016-06-20T06:04:08.000Z","_content":"## 1、Block的循环引用\n&emsp;&emsp;在iOS4.2时，Apple推出ARC内存管理机制。这是一种编译期的内存管理方式，在编译期间，编译器会判断对象的引用情况，并在合适的位置加上retain和release，使得对象的内存被合理的管理。所以，从本质上说ARC和MRC在本质上是一样的，都是通过引用计数的内存管理方式。  \n&emsp;&emsp;使用ARC虽然可以简化内存管理，但是ARC并不是万能的，有些情况程序为了能够正常运行，会隐式地持有或者复制对象，如果不加以注意，便会造成内存泄露。在ARC下，当Block获取到外部变量时，由于编译器无法预测获取到的变量何时会被突然释放，为了保证程序能够正确运行，让Block持有获取到的变量。  \n<!--more-->\n&emsp;&emsp;下面主要通过一个例子来介绍在ARC情况下使用Block不当会导致内存泄露的问题。示例代码来源于《Effective Objective-C 2.0》（编写高质量iOS与OS X代码的52个有效方法）。  \n（1）EOCNetworkFetcher.h\n\n```\ntypedef void (^EOCNetworkFetcherCompletionHandler)(NSData *data);\n\n@interface EOCNetworkFetcher : NSObject\n\n@property (nonatomic, strong, readonly) NSURL *url;\n\n- (id)initWithURL:(NSURL *)url;\n\n- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion;\n\n@end\n```\n\n（2）EOCNetworkFetcher.m\n\n```\n@interface EOCNetworkFetcher ()\n\n@property (nonatomic, strong, readwrite) NSURL *url;\n@property (nonatomic, copy) EOCNetworkFetcherCompletionHandler completionHandler;\n@property (nonatomic, strong) NSData *downloadData;\n\n@end\n\n@implementation EOCNetworkFetcher\n\n- (id)initWithURL:(NSURL *)url {\n    if(self = [super init]) {\n        _url = url;\n    }\n    return self;\n}\n\n- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion {\n    self.completionHandler = completion;\n    //开始网络请求\n    dispatch_async(dispatch_get_global_queue(0, 0), ^{\n        _downloadData = [[NSData alloc] initWithContentsOfURL:_url];\n        dispatch_async(dispatch_get_main_queue(), ^{\n             //网络请求完成\n            [self p_requestCompleted];\n        });\n    });\n}\n\n- (void)p_requestCompleted {\n    if(_completionHandler) {\n        _completionHandler(_downloadData);\n    }\n}\n\n@end\n```\n\n（3）EOCClass.m\n\n```\n@implementation EOCClass {\n    EOCNetworkFetcher *_networkFetcher;\n    NSData *_fetchedData;\n}\n\n- (void)downloadData {\n    NSURL *url = [NSURL URLWithString:@\"http://www.baidu.com\"];\n    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];\n    [_networkFetcher startWithCompletionHandler:^(NSData *data) {\n        _fetchedData = data;\n    }];\n}\n\n@end\n```\n\n代码分析：\n\n> * completion handler块因为要设置_fetchedData实例变量的值，所以它必须捕获self变量，也就是说handler块保留了EOCClass实例。\n\n> * 而EOCClass实例通过strong实例变量保留了EOCNetworkFetcher，最后EOCNetworkFetcher实例对象又保留了handler块。\n\n引用关系如下下图所示\n![循环引用示意图](http://7xk4rv.com1.z0.glb.clouddn.com/ARC%E4%B8%8B%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E6%80%BB%E7%BB%93_1.png)\n  \n要想打破保留环，解决办法：\n\n> * 方法一：使用完EOCNetworkFetcher对象之后就没有必要在保留该对象了，在block里面将对象释放即可打破保留环。\n\n```\n- (void)downloadData {\n    NSURL *url = [NSURL URLWithString:@\"http://www.baidu.com\"];\n    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];\n    [_networkFetcher startWithCompletionHandler:^(NSData *data) {\n        _fetchedData = data;\n        _networkFetcher = nil;   //加上此行，此处是为了打破循环引用\n    }];\n}\n```\n\n> * 方法二：上面的方法需要调用者自己来将对象手动设置为nil，对于使用者来说会造成很多困恼，如果忘记将对象设置为nil就会造成循环引用。在运行完completion handler之后将block释放即可。\n\n```\n- (void)p_requestCompleted {\n    if(_completionHandler) {\n        _completionHandler(_downloadData);\n    }\n    self.completionHandler = nil;   //加上此行，此处是为了打破循环引用\n}\n```\n\n> * 方法三：将引用的一方变成weak，从而避免循环引用。\n\n```\n- (void)downloadData {\n   __weak __typeof(self) weakSelf = self;\n   NSURL *url = [NSURL URLWithString:@\"http://www.baidu.com\"];\n   _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];\n   [_networkFetcher startWithCompletionHandler:^(NSData *data) {\n        //如果想防止weakSelf被释放，可以再次强引用\n        __typeof(&*weakSelf) strongSelf = weakSelf;\n        if (strongSelf) {\n            strongSelf.fetchedData = data;\n        }\n   }];\n}\n```\n\n## 2、NSTimer\n在使用NSTimer addTarget时，为了防止target被释放而导致的程序异常，timer会持有target，所以这也是一处内存泄露的隐患。\n\n```\n/**\n * self持有timer，timer在初始化时持有self，造成循环引用。\n * 解决的方法就是使用invalidate方法销掉timer。\n */\n@interface SomeViewController : UIViewController\n@property (nonatomic, strong) NSTimer *timer;\n@end\n@implementation SomeViewController\n\n- (void)someMethod\n{\n    timer = [NSTimer scheduledTimerWithTimeInterval:0.1  \n                                             target:self  \n                                           selector:@selector(handleTimer:)  \n                                           userInfo:nil  \n                                            repeats:YES];  \n}\n\n@end\n```\n\n## 3、performSelector 系列\nperformSelector顾名思义即在运行时执行一个selector，最简单的方法如下\n\n```\n- (id)performSelector:(SEL)selector;\n```\n\n这种调用selector的方法和直接调用selector基本等效，执行效果相同\n\n```\n[object methodName];\n[object performSelector:@selector(methodName)];\n```\n\n但performSelector相比直接调用更加灵活\n\n```\nSEL selector;\nif (/* some condition */) {\n    selector = @selector(newObject);\n} else if (/* some other condition */) {\n    selector = @selector(copy);\n} else {\n    selector = @selector(someProperty);\n}\nid ret = [object performSelector:selector];\n```\n\n这段代码就相当于在动态之上再动态绑定。在ARC下编译这段代码，编译器会发出警告\n\n```\nwarning: performSelector may cause a leak because its selector is unknow [-Warc-performSelector-leak]\n```\n\n正是由于动态，编译器不知道即将调用的selector是什么，不了解方法签名和返回值，甚至是否有返回值都不懂，所以编译器无法用ARC的内存管理规则来判断返回值是否应该释放。因此，ARC采用了比较谨慎的做法，不添加释放操作，即在方法返回对象时就可能将其持有，从而可能导致内存泄露。\n\n以本段代码为例，前两种情况（newObject, copy）都需要再次释放，而第三种情况不需要。这种泄露隐藏得如此之深，以至于使用static analyzer都很难检测到。如果把代码的最后一行改成\n\n```\n[object performSelector:selector];\n```\n\n不创建一个返回值变量测试分析，简直难以想象这里居然会出现内存问题。所以如果你使用的selector有返回值，一定要处理掉。\n\n## 4、循环引用\nA有个属性B，B有个属性A，如果都是strong修饰的话，两个对象都无法释放。   \n这种问题常发生于把delegate声明为strong属性了。 \n\n```\n@interface SampleViewController\n@property (nonatomic, strong) SampleClass *sampleClass;\n@end\n@interface SampleClass\n@property (nonatomic, strong) SampleViewController *delegate;\n@end\n```\n\n## 5、循环未结束\n如果某个ViewController中有无限循环，也会导致即使ViewController对应的view关掉了，ViewController也不能被释放。   \n这种问题常发生于animation处理。\n\n```\nCATransition *transition = [CATransition animation];\ntransition.duration = 0.5;\ntansition.repeatCount = HUGE_VALL;\n[self.view.layer addAnimation:transition forKey:\"myAnimation\"];\n```\n\n上例中，animation重复次数设成HUGE_VALL，一个很大的数值，基本上等于无限循环了。 \n解决办法是，在ViewController关掉的时候，停止这个animation。\n\n```\n-(void)viewWillDisappear:(BOOL)animated {\n    [self.view.layer removeAllAnimations];\n}\n```\n\n## 6、非OBJC对象\nARC是自动检测objc对象的，非objc对象就无能为力了，比如C或C++等。  \nC语言使用malloc开辟，free释放。  \nC++使用new开辟，delete释放。  \n但是在ARC下，不会添加非objc对象释放语句，如果没去释放，也会造成内存泄露。\n\nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","source":"_posts/ARC下内存泄露总结.md","raw":"---\ntitle: ARC下内存泄露总结\ndate: 2016-06-20 14:04:08\ncategories: iOS\ntags: [iOS]\n---\n## 1、Block的循环引用\n&emsp;&emsp;在iOS4.2时，Apple推出ARC内存管理机制。这是一种编译期的内存管理方式，在编译期间，编译器会判断对象的引用情况，并在合适的位置加上retain和release，使得对象的内存被合理的管理。所以，从本质上说ARC和MRC在本质上是一样的，都是通过引用计数的内存管理方式。  \n&emsp;&emsp;使用ARC虽然可以简化内存管理，但是ARC并不是万能的，有些情况程序为了能够正常运行，会隐式地持有或者复制对象，如果不加以注意，便会造成内存泄露。在ARC下，当Block获取到外部变量时，由于编译器无法预测获取到的变量何时会被突然释放，为了保证程序能够正确运行，让Block持有获取到的变量。  \n<!--more-->\n&emsp;&emsp;下面主要通过一个例子来介绍在ARC情况下使用Block不当会导致内存泄露的问题。示例代码来源于《Effective Objective-C 2.0》（编写高质量iOS与OS X代码的52个有效方法）。  \n（1）EOCNetworkFetcher.h\n\n```\ntypedef void (^EOCNetworkFetcherCompletionHandler)(NSData *data);\n\n@interface EOCNetworkFetcher : NSObject\n\n@property (nonatomic, strong, readonly) NSURL *url;\n\n- (id)initWithURL:(NSURL *)url;\n\n- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion;\n\n@end\n```\n\n（2）EOCNetworkFetcher.m\n\n```\n@interface EOCNetworkFetcher ()\n\n@property (nonatomic, strong, readwrite) NSURL *url;\n@property (nonatomic, copy) EOCNetworkFetcherCompletionHandler completionHandler;\n@property (nonatomic, strong) NSData *downloadData;\n\n@end\n\n@implementation EOCNetworkFetcher\n\n- (id)initWithURL:(NSURL *)url {\n    if(self = [super init]) {\n        _url = url;\n    }\n    return self;\n}\n\n- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion {\n    self.completionHandler = completion;\n    //开始网络请求\n    dispatch_async(dispatch_get_global_queue(0, 0), ^{\n        _downloadData = [[NSData alloc] initWithContentsOfURL:_url];\n        dispatch_async(dispatch_get_main_queue(), ^{\n             //网络请求完成\n            [self p_requestCompleted];\n        });\n    });\n}\n\n- (void)p_requestCompleted {\n    if(_completionHandler) {\n        _completionHandler(_downloadData);\n    }\n}\n\n@end\n```\n\n（3）EOCClass.m\n\n```\n@implementation EOCClass {\n    EOCNetworkFetcher *_networkFetcher;\n    NSData *_fetchedData;\n}\n\n- (void)downloadData {\n    NSURL *url = [NSURL URLWithString:@\"http://www.baidu.com\"];\n    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];\n    [_networkFetcher startWithCompletionHandler:^(NSData *data) {\n        _fetchedData = data;\n    }];\n}\n\n@end\n```\n\n代码分析：\n\n> * completion handler块因为要设置_fetchedData实例变量的值，所以它必须捕获self变量，也就是说handler块保留了EOCClass实例。\n\n> * 而EOCClass实例通过strong实例变量保留了EOCNetworkFetcher，最后EOCNetworkFetcher实例对象又保留了handler块。\n\n引用关系如下下图所示\n![循环引用示意图](http://7xk4rv.com1.z0.glb.clouddn.com/ARC%E4%B8%8B%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E6%80%BB%E7%BB%93_1.png)\n  \n要想打破保留环，解决办法：\n\n> * 方法一：使用完EOCNetworkFetcher对象之后就没有必要在保留该对象了，在block里面将对象释放即可打破保留环。\n\n```\n- (void)downloadData {\n    NSURL *url = [NSURL URLWithString:@\"http://www.baidu.com\"];\n    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];\n    [_networkFetcher startWithCompletionHandler:^(NSData *data) {\n        _fetchedData = data;\n        _networkFetcher = nil;   //加上此行，此处是为了打破循环引用\n    }];\n}\n```\n\n> * 方法二：上面的方法需要调用者自己来将对象手动设置为nil，对于使用者来说会造成很多困恼，如果忘记将对象设置为nil就会造成循环引用。在运行完completion handler之后将block释放即可。\n\n```\n- (void)p_requestCompleted {\n    if(_completionHandler) {\n        _completionHandler(_downloadData);\n    }\n    self.completionHandler = nil;   //加上此行，此处是为了打破循环引用\n}\n```\n\n> * 方法三：将引用的一方变成weak，从而避免循环引用。\n\n```\n- (void)downloadData {\n   __weak __typeof(self) weakSelf = self;\n   NSURL *url = [NSURL URLWithString:@\"http://www.baidu.com\"];\n   _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];\n   [_networkFetcher startWithCompletionHandler:^(NSData *data) {\n        //如果想防止weakSelf被释放，可以再次强引用\n        __typeof(&*weakSelf) strongSelf = weakSelf;\n        if (strongSelf) {\n            strongSelf.fetchedData = data;\n        }\n   }];\n}\n```\n\n## 2、NSTimer\n在使用NSTimer addTarget时，为了防止target被释放而导致的程序异常，timer会持有target，所以这也是一处内存泄露的隐患。\n\n```\n/**\n * self持有timer，timer在初始化时持有self，造成循环引用。\n * 解决的方法就是使用invalidate方法销掉timer。\n */\n@interface SomeViewController : UIViewController\n@property (nonatomic, strong) NSTimer *timer;\n@end\n@implementation SomeViewController\n\n- (void)someMethod\n{\n    timer = [NSTimer scheduledTimerWithTimeInterval:0.1  \n                                             target:self  \n                                           selector:@selector(handleTimer:)  \n                                           userInfo:nil  \n                                            repeats:YES];  \n}\n\n@end\n```\n\n## 3、performSelector 系列\nperformSelector顾名思义即在运行时执行一个selector，最简单的方法如下\n\n```\n- (id)performSelector:(SEL)selector;\n```\n\n这种调用selector的方法和直接调用selector基本等效，执行效果相同\n\n```\n[object methodName];\n[object performSelector:@selector(methodName)];\n```\n\n但performSelector相比直接调用更加灵活\n\n```\nSEL selector;\nif (/* some condition */) {\n    selector = @selector(newObject);\n} else if (/* some other condition */) {\n    selector = @selector(copy);\n} else {\n    selector = @selector(someProperty);\n}\nid ret = [object performSelector:selector];\n```\n\n这段代码就相当于在动态之上再动态绑定。在ARC下编译这段代码，编译器会发出警告\n\n```\nwarning: performSelector may cause a leak because its selector is unknow [-Warc-performSelector-leak]\n```\n\n正是由于动态，编译器不知道即将调用的selector是什么，不了解方法签名和返回值，甚至是否有返回值都不懂，所以编译器无法用ARC的内存管理规则来判断返回值是否应该释放。因此，ARC采用了比较谨慎的做法，不添加释放操作，即在方法返回对象时就可能将其持有，从而可能导致内存泄露。\n\n以本段代码为例，前两种情况（newObject, copy）都需要再次释放，而第三种情况不需要。这种泄露隐藏得如此之深，以至于使用static analyzer都很难检测到。如果把代码的最后一行改成\n\n```\n[object performSelector:selector];\n```\n\n不创建一个返回值变量测试分析，简直难以想象这里居然会出现内存问题。所以如果你使用的selector有返回值，一定要处理掉。\n\n## 4、循环引用\nA有个属性B，B有个属性A，如果都是strong修饰的话，两个对象都无法释放。   \n这种问题常发生于把delegate声明为strong属性了。 \n\n```\n@interface SampleViewController\n@property (nonatomic, strong) SampleClass *sampleClass;\n@end\n@interface SampleClass\n@property (nonatomic, strong) SampleViewController *delegate;\n@end\n```\n\n## 5、循环未结束\n如果某个ViewController中有无限循环，也会导致即使ViewController对应的view关掉了，ViewController也不能被释放。   \n这种问题常发生于animation处理。\n\n```\nCATransition *transition = [CATransition animation];\ntransition.duration = 0.5;\ntansition.repeatCount = HUGE_VALL;\n[self.view.layer addAnimation:transition forKey:\"myAnimation\"];\n```\n\n上例中，animation重复次数设成HUGE_VALL，一个很大的数值，基本上等于无限循环了。 \n解决办法是，在ViewController关掉的时候，停止这个animation。\n\n```\n-(void)viewWillDisappear:(BOOL)animated {\n    [self.view.layer removeAllAnimations];\n}\n```\n\n## 6、非OBJC对象\nARC是自动检测objc对象的，非objc对象就无能为力了，比如C或C++等。  \nC语言使用malloc开辟，free释放。  \nC++使用new开辟，delete释放。  \n但是在ARC下，不会添加非objc对象释放语句，如果没去释放，也会造成内存泄露。\n\nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","slug":"ARC下内存泄露总结","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh0p0000n5xf15wfhhh1","content":"<h2 id=\"1、Block的循环引用\"><a href=\"#1、Block的循环引用\" class=\"headerlink\" title=\"1、Block的循环引用\"></a>1、Block的循环引用</h2><p>&emsp;&emsp;在iOS4.2时，Apple推出ARC内存管理机制。这是一种编译期的内存管理方式，在编译期间，编译器会判断对象的引用情况，并在合适的位置加上retain和release，使得对象的内存被合理的管理。所以，从本质上说ARC和MRC在本质上是一样的，都是通过引用计数的内存管理方式。<br>&emsp;&emsp;使用ARC虽然可以简化内存管理，但是ARC并不是万能的，有些情况程序为了能够正常运行，会隐式地持有或者复制对象，如果不加以注意，便会造成内存泄露。在ARC下，当Block获取到外部变量时，由于编译器无法预测获取到的变量何时会被突然释放，为了保证程序能够正确运行，让Block持有获取到的变量。<br><a id=\"more\"></a><br>&emsp;&emsp;下面主要通过一个例子来介绍在ARC情况下使用Block不当会导致内存泄露的问题。示例代码来源于《Effective Objective-C 2.0》（编写高质量iOS与OS X代码的52个有效方法）。<br>（1）EOCNetworkFetcher.h</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef void (^EOCNetworkFetcherCompletionHandler)(NSData *data);</span><br><span class=\"line\"></span><br><span class=\"line\">@interface EOCNetworkFetcher : NSObject</span><br><span class=\"line\"></span><br><span class=\"line\">@property (nonatomic, strong, readonly) NSURL *url;</span><br><span class=\"line\"></span><br><span class=\"line\">- (id)initWithURL:(NSURL *)url;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>（2）EOCNetworkFetcher.m</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@interface EOCNetworkFetcher ()</span><br><span class=\"line\"></span><br><span class=\"line\">@property (nonatomic, strong, readwrite) NSURL *url;</span><br><span class=\"line\">@property (nonatomic, copy) EOCNetworkFetcherCompletionHandler completionHandler;</span><br><span class=\"line\">@property (nonatomic, strong) NSData *downloadData;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br><span class=\"line\"></span><br><span class=\"line\">@implementation EOCNetworkFetcher</span><br><span class=\"line\"></span><br><span class=\"line\">- (id)initWithURL:(NSURL *)url &#123;</span><br><span class=\"line\">    if(self = [super init]) &#123;</span><br><span class=\"line\">        _url = url;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return self;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion &#123;</span><br><span class=\"line\">    self.completionHandler = completion;</span><br><span class=\"line\">    //开始网络请求</span><br><span class=\"line\">    dispatch_async(dispatch_get_global_queue(0, 0), ^&#123;</span><br><span class=\"line\">        _downloadData = [[NSData alloc] initWithContentsOfURL:_url];</span><br><span class=\"line\">        dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class=\"line\">             //网络请求完成</span><br><span class=\"line\">            [self p_requestCompleted];</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)p_requestCompleted &#123;</span><br><span class=\"line\">    if(_completionHandler) &#123;</span><br><span class=\"line\">        _completionHandler(_downloadData);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>（3）EOCClass.m</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@implementation EOCClass &#123;</span><br><span class=\"line\">    EOCNetworkFetcher *_networkFetcher;</span><br><span class=\"line\">    NSData *_fetchedData;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)downloadData &#123;</span><br><span class=\"line\">    NSURL *url = [NSURL URLWithString:@&quot;http://www.baidu.com&quot;];</span><br><span class=\"line\">    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];</span><br><span class=\"line\">    [_networkFetcher startWithCompletionHandler:^(NSData *data) &#123;</span><br><span class=\"line\">        _fetchedData = data;</span><br><span class=\"line\">    &#125;];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>代码分析：</p>\n<blockquote>\n<ul>\n<li>completion handler块因为要设置_fetchedData实例变量的值，所以它必须捕获self变量，也就是说handler块保留了EOCClass实例。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>而EOCClass实例通过strong实例变量保留了EOCNetworkFetcher，最后EOCNetworkFetcher实例对象又保留了handler块。</li>\n</ul>\n</blockquote>\n<p>引用关系如下下图所示<br><img src=\"http://7xk4rv.com1.z0.glb.clouddn.com/ARC%E4%B8%8B%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E6%80%BB%E7%BB%93_1.png\" alt=\"循环引用示意图\"></p>\n<p>要想打破保留环，解决办法：</p>\n<blockquote>\n<ul>\n<li>方法一：使用完EOCNetworkFetcher对象之后就没有必要在保留该对象了，在block里面将对象释放即可打破保留环。</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)downloadData &#123;</span><br><span class=\"line\">    NSURL *url = [NSURL URLWithString:@&quot;http://www.baidu.com&quot;];</span><br><span class=\"line\">    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];</span><br><span class=\"line\">    [_networkFetcher startWithCompletionHandler:^(NSData *data) &#123;</span><br><span class=\"line\">        _fetchedData = data;</span><br><span class=\"line\">        _networkFetcher = nil;   //加上此行，此处是为了打破循环引用</span><br><span class=\"line\">    &#125;];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li>方法二：上面的方法需要调用者自己来将对象手动设置为nil，对于使用者来说会造成很多困恼，如果忘记将对象设置为nil就会造成循环引用。在运行完completion handler之后将block释放即可。</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)p_requestCompleted &#123;</span><br><span class=\"line\">    if(_completionHandler) &#123;</span><br><span class=\"line\">        _completionHandler(_downloadData);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    self.completionHandler = nil;   //加上此行，此处是为了打破循环引用</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li>方法三：将引用的一方变成weak，从而避免循环引用。</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)downloadData &#123;</span><br><span class=\"line\">   __weak __typeof(self) weakSelf = self;</span><br><span class=\"line\">   NSURL *url = [NSURL URLWithString:@&quot;http://www.baidu.com&quot;];</span><br><span class=\"line\">   _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];</span><br><span class=\"line\">   [_networkFetcher startWithCompletionHandler:^(NSData *data) &#123;</span><br><span class=\"line\">        //如果想防止weakSelf被释放，可以再次强引用</span><br><span class=\"line\">        __typeof(&amp;*weakSelf) strongSelf = weakSelf;</span><br><span class=\"line\">        if (strongSelf) &#123;</span><br><span class=\"line\">            strongSelf.fetchedData = data;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">   &#125;];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2、NSTimer\"><a href=\"#2、NSTimer\" class=\"headerlink\" title=\"2、NSTimer\"></a>2、NSTimer</h2><p>在使用NSTimer addTarget时，为了防止target被释放而导致的程序异常，timer会持有target，所以这也是一处内存泄露的隐患。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * self持有timer，timer在初始化时持有self，造成循环引用。</span><br><span class=\"line\"> * 解决的方法就是使用invalidate方法销掉timer。</span><br><span class=\"line\"> */</span><br><span class=\"line\">@interface SomeViewController : UIViewController</span><br><span class=\"line\">@property (nonatomic, strong) NSTimer *timer;</span><br><span class=\"line\">@end</span><br><span class=\"line\">@implementation SomeViewController</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)someMethod</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    timer = [NSTimer scheduledTimerWithTimeInterval:0.1  </span><br><span class=\"line\">                                             target:self  </span><br><span class=\"line\">                                           selector:@selector(handleTimer:)  </span><br><span class=\"line\">                                           userInfo:nil  </span><br><span class=\"line\">                                            repeats:YES];  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、performSelector-系列\"><a href=\"#3、performSelector-系列\" class=\"headerlink\" title=\"3、performSelector 系列\"></a>3、performSelector 系列</h2><p>performSelector顾名思义即在运行时执行一个selector，最简单的方法如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (id)performSelector:(SEL)selector;</span><br></pre></td></tr></table></figure>\n<p>这种调用selector的方法和直接调用selector基本等效，执行效果相同</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[object methodName];</span><br><span class=\"line\">[object performSelector:@selector(methodName)];</span><br></pre></td></tr></table></figure>\n<p>但performSelector相比直接调用更加灵活</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SEL selector;</span><br><span class=\"line\">if (/* some condition */) &#123;</span><br><span class=\"line\">    selector = @selector(newObject);</span><br><span class=\"line\">&#125; else if (/* some other condition */) &#123;</span><br><span class=\"line\">    selector = @selector(copy);</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">    selector = @selector(someProperty);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">id ret = [object performSelector:selector];</span><br></pre></td></tr></table></figure>\n<p>这段代码就相当于在动态之上再动态绑定。在ARC下编译这段代码，编译器会发出警告</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">warning: performSelector may cause a leak because its selector is unknow [-Warc-performSelector-leak]</span><br></pre></td></tr></table></figure>\n<p>正是由于动态，编译器不知道即将调用的selector是什么，不了解方法签名和返回值，甚至是否有返回值都不懂，所以编译器无法用ARC的内存管理规则来判断返回值是否应该释放。因此，ARC采用了比较谨慎的做法，不添加释放操作，即在方法返回对象时就可能将其持有，从而可能导致内存泄露。</p>\n<p>以本段代码为例，前两种情况（newObject, copy）都需要再次释放，而第三种情况不需要。这种泄露隐藏得如此之深，以至于使用static analyzer都很难检测到。如果把代码的最后一行改成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[object performSelector:selector];</span><br></pre></td></tr></table></figure>\n<p>不创建一个返回值变量测试分析，简直难以想象这里居然会出现内存问题。所以如果你使用的selector有返回值，一定要处理掉。</p>\n<h2 id=\"4、循环引用\"><a href=\"#4、循环引用\" class=\"headerlink\" title=\"4、循环引用\"></a>4、循环引用</h2><p>A有个属性B，B有个属性A，如果都是strong修饰的话，两个对象都无法释放。<br>这种问题常发生于把delegate声明为strong属性了。 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@interface SampleViewController</span><br><span class=\"line\">@property (nonatomic, strong) SampleClass *sampleClass;</span><br><span class=\"line\">@end</span><br><span class=\"line\">@interface SampleClass</span><br><span class=\"line\">@property (nonatomic, strong) SampleViewController *delegate;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<h2 id=\"5、循环未结束\"><a href=\"#5、循环未结束\" class=\"headerlink\" title=\"5、循环未结束\"></a>5、循环未结束</h2><p>如果某个ViewController中有无限循环，也会导致即使ViewController对应的view关掉了，ViewController也不能被释放。<br>这种问题常发生于animation处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CATransition *transition = [CATransition animation];</span><br><span class=\"line\">transition.duration = 0.5;</span><br><span class=\"line\">tansition.repeatCount = HUGE_VALL;</span><br><span class=\"line\">[self.view.layer addAnimation:transition forKey:&quot;myAnimation&quot;];</span><br></pre></td></tr></table></figure>\n<p>上例中，animation重复次数设成HUGE_VALL，一个很大的数值，基本上等于无限循环了。<br>解决办法是，在ViewController关掉的时候，停止这个animation。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-(void)viewWillDisappear:(BOOL)animated &#123;</span><br><span class=\"line\">    [self.view.layer removeAllAnimations];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"6、非OBJC对象\"><a href=\"#6、非OBJC对象\" class=\"headerlink\" title=\"6、非OBJC对象\"></a>6、非OBJC对象</h2><p>ARC是自动检测objc对象的，非objc对象就无能为力了，比如C或C++等。<br>C语言使用malloc开辟，free释放。<br>C++使用new开辟，delete释放。<br>但是在ARC下，不会添加非objc对象释放语句，如果没去释放，也会造成内存泄露。</p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1、Block的循环引用\"><a href=\"#1、Block的循环引用\" class=\"headerlink\" title=\"1、Block的循环引用\"></a>1、Block的循环引用</h2><p>&emsp;&emsp;在iOS4.2时，Apple推出ARC内存管理机制。这是一种编译期的内存管理方式，在编译期间，编译器会判断对象的引用情况，并在合适的位置加上retain和release，使得对象的内存被合理的管理。所以，从本质上说ARC和MRC在本质上是一样的，都是通过引用计数的内存管理方式。<br>&emsp;&emsp;使用ARC虽然可以简化内存管理，但是ARC并不是万能的，有些情况程序为了能够正常运行，会隐式地持有或者复制对象，如果不加以注意，便会造成内存泄露。在ARC下，当Block获取到外部变量时，由于编译器无法预测获取到的变量何时会被突然释放，为了保证程序能够正确运行，让Block持有获取到的变量。<br>","more":"<br>&emsp;&emsp;下面主要通过一个例子来介绍在ARC情况下使用Block不当会导致内存泄露的问题。示例代码来源于《Effective Objective-C 2.0》（编写高质量iOS与OS X代码的52个有效方法）。<br>（1）EOCNetworkFetcher.h</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef void (^EOCNetworkFetcherCompletionHandler)(NSData *data);</span><br><span class=\"line\"></span><br><span class=\"line\">@interface EOCNetworkFetcher : NSObject</span><br><span class=\"line\"></span><br><span class=\"line\">@property (nonatomic, strong, readonly) NSURL *url;</span><br><span class=\"line\"></span><br><span class=\"line\">- (id)initWithURL:(NSURL *)url;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>（2）EOCNetworkFetcher.m</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@interface EOCNetworkFetcher ()</span><br><span class=\"line\"></span><br><span class=\"line\">@property (nonatomic, strong, readwrite) NSURL *url;</span><br><span class=\"line\">@property (nonatomic, copy) EOCNetworkFetcherCompletionHandler completionHandler;</span><br><span class=\"line\">@property (nonatomic, strong) NSData *downloadData;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br><span class=\"line\"></span><br><span class=\"line\">@implementation EOCNetworkFetcher</span><br><span class=\"line\"></span><br><span class=\"line\">- (id)initWithURL:(NSURL *)url &#123;</span><br><span class=\"line\">    if(self = [super init]) &#123;</span><br><span class=\"line\">        _url = url;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return self;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)startWithCompletionHandler:(EOCNetworkFetcherCompletionHandler)completion &#123;</span><br><span class=\"line\">    self.completionHandler = completion;</span><br><span class=\"line\">    //开始网络请求</span><br><span class=\"line\">    dispatch_async(dispatch_get_global_queue(0, 0), ^&#123;</span><br><span class=\"line\">        _downloadData = [[NSData alloc] initWithContentsOfURL:_url];</span><br><span class=\"line\">        dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class=\"line\">             //网络请求完成</span><br><span class=\"line\">            [self p_requestCompleted];</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)p_requestCompleted &#123;</span><br><span class=\"line\">    if(_completionHandler) &#123;</span><br><span class=\"line\">        _completionHandler(_downloadData);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>（3）EOCClass.m</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@implementation EOCClass &#123;</span><br><span class=\"line\">    EOCNetworkFetcher *_networkFetcher;</span><br><span class=\"line\">    NSData *_fetchedData;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)downloadData &#123;</span><br><span class=\"line\">    NSURL *url = [NSURL URLWithString:@&quot;http://www.baidu.com&quot;];</span><br><span class=\"line\">    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];</span><br><span class=\"line\">    [_networkFetcher startWithCompletionHandler:^(NSData *data) &#123;</span><br><span class=\"line\">        _fetchedData = data;</span><br><span class=\"line\">    &#125;];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>代码分析：</p>\n<blockquote>\n<ul>\n<li>completion handler块因为要设置_fetchedData实例变量的值，所以它必须捕获self变量，也就是说handler块保留了EOCClass实例。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>而EOCClass实例通过strong实例变量保留了EOCNetworkFetcher，最后EOCNetworkFetcher实例对象又保留了handler块。</li>\n</ul>\n</blockquote>\n<p>引用关系如下下图所示<br><img src=\"http://7xk4rv.com1.z0.glb.clouddn.com/ARC%E4%B8%8B%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E6%80%BB%E7%BB%93_1.png\" alt=\"循环引用示意图\"></p>\n<p>要想打破保留环，解决办法：</p>\n<blockquote>\n<ul>\n<li>方法一：使用完EOCNetworkFetcher对象之后就没有必要在保留该对象了，在block里面将对象释放即可打破保留环。</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)downloadData &#123;</span><br><span class=\"line\">    NSURL *url = [NSURL URLWithString:@&quot;http://www.baidu.com&quot;];</span><br><span class=\"line\">    _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];</span><br><span class=\"line\">    [_networkFetcher startWithCompletionHandler:^(NSData *data) &#123;</span><br><span class=\"line\">        _fetchedData = data;</span><br><span class=\"line\">        _networkFetcher = nil;   //加上此行，此处是为了打破循环引用</span><br><span class=\"line\">    &#125;];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li>方法二：上面的方法需要调用者自己来将对象手动设置为nil，对于使用者来说会造成很多困恼，如果忘记将对象设置为nil就会造成循环引用。在运行完completion handler之后将block释放即可。</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)p_requestCompleted &#123;</span><br><span class=\"line\">    if(_completionHandler) &#123;</span><br><span class=\"line\">        _completionHandler(_downloadData);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    self.completionHandler = nil;   //加上此行，此处是为了打破循环引用</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ul>\n<li>方法三：将引用的一方变成weak，从而避免循环引用。</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)downloadData &#123;</span><br><span class=\"line\">   __weak __typeof(self) weakSelf = self;</span><br><span class=\"line\">   NSURL *url = [NSURL URLWithString:@&quot;http://www.baidu.com&quot;];</span><br><span class=\"line\">   _networkFetcher = [[EOCNetworkFetcher alloc] initWithURL:url];</span><br><span class=\"line\">   [_networkFetcher startWithCompletionHandler:^(NSData *data) &#123;</span><br><span class=\"line\">        //如果想防止weakSelf被释放，可以再次强引用</span><br><span class=\"line\">        __typeof(&amp;*weakSelf) strongSelf = weakSelf;</span><br><span class=\"line\">        if (strongSelf) &#123;</span><br><span class=\"line\">            strongSelf.fetchedData = data;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">   &#125;];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"2、NSTimer\"><a href=\"#2、NSTimer\" class=\"headerlink\" title=\"2、NSTimer\"></a>2、NSTimer</h2><p>在使用NSTimer addTarget时，为了防止target被释放而导致的程序异常，timer会持有target，所以这也是一处内存泄露的隐患。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * self持有timer，timer在初始化时持有self，造成循环引用。</span><br><span class=\"line\"> * 解决的方法就是使用invalidate方法销掉timer。</span><br><span class=\"line\"> */</span><br><span class=\"line\">@interface SomeViewController : UIViewController</span><br><span class=\"line\">@property (nonatomic, strong) NSTimer *timer;</span><br><span class=\"line\">@end</span><br><span class=\"line\">@implementation SomeViewController</span><br><span class=\"line\"></span><br><span class=\"line\">- (void)someMethod</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    timer = [NSTimer scheduledTimerWithTimeInterval:0.1  </span><br><span class=\"line\">                                             target:self  </span><br><span class=\"line\">                                           selector:@selector(handleTimer:)  </span><br><span class=\"line\">                                           userInfo:nil  </span><br><span class=\"line\">                                            repeats:YES];  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、performSelector-系列\"><a href=\"#3、performSelector-系列\" class=\"headerlink\" title=\"3、performSelector 系列\"></a>3、performSelector 系列</h2><p>performSelector顾名思义即在运行时执行一个selector，最简单的方法如下</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (id)performSelector:(SEL)selector;</span><br></pre></td></tr></table></figure>\n<p>这种调用selector的方法和直接调用selector基本等效，执行效果相同</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[object methodName];</span><br><span class=\"line\">[object performSelector:@selector(methodName)];</span><br></pre></td></tr></table></figure>\n<p>但performSelector相比直接调用更加灵活</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SEL selector;</span><br><span class=\"line\">if (/* some condition */) &#123;</span><br><span class=\"line\">    selector = @selector(newObject);</span><br><span class=\"line\">&#125; else if (/* some other condition */) &#123;</span><br><span class=\"line\">    selector = @selector(copy);</span><br><span class=\"line\">&#125; else &#123;</span><br><span class=\"line\">    selector = @selector(someProperty);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">id ret = [object performSelector:selector];</span><br></pre></td></tr></table></figure>\n<p>这段代码就相当于在动态之上再动态绑定。在ARC下编译这段代码，编译器会发出警告</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">warning: performSelector may cause a leak because its selector is unknow [-Warc-performSelector-leak]</span><br></pre></td></tr></table></figure>\n<p>正是由于动态，编译器不知道即将调用的selector是什么，不了解方法签名和返回值，甚至是否有返回值都不懂，所以编译器无法用ARC的内存管理规则来判断返回值是否应该释放。因此，ARC采用了比较谨慎的做法，不添加释放操作，即在方法返回对象时就可能将其持有，从而可能导致内存泄露。</p>\n<p>以本段代码为例，前两种情况（newObject, copy）都需要再次释放，而第三种情况不需要。这种泄露隐藏得如此之深，以至于使用static analyzer都很难检测到。如果把代码的最后一行改成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[object performSelector:selector];</span><br></pre></td></tr></table></figure>\n<p>不创建一个返回值变量测试分析，简直难以想象这里居然会出现内存问题。所以如果你使用的selector有返回值，一定要处理掉。</p>\n<h2 id=\"4、循环引用\"><a href=\"#4、循环引用\" class=\"headerlink\" title=\"4、循环引用\"></a>4、循环引用</h2><p>A有个属性B，B有个属性A，如果都是strong修饰的话，两个对象都无法释放。<br>这种问题常发生于把delegate声明为strong属性了。 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@interface SampleViewController</span><br><span class=\"line\">@property (nonatomic, strong) SampleClass *sampleClass;</span><br><span class=\"line\">@end</span><br><span class=\"line\">@interface SampleClass</span><br><span class=\"line\">@property (nonatomic, strong) SampleViewController *delegate;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<h2 id=\"5、循环未结束\"><a href=\"#5、循环未结束\" class=\"headerlink\" title=\"5、循环未结束\"></a>5、循环未结束</h2><p>如果某个ViewController中有无限循环，也会导致即使ViewController对应的view关掉了，ViewController也不能被释放。<br>这种问题常发生于animation处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CATransition *transition = [CATransition animation];</span><br><span class=\"line\">transition.duration = 0.5;</span><br><span class=\"line\">tansition.repeatCount = HUGE_VALL;</span><br><span class=\"line\">[self.view.layer addAnimation:transition forKey:&quot;myAnimation&quot;];</span><br></pre></td></tr></table></figure>\n<p>上例中，animation重复次数设成HUGE_VALL，一个很大的数值，基本上等于无限循环了。<br>解决办法是，在ViewController关掉的时候，停止这个animation。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-(void)viewWillDisappear:(BOOL)animated &#123;</span><br><span class=\"line\">    [self.view.layer removeAllAnimations];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"6、非OBJC对象\"><a href=\"#6、非OBJC对象\" class=\"headerlink\" title=\"6、非OBJC对象\"></a>6、非OBJC对象</h2><p>ARC是自动检测objc对象的，非objc对象就无能为力了，比如C或C++等。<br>C语言使用malloc开辟，free释放。<br>C++使用new开辟，delete释放。<br>但是在ARC下，不会添加非objc对象释放语句，如果没去释放，也会造成内存泄露。</p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>"},{"title":"Realm，一个跨平台、高性能的数据库","date":"2016-06-20T06:05:14.000Z","_content":"## 为什么要使用Realm？\n### 1、简单易用\nRealm并不是一个建立在SQLite之上的ORM，而是一个基于自己的持久化引擎，简单并且快速的面向对象移动数据库。我们的用户们说分分钟就学会了怎样使用Realm，迁移App到Realm也不过只需要花几个小时，方便的Realm为他们省却了数周的开发工作。\n<!--more-->\n### 2、跨平台\nRealm支持iOS、OS X（Objective-C和Swift）以及Android。Realm文件可以跨平台共享，让Java、Swift和Objective-C使用相同的抽象模型访问，从而让您在各个平台上使用尽可能相似的业务逻辑。\n### 3、快速\n得益于zero-copy的设计，Realm比普通的ORM要快很多，甚至比单独无封装的SQLite还要快。请参考iOS benchmark和Android benchmark，或者看看我们的用户们在Twitter上怎么说。\n### 4、支持\n您可以通过以下渠道获得迅速的官方支持：Github、StackOverflow、Twitter、微博。\n\n## 安装\n### 系统要求\n1、使用 Realm 构建应用的基本要求：iOS >= 7, OS X >= 10.9，并且支持 WatchKit；  \n2、需要使用 Xcode 6.4 或者以后的版本;  \n3、程序支持Objective-C, Swift 1.2 & Swift 2.x。\n### 动态框架\n注意：动态框架与 iOS 7 不兼容，要支持 iOS 7 的话请使用\"静态框架\"。  \n1、[下载](https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip)最新的Realm发行版本，并解压；  \n2、前往Xcode 工程的\"General\"设置项中，从ios/dynamic/、osx/、tvos/或者watchos/中将\"Realm.framework\"拖曳到\"Embedded Binaries\"选项中。确认Copy items if needed被选中后，点击Finish按钮；  \n3、在单元测试目标的”Build Settings”中，在”Framework Search Paths”中添加Realm.framework的上级目录；  \n4、如果希望使用Swift加载Realm，请拖动Swift/RLMSupport.swift文件到 Xcode 工程的文件导航栏中并选中Copy items if needed；  \n5、如果在 iOS、watchOS 或者 tvOS 项目中使用 Realm，请在您应用目标的”Build Phases”中，创建一个新的”Run Script Phase”，并将这条脚本复制到文本框中。 因为要绕过APP商店提交的bug，这一步在打包通用设备的二进制发布版本时是必须的。\n  \n```\nbash \"${BUILT_PRODUCTS_DIR}/${FRAMEWORKS_FOLDER_PATH}/Realm.framework/strip-frameworks.sh\"\n```\n\n### 静态框架\n1、下载 Realm 的[最新版本](https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip)并解压；  \n2、将 Realm.framework 从 ios/static/ 文件夹拖曳到您 Xcode 项目中的文件导航器当中。确保 Copy items if needed 选中然后单击 Finish；  \n3、在 Xcode 文件导航器中选择您的项目，然后选择您的应用目标，进入到** Build Phases** 选项卡中。在 Link Binary with Libraries 中单击 + 号然后添加 libc++.dylib；  \n4、如果你在用 Swift 来使用 Realm，那么将位于 Swift/RLMSupport.swift 的文件拖曳进您 Xcode 项目中的文件导航器当中，确保 Copy items if needed 选中。  \n\n## 从这里开始\nObjective-C版本的 Realm 能够让您以一种安全、耐用以及迅捷的方式来高效地编写应用的数据模型层，如下例所示：\n\n```\n// 定义模型的做法和定义常规 Objective-C 类的做法类似\n@interface Dog : RLMObject\n@property NSString *name;\n@property NSInteger age;\n@end\nRLM_ARRAY_TYPE(Dog)\n@interface Person : RLMObject\n@property NSString             *name;\n@property NSData               *picture;\n@property RLMArray<Dog *><Dog> *dogs;\n@end\n//-------------------------------------------\n// 使用的方法和常规 Objective-C 对象的使用方法类似\nDog *mydog = [[Dog alloc] init];\nmydog.name = @\"大黄\";\nmydog.age = 1;\nmydog.picture = nil; // 属性的值可以为空\nNSLog(@\"狗狗的名字： %@\", mydog.name);\n//-------------------------------------------\n// 检索 Realm 数据库，找到小于 2 岁 的所有狗狗\nRLMResults<Dog *> *puppies = [Dog objectsWhere:@\"age < 2\"];\npuppies.count; // => 0 因为目前还没有任何狗狗被添加到了 Realm 数据库中\n//-------------------------------------------\n// 数据持久化操作十分简单\nRLMRealm *realm = [RLMRealm defaultRealm];\n[realm transactionWithBlock:^{\n  [realm addObject:mydog];\n}];\n//-------------------------------------------\n// 检索结果会实时更新\npuppies.count; // => 1\n//-------------------------------------------\n// 可以在任何一个线程中执行检索操作\ndispatch_async(dispatch_queue_create(\"background\", 0), ^{\n  Dog *theDog = [[Dog objectsWhere:@\"age == 1\"] firstObject];\n  RLMRealm *realm = [RLMRealm defaultRealm];\n  [realm beginWriteTransaction];\n  theDog.age = 3;\n  [realm commitWriteTransaction];\n});\n```\n\n## 相关资料\nhttps://github.com/realm/realm-cocoa  \nhttps://realm.io/cn/docs/objc/latest/#section\n\nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","source":"_posts/Realm，一个跨平台、高性能的数据库.md","raw":"---\ntitle: Realm，一个跨平台、高性能的数据库\ndate: 2016-06-20 14:05:14\ncategories: iOS\ntags: [iOS]\n---\n## 为什么要使用Realm？\n### 1、简单易用\nRealm并不是一个建立在SQLite之上的ORM，而是一个基于自己的持久化引擎，简单并且快速的面向对象移动数据库。我们的用户们说分分钟就学会了怎样使用Realm，迁移App到Realm也不过只需要花几个小时，方便的Realm为他们省却了数周的开发工作。\n<!--more-->\n### 2、跨平台\nRealm支持iOS、OS X（Objective-C和Swift）以及Android。Realm文件可以跨平台共享，让Java、Swift和Objective-C使用相同的抽象模型访问，从而让您在各个平台上使用尽可能相似的业务逻辑。\n### 3、快速\n得益于zero-copy的设计，Realm比普通的ORM要快很多，甚至比单独无封装的SQLite还要快。请参考iOS benchmark和Android benchmark，或者看看我们的用户们在Twitter上怎么说。\n### 4、支持\n您可以通过以下渠道获得迅速的官方支持：Github、StackOverflow、Twitter、微博。\n\n## 安装\n### 系统要求\n1、使用 Realm 构建应用的基本要求：iOS >= 7, OS X >= 10.9，并且支持 WatchKit；  \n2、需要使用 Xcode 6.4 或者以后的版本;  \n3、程序支持Objective-C, Swift 1.2 & Swift 2.x。\n### 动态框架\n注意：动态框架与 iOS 7 不兼容，要支持 iOS 7 的话请使用\"静态框架\"。  \n1、[下载](https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip)最新的Realm发行版本，并解压；  \n2、前往Xcode 工程的\"General\"设置项中，从ios/dynamic/、osx/、tvos/或者watchos/中将\"Realm.framework\"拖曳到\"Embedded Binaries\"选项中。确认Copy items if needed被选中后，点击Finish按钮；  \n3、在单元测试目标的”Build Settings”中，在”Framework Search Paths”中添加Realm.framework的上级目录；  \n4、如果希望使用Swift加载Realm，请拖动Swift/RLMSupport.swift文件到 Xcode 工程的文件导航栏中并选中Copy items if needed；  \n5、如果在 iOS、watchOS 或者 tvOS 项目中使用 Realm，请在您应用目标的”Build Phases”中，创建一个新的”Run Script Phase”，并将这条脚本复制到文本框中。 因为要绕过APP商店提交的bug，这一步在打包通用设备的二进制发布版本时是必须的。\n  \n```\nbash \"${BUILT_PRODUCTS_DIR}/${FRAMEWORKS_FOLDER_PATH}/Realm.framework/strip-frameworks.sh\"\n```\n\n### 静态框架\n1、下载 Realm 的[最新版本](https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip)并解压；  \n2、将 Realm.framework 从 ios/static/ 文件夹拖曳到您 Xcode 项目中的文件导航器当中。确保 Copy items if needed 选中然后单击 Finish；  \n3、在 Xcode 文件导航器中选择您的项目，然后选择您的应用目标，进入到** Build Phases** 选项卡中。在 Link Binary with Libraries 中单击 + 号然后添加 libc++.dylib；  \n4、如果你在用 Swift 来使用 Realm，那么将位于 Swift/RLMSupport.swift 的文件拖曳进您 Xcode 项目中的文件导航器当中，确保 Copy items if needed 选中。  \n\n## 从这里开始\nObjective-C版本的 Realm 能够让您以一种安全、耐用以及迅捷的方式来高效地编写应用的数据模型层，如下例所示：\n\n```\n// 定义模型的做法和定义常规 Objective-C 类的做法类似\n@interface Dog : RLMObject\n@property NSString *name;\n@property NSInteger age;\n@end\nRLM_ARRAY_TYPE(Dog)\n@interface Person : RLMObject\n@property NSString             *name;\n@property NSData               *picture;\n@property RLMArray<Dog *><Dog> *dogs;\n@end\n//-------------------------------------------\n// 使用的方法和常规 Objective-C 对象的使用方法类似\nDog *mydog = [[Dog alloc] init];\nmydog.name = @\"大黄\";\nmydog.age = 1;\nmydog.picture = nil; // 属性的值可以为空\nNSLog(@\"狗狗的名字： %@\", mydog.name);\n//-------------------------------------------\n// 检索 Realm 数据库，找到小于 2 岁 的所有狗狗\nRLMResults<Dog *> *puppies = [Dog objectsWhere:@\"age < 2\"];\npuppies.count; // => 0 因为目前还没有任何狗狗被添加到了 Realm 数据库中\n//-------------------------------------------\n// 数据持久化操作十分简单\nRLMRealm *realm = [RLMRealm defaultRealm];\n[realm transactionWithBlock:^{\n  [realm addObject:mydog];\n}];\n//-------------------------------------------\n// 检索结果会实时更新\npuppies.count; // => 1\n//-------------------------------------------\n// 可以在任何一个线程中执行检索操作\ndispatch_async(dispatch_queue_create(\"background\", 0), ^{\n  Dog *theDog = [[Dog objectsWhere:@\"age == 1\"] firstObject];\n  RLMRealm *realm = [RLMRealm defaultRealm];\n  [realm beginWriteTransaction];\n  theDog.age = 3;\n  [realm commitWriteTransaction];\n});\n```\n\n## 相关资料\nhttps://github.com/realm/realm-cocoa  \nhttps://realm.io/cn/docs/objc/latest/#section\n\nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","slug":"Realm，一个跨平台、高性能的数据库","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh0u0001n5xf07hcftlg","content":"<h2 id=\"为什么要使用Realm？\"><a href=\"#为什么要使用Realm？\" class=\"headerlink\" title=\"为什么要使用Realm？\"></a>为什么要使用Realm？</h2><h3 id=\"1、简单易用\"><a href=\"#1、简单易用\" class=\"headerlink\" title=\"1、简单易用\"></a>1、简单易用</h3><p>Realm并不是一个建立在SQLite之上的ORM，而是一个基于自己的持久化引擎，简单并且快速的面向对象移动数据库。我们的用户们说分分钟就学会了怎样使用Realm，迁移App到Realm也不过只需要花几个小时，方便的Realm为他们省却了数周的开发工作。<br><a id=\"more\"></a></p>\n<h3 id=\"2、跨平台\"><a href=\"#2、跨平台\" class=\"headerlink\" title=\"2、跨平台\"></a>2、跨平台</h3><p>Realm支持iOS、OS X（Objective-C和Swift）以及Android。Realm文件可以跨平台共享，让Java、Swift和Objective-C使用相同的抽象模型访问，从而让您在各个平台上使用尽可能相似的业务逻辑。</p>\n<h3 id=\"3、快速\"><a href=\"#3、快速\" class=\"headerlink\" title=\"3、快速\"></a>3、快速</h3><p>得益于zero-copy的设计，Realm比普通的ORM要快很多，甚至比单独无封装的SQLite还要快。请参考iOS benchmark和Android benchmark，或者看看我们的用户们在Twitter上怎么说。</p>\n<h3 id=\"4、支持\"><a href=\"#4、支持\" class=\"headerlink\" title=\"4、支持\"></a>4、支持</h3><p>您可以通过以下渠道获得迅速的官方支持：Github、StackOverflow、Twitter、微博。</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><h3 id=\"系统要求\"><a href=\"#系统要求\" class=\"headerlink\" title=\"系统要求\"></a>系统要求</h3><p>1、使用 Realm 构建应用的基本要求：iOS &gt;= 7, OS X &gt;= 10.9，并且支持 WatchKit；<br>2、需要使用 Xcode 6.4 或者以后的版本;<br>3、程序支持Objective-C, Swift 1.2 &amp; Swift 2.x。</p>\n<h3 id=\"动态框架\"><a href=\"#动态框架\" class=\"headerlink\" title=\"动态框架\"></a>动态框架</h3><p>注意：动态框架与 iOS 7 不兼容，要支持 iOS 7 的话请使用”静态框架”。<br>1、<a href=\"https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip\" target=\"_blank\" rel=\"noopener\">下载</a>最新的Realm发行版本，并解压；<br>2、前往Xcode 工程的”General”设置项中，从ios/dynamic/、osx/、tvos/或者watchos/中将”Realm.framework”拖曳到”Embedded Binaries”选项中。确认Copy items if needed被选中后，点击Finish按钮；<br>3、在单元测试目标的”Build Settings”中，在”Framework Search Paths”中添加Realm.framework的上级目录；<br>4、如果希望使用Swift加载Realm，请拖动Swift/RLMSupport.swift文件到 Xcode 工程的文件导航栏中并选中Copy items if needed；<br>5、如果在 iOS、watchOS 或者 tvOS 项目中使用 Realm，请在您应用目标的”Build Phases”中，创建一个新的”Run Script Phase”，并将这条脚本复制到文本框中。 因为要绕过APP商店提交的bug，这一步在打包通用设备的二进制发布版本时是必须的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bash &quot;$&#123;BUILT_PRODUCTS_DIR&#125;/$&#123;FRAMEWORKS_FOLDER_PATH&#125;/Realm.framework/strip-frameworks.sh&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"静态框架\"><a href=\"#静态框架\" class=\"headerlink\" title=\"静态框架\"></a>静态框架</h3><p>1、下载 Realm 的<a href=\"https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip\" target=\"_blank\" rel=\"noopener\">最新版本</a>并解压；<br>2、将 Realm.framework 从 ios/static/ 文件夹拖曳到您 Xcode 项目中的文件导航器当中。确保 Copy items if needed 选中然后单击 Finish；<br>3、在 Xcode 文件导航器中选择您的项目，然后选择您的应用目标，进入到<strong> Build Phases</strong> 选项卡中。在 Link Binary with Libraries 中单击 + 号然后添加 libc++.dylib；<br>4、如果你在用 Swift 来使用 Realm，那么将位于 Swift/RLMSupport.swift 的文件拖曳进您 Xcode 项目中的文件导航器当中，确保 Copy items if needed 选中。  </p>\n<h2 id=\"从这里开始\"><a href=\"#从这里开始\" class=\"headerlink\" title=\"从这里开始\"></a>从这里开始</h2><p>Objective-C版本的 Realm 能够让您以一种安全、耐用以及迅捷的方式来高效地编写应用的数据模型层，如下例所示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 定义模型的做法和定义常规 Objective-C 类的做法类似</span><br><span class=\"line\">@interface Dog : RLMObject</span><br><span class=\"line\">@property NSString *name;</span><br><span class=\"line\">@property NSInteger age;</span><br><span class=\"line\">@end</span><br><span class=\"line\">RLM_ARRAY_TYPE(Dog)</span><br><span class=\"line\">@interface Person : RLMObject</span><br><span class=\"line\">@property NSString             *name;</span><br><span class=\"line\">@property NSData               *picture;</span><br><span class=\"line\">@property RLMArray&lt;Dog *&gt;&lt;Dog&gt; *dogs;</span><br><span class=\"line\">@end</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 使用的方法和常规 Objective-C 对象的使用方法类似</span><br><span class=\"line\">Dog *mydog = [[Dog alloc] init];</span><br><span class=\"line\">mydog.name = @&quot;大黄&quot;;</span><br><span class=\"line\">mydog.age = 1;</span><br><span class=\"line\">mydog.picture = nil; // 属性的值可以为空</span><br><span class=\"line\">NSLog(@&quot;狗狗的名字： %@&quot;, mydog.name);</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 检索 Realm 数据库，找到小于 2 岁 的所有狗狗</span><br><span class=\"line\">RLMResults&lt;Dog *&gt; *puppies = [Dog objectsWhere:@&quot;age &lt; 2&quot;];</span><br><span class=\"line\">puppies.count; // =&gt; 0 因为目前还没有任何狗狗被添加到了 Realm 数据库中</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 数据持久化操作十分简单</span><br><span class=\"line\">RLMRealm *realm = [RLMRealm defaultRealm];</span><br><span class=\"line\">[realm transactionWithBlock:^&#123;</span><br><span class=\"line\">  [realm addObject:mydog];</span><br><span class=\"line\">&#125;];</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 检索结果会实时更新</span><br><span class=\"line\">puppies.count; // =&gt; 1</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 可以在任何一个线程中执行检索操作</span><br><span class=\"line\">dispatch_async(dispatch_queue_create(&quot;background&quot;, 0), ^&#123;</span><br><span class=\"line\">  Dog *theDog = [[Dog objectsWhere:@&quot;age == 1&quot;] firstObject];</span><br><span class=\"line\">  RLMRealm *realm = [RLMRealm defaultRealm];</span><br><span class=\"line\">  [realm beginWriteTransaction];</span><br><span class=\"line\">  theDog.age = 3;</span><br><span class=\"line\">  [realm commitWriteTransaction];</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h2 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h2><p><a href=\"https://github.com/realm/realm-cocoa\" target=\"_blank\" rel=\"noopener\">https://github.com/realm/realm-cocoa</a><br><a href=\"https://realm.io/cn/docs/objc/latest/#section\" target=\"_blank\" rel=\"noopener\">https://realm.io/cn/docs/objc/latest/#section</a></p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"为什么要使用Realm？\"><a href=\"#为什么要使用Realm？\" class=\"headerlink\" title=\"为什么要使用Realm？\"></a>为什么要使用Realm？</h2><h3 id=\"1、简单易用\"><a href=\"#1、简单易用\" class=\"headerlink\" title=\"1、简单易用\"></a>1、简单易用</h3><p>Realm并不是一个建立在SQLite之上的ORM，而是一个基于自己的持久化引擎，简单并且快速的面向对象移动数据库。我们的用户们说分分钟就学会了怎样使用Realm，迁移App到Realm也不过只需要花几个小时，方便的Realm为他们省却了数周的开发工作。<br>","more":"</p>\n<h3 id=\"2、跨平台\"><a href=\"#2、跨平台\" class=\"headerlink\" title=\"2、跨平台\"></a>2、跨平台</h3><p>Realm支持iOS、OS X（Objective-C和Swift）以及Android。Realm文件可以跨平台共享，让Java、Swift和Objective-C使用相同的抽象模型访问，从而让您在各个平台上使用尽可能相似的业务逻辑。</p>\n<h3 id=\"3、快速\"><a href=\"#3、快速\" class=\"headerlink\" title=\"3、快速\"></a>3、快速</h3><p>得益于zero-copy的设计，Realm比普通的ORM要快很多，甚至比单独无封装的SQLite还要快。请参考iOS benchmark和Android benchmark，或者看看我们的用户们在Twitter上怎么说。</p>\n<h3 id=\"4、支持\"><a href=\"#4、支持\" class=\"headerlink\" title=\"4、支持\"></a>4、支持</h3><p>您可以通过以下渠道获得迅速的官方支持：Github、StackOverflow、Twitter、微博。</p>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><h3 id=\"系统要求\"><a href=\"#系统要求\" class=\"headerlink\" title=\"系统要求\"></a>系统要求</h3><p>1、使用 Realm 构建应用的基本要求：iOS &gt;= 7, OS X &gt;= 10.9，并且支持 WatchKit；<br>2、需要使用 Xcode 6.4 或者以后的版本;<br>3、程序支持Objective-C, Swift 1.2 &amp; Swift 2.x。</p>\n<h3 id=\"动态框架\"><a href=\"#动态框架\" class=\"headerlink\" title=\"动态框架\"></a>动态框架</h3><p>注意：动态框架与 iOS 7 不兼容，要支持 iOS 7 的话请使用”静态框架”。<br>1、<a href=\"https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip\" target=\"_blank\" rel=\"noopener\">下载</a>最新的Realm发行版本，并解压；<br>2、前往Xcode 工程的”General”设置项中，从ios/dynamic/、osx/、tvos/或者watchos/中将”Realm.framework”拖曳到”Embedded Binaries”选项中。确认Copy items if needed被选中后，点击Finish按钮；<br>3、在单元测试目标的”Build Settings”中，在”Framework Search Paths”中添加Realm.framework的上级目录；<br>4、如果希望使用Swift加载Realm，请拖动Swift/RLMSupport.swift文件到 Xcode 工程的文件导航栏中并选中Copy items if needed；<br>5、如果在 iOS、watchOS 或者 tvOS 项目中使用 Realm，请在您应用目标的”Build Phases”中，创建一个新的”Run Script Phase”，并将这条脚本复制到文本框中。 因为要绕过APP商店提交的bug，这一步在打包通用设备的二进制发布版本时是必须的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bash &quot;$&#123;BUILT_PRODUCTS_DIR&#125;/$&#123;FRAMEWORKS_FOLDER_PATH&#125;/Realm.framework/strip-frameworks.sh&quot;</span><br></pre></td></tr></table></figure>\n<h3 id=\"静态框架\"><a href=\"#静态框架\" class=\"headerlink\" title=\"静态框架\"></a>静态框架</h3><p>1、下载 Realm 的<a href=\"https://static.realm.io/downloads/objc/realm-objc-0.98.3.zip\" target=\"_blank\" rel=\"noopener\">最新版本</a>并解压；<br>2、将 Realm.framework 从 ios/static/ 文件夹拖曳到您 Xcode 项目中的文件导航器当中。确保 Copy items if needed 选中然后单击 Finish；<br>3、在 Xcode 文件导航器中选择您的项目，然后选择您的应用目标，进入到<strong> Build Phases</strong> 选项卡中。在 Link Binary with Libraries 中单击 + 号然后添加 libc++.dylib；<br>4、如果你在用 Swift 来使用 Realm，那么将位于 Swift/RLMSupport.swift 的文件拖曳进您 Xcode 项目中的文件导航器当中，确保 Copy items if needed 选中。  </p>\n<h2 id=\"从这里开始\"><a href=\"#从这里开始\" class=\"headerlink\" title=\"从这里开始\"></a>从这里开始</h2><p>Objective-C版本的 Realm 能够让您以一种安全、耐用以及迅捷的方式来高效地编写应用的数据模型层，如下例所示：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 定义模型的做法和定义常规 Objective-C 类的做法类似</span><br><span class=\"line\">@interface Dog : RLMObject</span><br><span class=\"line\">@property NSString *name;</span><br><span class=\"line\">@property NSInteger age;</span><br><span class=\"line\">@end</span><br><span class=\"line\">RLM_ARRAY_TYPE(Dog)</span><br><span class=\"line\">@interface Person : RLMObject</span><br><span class=\"line\">@property NSString             *name;</span><br><span class=\"line\">@property NSData               *picture;</span><br><span class=\"line\">@property RLMArray&lt;Dog *&gt;&lt;Dog&gt; *dogs;</span><br><span class=\"line\">@end</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 使用的方法和常规 Objective-C 对象的使用方法类似</span><br><span class=\"line\">Dog *mydog = [[Dog alloc] init];</span><br><span class=\"line\">mydog.name = @&quot;大黄&quot;;</span><br><span class=\"line\">mydog.age = 1;</span><br><span class=\"line\">mydog.picture = nil; // 属性的值可以为空</span><br><span class=\"line\">NSLog(@&quot;狗狗的名字： %@&quot;, mydog.name);</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 检索 Realm 数据库，找到小于 2 岁 的所有狗狗</span><br><span class=\"line\">RLMResults&lt;Dog *&gt; *puppies = [Dog objectsWhere:@&quot;age &lt; 2&quot;];</span><br><span class=\"line\">puppies.count; // =&gt; 0 因为目前还没有任何狗狗被添加到了 Realm 数据库中</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 数据持久化操作十分简单</span><br><span class=\"line\">RLMRealm *realm = [RLMRealm defaultRealm];</span><br><span class=\"line\">[realm transactionWithBlock:^&#123;</span><br><span class=\"line\">  [realm addObject:mydog];</span><br><span class=\"line\">&#125;];</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 检索结果会实时更新</span><br><span class=\"line\">puppies.count; // =&gt; 1</span><br><span class=\"line\">//-------------------------------------------</span><br><span class=\"line\">// 可以在任何一个线程中执行检索操作</span><br><span class=\"line\">dispatch_async(dispatch_queue_create(&quot;background&quot;, 0), ^&#123;</span><br><span class=\"line\">  Dog *theDog = [[Dog objectsWhere:@&quot;age == 1&quot;] firstObject];</span><br><span class=\"line\">  RLMRealm *realm = [RLMRealm defaultRealm];</span><br><span class=\"line\">  [realm beginWriteTransaction];</span><br><span class=\"line\">  theDog.age = 3;</span><br><span class=\"line\">  [realm commitWriteTransaction];</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h2 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h2><p><a href=\"https://github.com/realm/realm-cocoa\" target=\"_blank\" rel=\"noopener\">https://github.com/realm/realm-cocoa</a><br><a href=\"https://realm.io/cn/docs/objc/latest/#section\" target=\"_blank\" rel=\"noopener\">https://realm.io/cn/docs/objc/latest/#section</a></p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>"},{"title":"Github+Hexo搭建免费个人博客","date":"2016-06-10T06:03:28.000Z","_content":"经过各种找资料，踩过各种坑，终于搭建好了hexo，域名目前用的是github的，我的hexo是3.2.2版本，hexo不同的版本，很多配置都不一样。好吧，废话不多说了，开始吧。  \n<!--more-->\n## 正文\n这篇教程是针对Mac的，之前是想着写博客，一方面是给自己做笔记，可以提升自己的写作、总结能力。一个技术点我们会使用，并不难，但是要做到让别人也能听懂，还是需要一定的技巧和经验的。很多类似于CSDN、博客园也都可以写文章，但是页面的样式我不是太喜欢，简书还算好点（我的文章在简书上也有同步）。最近看到一些大神们的博客，貌似都是用hexo写的，我也依葫芦画瓢的搭建了一个。不啰嗦了，直接上搭建步骤。\n## 配置环境\n### 安装Node.js（必须）\n作用：用来生成静态页面。  \n到Node.js[官网](https://nodejs.org/en/)下载相应平台的最新版本，按照提示一路安装即可。\n### 安装Git（必须）\n作用：把本地的hexo内容提交到github上去。  \n如果已经安装了Xcode就自带Git，我就不多说了。\n### 申请GitHub（必须）\n作用：是用来做博客的远程仓库、域名、服务器之类的，怎么与本地hexo建立连接等下讲。\n[Github](https://github.com/)账号我也不再啰嗦了，没有的话直接申请就行了，跟一般的注册账号差不多，SSH Keys，看你自己了，可以不配置，不配置的话以后每次对自己的博客有改动提交的时候就要手动输入账号密码，假如配置了就不需要了，怎么配置我就不多说了，网上有很多教程。\n## 开始安装Hexo\n### 安装Hexo\nNode.js和Git都安装好后，可执行如下命令安装hexo：\n  \n```\n$ sudo npm install -g hexo\n```\n\n### 初始化\n然后，执行init命令初始化hexo到你指定的目录，我是直接cd到目标，在目录里执行如下命令:\n\n```\n$ hexo init\n```\n\n好啦，至此，全部安装工作已经完成！\n### 生成静态页面\ncd 到你的init目录，执行如下命令，生成静态页面至public目录。\n\n```\n$ hexo generate（hexo g也可以）\n```\n\n### 本地启动\n启动本地服务，进行文章预览调试，命令：\n\n```\n$ hexo server\n```\n\n在浏览器中输入:http://localhost:4000\n我不知道你们能不能，反正我不能，因为我还没有把环境配置好\n我把我报的一些错，和解决方式列出来：\n\n```\nERROR Plugin load failed: hexo-server\n```\n\n原因：\n\n```\nBesides, utilities are separated into a standalone module. hexo.util is not reachable anymore.\n```\n\n解决方法，执行命令：\n\n```\n$ sudo npm install hexo-server --save \n```\n\n安装完成后，输入以下命令以启动服务器，您的网站会在 http://localhost:4000 下启动。在服务器启动期间，Hexo 会监视文件变动并自动更新，您无须重启服务器。\n这个时候再重新生成静态文件，命令：\n\n```\n$ hexo generate（或hexo g）  \n```\n\n启动本地服务器：\n\n```\n$ hexo server\n```\n\n如果您想要更改端口，或是在执行时遇到了 EADDRINUSE 错误，可以在执行时使用 -p 选项指定其他端口，如下：\n\n```\n$ hexo server -p 5000\n```\n \n## 配置 Github\n### 建立Repository\n建立与你用户名对应的仓库，仓库名必须为【your_user_name.github.io】，固定写法。然后建立关联，我的blog在本地/Users/chenhu/Documents/Hexo，这里面有：\n\n```\n_config.yml    node_modules    public        source　　　　\ndb.json        package.json    scaffolds    themes\n```\n\n现在我们需要修改_config.yml文件来建立关联，命令：\n\n```\n$ vim _config.yml\n```\n\n翻到最下面，改成类似我这样子\n\n```\ndeploy:\n  type: git\n  repository: https://github.com/chenhu1001/chenhu1001.github.io.git\n  branch: master\n```\n\n执行如下命令才能使用git部署\n\n```\n$ sudo npm install hexo-deployer-git --save\n```\n\n网上会有很多说法，有的type是github，还有repository最后面的后缀也不一样，是github.com.git，我也踩了很多坑，我现在的版本是hexo:3.2.2，执行命令hexo -version就出来了，貌似3.0以后全部改成我上面这种格式了。\n然后，执行配置命令：\n\n```\n$ hexo deploy\n```\n\n然后再浏览器中输入[https://chenhu1001.github.io](https://chenhu1001.github.io)就行了，我的github账户叫chenhu1001，把这个改成你github的账户名就行了。\n## 部署步骤\n### 步骤\n每次部署的步骤，可按以下三步来进行。\n\n```\nhexo clean  \nhexo generate  \nhexo deploy\n```\n\n还可以将上面的3个命令封装成一个shell脚本（publish.sh），放在Hexo对应的目录下方便上传部署。\n### 一些常用命令：  \nhexo new \"postName\"&emsp;&emsp;&emsp;//新建文章  \nhexo new page \"pageName\"&emsp;&emsp;&emsp;//新建页面  \nhexo generate&emsp;&emsp;&emsp;//生成静态页面至public目录  \nhexo server&emsp;&emsp;&emsp;//开启预览访问端口（默认端口4000，'ctrl + c'关闭server）  \nhexo deploy&emsp;&emsp;&emsp;//将Hexo部署到GitHub  \nhexo help&emsp;&emsp;&emsp;//查看帮助  \nhexo version&emsp;&emsp;&emsp;//查看Hexo的版本   \n&emsp\\;&emsp\\;&emsp;&emsp;&emsp;//段落前空两格(为了显示，没有转移符) \n<!-\\-more-\\-\\>&emsp;&emsp;&emsp;//用于文章的隔断，显示更多  \n[iOS,WebRTC,直播,FFMpeg]&emsp;&emsp;&emsp;//用于写文章时增加tag\n### 一些基本路径  \n文章在source/_posts下，支持Markdown语法，可以用Markdown编辑器进行编辑，如果想修改头像可以直接在主题的_config.yml文件里面修改，友情链接之类的都在这里，开始打理你的博客吧，有什么问题或者建议，都可以提出来，我会继续完善的。  \n## Markdown语法 \n[实用的Markdown语法例子](https://www.zybuluo.com/mdeditor)\n\nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","source":"_posts/Github-Hexo搭建免费个人博客.md","raw":"---\ntitle: Github+Hexo搭建免费个人博客\ndate: 2016-06-10 14:03:28\ncategories: 随笔\ntags: [随笔]\n---\n经过各种找资料，踩过各种坑，终于搭建好了hexo，域名目前用的是github的，我的hexo是3.2.2版本，hexo不同的版本，很多配置都不一样。好吧，废话不多说了，开始吧。  \n<!--more-->\n## 正文\n这篇教程是针对Mac的，之前是想着写博客，一方面是给自己做笔记，可以提升自己的写作、总结能力。一个技术点我们会使用，并不难，但是要做到让别人也能听懂，还是需要一定的技巧和经验的。很多类似于CSDN、博客园也都可以写文章，但是页面的样式我不是太喜欢，简书还算好点（我的文章在简书上也有同步）。最近看到一些大神们的博客，貌似都是用hexo写的，我也依葫芦画瓢的搭建了一个。不啰嗦了，直接上搭建步骤。\n## 配置环境\n### 安装Node.js（必须）\n作用：用来生成静态页面。  \n到Node.js[官网](https://nodejs.org/en/)下载相应平台的最新版本，按照提示一路安装即可。\n### 安装Git（必须）\n作用：把本地的hexo内容提交到github上去。  \n如果已经安装了Xcode就自带Git，我就不多说了。\n### 申请GitHub（必须）\n作用：是用来做博客的远程仓库、域名、服务器之类的，怎么与本地hexo建立连接等下讲。\n[Github](https://github.com/)账号我也不再啰嗦了，没有的话直接申请就行了，跟一般的注册账号差不多，SSH Keys，看你自己了，可以不配置，不配置的话以后每次对自己的博客有改动提交的时候就要手动输入账号密码，假如配置了就不需要了，怎么配置我就不多说了，网上有很多教程。\n## 开始安装Hexo\n### 安装Hexo\nNode.js和Git都安装好后，可执行如下命令安装hexo：\n  \n```\n$ sudo npm install -g hexo\n```\n\n### 初始化\n然后，执行init命令初始化hexo到你指定的目录，我是直接cd到目标，在目录里执行如下命令:\n\n```\n$ hexo init\n```\n\n好啦，至此，全部安装工作已经完成！\n### 生成静态页面\ncd 到你的init目录，执行如下命令，生成静态页面至public目录。\n\n```\n$ hexo generate（hexo g也可以）\n```\n\n### 本地启动\n启动本地服务，进行文章预览调试，命令：\n\n```\n$ hexo server\n```\n\n在浏览器中输入:http://localhost:4000\n我不知道你们能不能，反正我不能，因为我还没有把环境配置好\n我把我报的一些错，和解决方式列出来：\n\n```\nERROR Plugin load failed: hexo-server\n```\n\n原因：\n\n```\nBesides, utilities are separated into a standalone module. hexo.util is not reachable anymore.\n```\n\n解决方法，执行命令：\n\n```\n$ sudo npm install hexo-server --save \n```\n\n安装完成后，输入以下命令以启动服务器，您的网站会在 http://localhost:4000 下启动。在服务器启动期间，Hexo 会监视文件变动并自动更新，您无须重启服务器。\n这个时候再重新生成静态文件，命令：\n\n```\n$ hexo generate（或hexo g）  \n```\n\n启动本地服务器：\n\n```\n$ hexo server\n```\n\n如果您想要更改端口，或是在执行时遇到了 EADDRINUSE 错误，可以在执行时使用 -p 选项指定其他端口，如下：\n\n```\n$ hexo server -p 5000\n```\n \n## 配置 Github\n### 建立Repository\n建立与你用户名对应的仓库，仓库名必须为【your_user_name.github.io】，固定写法。然后建立关联，我的blog在本地/Users/chenhu/Documents/Hexo，这里面有：\n\n```\n_config.yml    node_modules    public        source　　　　\ndb.json        package.json    scaffolds    themes\n```\n\n现在我们需要修改_config.yml文件来建立关联，命令：\n\n```\n$ vim _config.yml\n```\n\n翻到最下面，改成类似我这样子\n\n```\ndeploy:\n  type: git\n  repository: https://github.com/chenhu1001/chenhu1001.github.io.git\n  branch: master\n```\n\n执行如下命令才能使用git部署\n\n```\n$ sudo npm install hexo-deployer-git --save\n```\n\n网上会有很多说法，有的type是github，还有repository最后面的后缀也不一样，是github.com.git，我也踩了很多坑，我现在的版本是hexo:3.2.2，执行命令hexo -version就出来了，貌似3.0以后全部改成我上面这种格式了。\n然后，执行配置命令：\n\n```\n$ hexo deploy\n```\n\n然后再浏览器中输入[https://chenhu1001.github.io](https://chenhu1001.github.io)就行了，我的github账户叫chenhu1001，把这个改成你github的账户名就行了。\n## 部署步骤\n### 步骤\n每次部署的步骤，可按以下三步来进行。\n\n```\nhexo clean  \nhexo generate  \nhexo deploy\n```\n\n还可以将上面的3个命令封装成一个shell脚本（publish.sh），放在Hexo对应的目录下方便上传部署。\n### 一些常用命令：  \nhexo new \"postName\"&emsp;&emsp;&emsp;//新建文章  \nhexo new page \"pageName\"&emsp;&emsp;&emsp;//新建页面  \nhexo generate&emsp;&emsp;&emsp;//生成静态页面至public目录  \nhexo server&emsp;&emsp;&emsp;//开启预览访问端口（默认端口4000，'ctrl + c'关闭server）  \nhexo deploy&emsp;&emsp;&emsp;//将Hexo部署到GitHub  \nhexo help&emsp;&emsp;&emsp;//查看帮助  \nhexo version&emsp;&emsp;&emsp;//查看Hexo的版本   \n&emsp\\;&emsp\\;&emsp;&emsp;&emsp;//段落前空两格(为了显示，没有转移符) \n<!-\\-more-\\-\\>&emsp;&emsp;&emsp;//用于文章的隔断，显示更多  \n[iOS,WebRTC,直播,FFMpeg]&emsp;&emsp;&emsp;//用于写文章时增加tag\n### 一些基本路径  \n文章在source/_posts下，支持Markdown语法，可以用Markdown编辑器进行编辑，如果想修改头像可以直接在主题的_config.yml文件里面修改，友情链接之类的都在这里，开始打理你的博客吧，有什么问题或者建议，都可以提出来，我会继续完善的。  \n## Markdown语法 \n[实用的Markdown语法例子](https://www.zybuluo.com/mdeditor)\n\nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","slug":"Github-Hexo搭建免费个人博客","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh0z0004n5xfq0g4sa6o","content":"<p>经过各种找资料，踩过各种坑，终于搭建好了hexo，域名目前用的是github的，我的hexo是3.2.2版本，hexo不同的版本，很多配置都不一样。好吧，废话不多说了，开始吧。<br><a id=\"more\"></a></p>\n<h2 id=\"正文\"><a href=\"#正文\" class=\"headerlink\" title=\"正文\"></a>正文</h2><p>这篇教程是针对Mac的，之前是想着写博客，一方面是给自己做笔记，可以提升自己的写作、总结能力。一个技术点我们会使用，并不难，但是要做到让别人也能听懂，还是需要一定的技巧和经验的。很多类似于CSDN、博客园也都可以写文章，但是页面的样式我不是太喜欢，简书还算好点（我的文章在简书上也有同步）。最近看到一些大神们的博客，貌似都是用hexo写的，我也依葫芦画瓢的搭建了一个。不啰嗦了，直接上搭建步骤。</p>\n<h2 id=\"配置环境\"><a href=\"#配置环境\" class=\"headerlink\" title=\"配置环境\"></a>配置环境</h2><h3 id=\"安装Node-js（必须）\"><a href=\"#安装Node-js（必须）\" class=\"headerlink\" title=\"安装Node.js（必须）\"></a>安装Node.js（必须）</h3><p>作用：用来生成静态页面。<br>到Node.js<a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"noopener\">官网</a>下载相应平台的最新版本，按照提示一路安装即可。</p>\n<h3 id=\"安装Git（必须）\"><a href=\"#安装Git（必须）\" class=\"headerlink\" title=\"安装Git（必须）\"></a>安装Git（必须）</h3><p>作用：把本地的hexo内容提交到github上去。<br>如果已经安装了Xcode就自带Git，我就不多说了。</p>\n<h3 id=\"申请GitHub（必须）\"><a href=\"#申请GitHub（必须）\" class=\"headerlink\" title=\"申请GitHub（必须）\"></a>申请GitHub（必须）</h3><p>作用：是用来做博客的远程仓库、域名、服务器之类的，怎么与本地hexo建立连接等下讲。<br><a href=\"https://github.com/\" target=\"_blank\" rel=\"noopener\">Github</a>账号我也不再啰嗦了，没有的话直接申请就行了，跟一般的注册账号差不多，SSH Keys，看你自己了，可以不配置，不配置的话以后每次对自己的博客有改动提交的时候就要手动输入账号密码，假如配置了就不需要了，怎么配置我就不多说了，网上有很多教程。</p>\n<h2 id=\"开始安装Hexo\"><a href=\"#开始安装Hexo\" class=\"headerlink\" title=\"开始安装Hexo\"></a>开始安装Hexo</h2><h3 id=\"安装Hexo\"><a href=\"#安装Hexo\" class=\"headerlink\" title=\"安装Hexo\"></a>安装Hexo</h3><p>Node.js和Git都安装好后，可执行如下命令安装hexo：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install -g hexo</span><br></pre></td></tr></table></figure>\n<h3 id=\"初始化\"><a href=\"#初始化\" class=\"headerlink\" title=\"初始化\"></a>初始化</h3><p>然后，执行init命令初始化hexo到你指定的目录，我是直接cd到目标，在目录里执行如下命令:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo init</span><br></pre></td></tr></table></figure>\n<p>好啦，至此，全部安装工作已经完成！</p>\n<h3 id=\"生成静态页面\"><a href=\"#生成静态页面\" class=\"headerlink\" title=\"生成静态页面\"></a>生成静态页面</h3><p>cd 到你的init目录，执行如下命令，生成静态页面至public目录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate（hexo g也可以）</span><br></pre></td></tr></table></figure>\n<h3 id=\"本地启动\"><a href=\"#本地启动\" class=\"headerlink\" title=\"本地启动\"></a>本地启动</h3><p>启动本地服务，进行文章预览调试，命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>在浏览器中输入:<a href=\"http://localhost:4000\" target=\"_blank\" rel=\"noopener\">http://localhost:4000</a><br>我不知道你们能不能，反正我不能，因为我还没有把环境配置好<br>我把我报的一些错，和解决方式列出来：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ERROR Plugin load failed: hexo-server</span><br></pre></td></tr></table></figure>\n<p>原因：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Besides, utilities are separated into a standalone module. hexo.util is not reachable anymore.</span><br></pre></td></tr></table></figure>\n<p>解决方法，执行命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install hexo-server --save</span><br></pre></td></tr></table></figure>\n<p>安装完成后，输入以下命令以启动服务器，您的网站会在 <a href=\"http://localhost:4000\" target=\"_blank\" rel=\"noopener\">http://localhost:4000</a> 下启动。在服务器启动期间，Hexo 会监视文件变动并自动更新，您无须重启服务器。<br>这个时候再重新生成静态文件，命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate（或hexo g）</span><br></pre></td></tr></table></figure>\n<p>启动本地服务器：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>如果您想要更改端口，或是在执行时遇到了 EADDRINUSE 错误，可以在执行时使用 -p 选项指定其他端口，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server -p 5000</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置-Github\"><a href=\"#配置-Github\" class=\"headerlink\" title=\"配置 Github\"></a>配置 Github</h2><h3 id=\"建立Repository\"><a href=\"#建立Repository\" class=\"headerlink\" title=\"建立Repository\"></a>建立Repository</h3><p>建立与你用户名对应的仓库，仓库名必须为【your_user_name.github.io】，固定写法。然后建立关联，我的blog在本地/Users/chenhu/Documents/Hexo，这里面有：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_config.yml    node_modules    public        source　　　　</span><br><span class=\"line\">db.json        package.json    scaffolds    themes</span><br></pre></td></tr></table></figure>\n<p>现在我们需要修改_config.yml文件来建立关联，命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim _config.yml</span><br></pre></td></tr></table></figure>\n<p>翻到最下面，改成类似我这样子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: https://github.com/chenhu1001/chenhu1001.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>执行如下命令才能使用git部署</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>\n<p>网上会有很多说法，有的type是github，还有repository最后面的后缀也不一样，是github.com.git，我也踩了很多坑，我现在的版本是hexo:3.2.2，执行命令hexo -version就出来了，貌似3.0以后全部改成我上面这种格式了。<br>然后，执行配置命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>然后再浏览器中输入<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a>就行了，我的github账户叫chenhu1001，把这个改成你github的账户名就行了。</p>\n<h2 id=\"部署步骤\"><a href=\"#部署步骤\" class=\"headerlink\" title=\"部署步骤\"></a>部署步骤</h2><h3 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h3><p>每次部署的步骤，可按以下三步来进行。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean  </span><br><span class=\"line\">hexo generate  </span><br><span class=\"line\">hexo deploy</span><br></pre></td></tr></table></figure>\n<p>还可以将上面的3个命令封装成一个shell脚本（publish.sh），放在Hexo对应的目录下方便上传部署。</p>\n<h3 id=\"一些常用命令：\"><a href=\"#一些常用命令：\" class=\"headerlink\" title=\"一些常用命令：\"></a>一些常用命令：</h3><p>hexo new “postName”&emsp;&emsp;&emsp;//新建文章<br>hexo new page “pageName”&emsp;&emsp;&emsp;//新建页面<br>hexo generate&emsp;&emsp;&emsp;//生成静态页面至public目录<br>hexo server&emsp;&emsp;&emsp;//开启预览访问端口（默认端口4000，’ctrl + c’关闭server）<br>hexo deploy&emsp;&emsp;&emsp;//将Hexo部署到GitHub<br>hexo help&emsp;&emsp;&emsp;//查看帮助<br>hexo version&emsp;&emsp;&emsp;//查看Hexo的版本<br>&amp;emsp\\;&amp;emsp\\;&emsp;&emsp;&emsp;//段落前空两格(为了显示，没有转移符)<br>&lt;!--more-->&emsp;&emsp;&emsp;//用于文章的隔断，显示更多<br>[iOS,WebRTC,直播,FFMpeg]&emsp;&emsp;&emsp;//用于写文章时增加tag</p>\n<h3 id=\"一些基本路径\"><a href=\"#一些基本路径\" class=\"headerlink\" title=\"一些基本路径\"></a>一些基本路径</h3><p>文章在source/_posts下，支持Markdown语法，可以用Markdown编辑器进行编辑，如果想修改头像可以直接在主题的_config.yml文件里面修改，友情链接之类的都在这里，开始打理你的博客吧，有什么问题或者建议，都可以提出来，我会继续完善的。  </p>\n<h2 id=\"Markdown语法\"><a href=\"#Markdown语法\" class=\"headerlink\" title=\"Markdown语法\"></a>Markdown语法</h2><p><a href=\"https://www.zybuluo.com/mdeditor\" target=\"_blank\" rel=\"noopener\">实用的Markdown语法例子</a></p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>\n","site":{"data":{}},"excerpt":"<p>经过各种找资料，踩过各种坑，终于搭建好了hexo，域名目前用的是github的，我的hexo是3.2.2版本，hexo不同的版本，很多配置都不一样。好吧，废话不多说了，开始吧。<br>","more":"</p>\n<h2 id=\"正文\"><a href=\"#正文\" class=\"headerlink\" title=\"正文\"></a>正文</h2><p>这篇教程是针对Mac的，之前是想着写博客，一方面是给自己做笔记，可以提升自己的写作、总结能力。一个技术点我们会使用，并不难，但是要做到让别人也能听懂，还是需要一定的技巧和经验的。很多类似于CSDN、博客园也都可以写文章，但是页面的样式我不是太喜欢，简书还算好点（我的文章在简书上也有同步）。最近看到一些大神们的博客，貌似都是用hexo写的，我也依葫芦画瓢的搭建了一个。不啰嗦了，直接上搭建步骤。</p>\n<h2 id=\"配置环境\"><a href=\"#配置环境\" class=\"headerlink\" title=\"配置环境\"></a>配置环境</h2><h3 id=\"安装Node-js（必须）\"><a href=\"#安装Node-js（必须）\" class=\"headerlink\" title=\"安装Node.js（必须）\"></a>安装Node.js（必须）</h3><p>作用：用来生成静态页面。<br>到Node.js<a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"noopener\">官网</a>下载相应平台的最新版本，按照提示一路安装即可。</p>\n<h3 id=\"安装Git（必须）\"><a href=\"#安装Git（必须）\" class=\"headerlink\" title=\"安装Git（必须）\"></a>安装Git（必须）</h3><p>作用：把本地的hexo内容提交到github上去。<br>如果已经安装了Xcode就自带Git，我就不多说了。</p>\n<h3 id=\"申请GitHub（必须）\"><a href=\"#申请GitHub（必须）\" class=\"headerlink\" title=\"申请GitHub（必须）\"></a>申请GitHub（必须）</h3><p>作用：是用来做博客的远程仓库、域名、服务器之类的，怎么与本地hexo建立连接等下讲。<br><a href=\"https://github.com/\" target=\"_blank\" rel=\"noopener\">Github</a>账号我也不再啰嗦了，没有的话直接申请就行了，跟一般的注册账号差不多，SSH Keys，看你自己了，可以不配置，不配置的话以后每次对自己的博客有改动提交的时候就要手动输入账号密码，假如配置了就不需要了，怎么配置我就不多说了，网上有很多教程。</p>\n<h2 id=\"开始安装Hexo\"><a href=\"#开始安装Hexo\" class=\"headerlink\" title=\"开始安装Hexo\"></a>开始安装Hexo</h2><h3 id=\"安装Hexo\"><a href=\"#安装Hexo\" class=\"headerlink\" title=\"安装Hexo\"></a>安装Hexo</h3><p>Node.js和Git都安装好后，可执行如下命令安装hexo：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install -g hexo</span><br></pre></td></tr></table></figure>\n<h3 id=\"初始化\"><a href=\"#初始化\" class=\"headerlink\" title=\"初始化\"></a>初始化</h3><p>然后，执行init命令初始化hexo到你指定的目录，我是直接cd到目标，在目录里执行如下命令:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo init</span><br></pre></td></tr></table></figure>\n<p>好啦，至此，全部安装工作已经完成！</p>\n<h3 id=\"生成静态页面\"><a href=\"#生成静态页面\" class=\"headerlink\" title=\"生成静态页面\"></a>生成静态页面</h3><p>cd 到你的init目录，执行如下命令，生成静态页面至public目录。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate（hexo g也可以）</span><br></pre></td></tr></table></figure>\n<h3 id=\"本地启动\"><a href=\"#本地启动\" class=\"headerlink\" title=\"本地启动\"></a>本地启动</h3><p>启动本地服务，进行文章预览调试，命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>在浏览器中输入:<a href=\"http://localhost:4000\" target=\"_blank\" rel=\"noopener\">http://localhost:4000</a><br>我不知道你们能不能，反正我不能，因为我还没有把环境配置好<br>我把我报的一些错，和解决方式列出来：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ERROR Plugin load failed: hexo-server</span><br></pre></td></tr></table></figure>\n<p>原因：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Besides, utilities are separated into a standalone module. hexo.util is not reachable anymore.</span><br></pre></td></tr></table></figure>\n<p>解决方法，执行命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install hexo-server --save</span><br></pre></td></tr></table></figure>\n<p>安装完成后，输入以下命令以启动服务器，您的网站会在 <a href=\"http://localhost:4000\" target=\"_blank\" rel=\"noopener\">http://localhost:4000</a> 下启动。在服务器启动期间，Hexo 会监视文件变动并自动更新，您无须重启服务器。<br>这个时候再重新生成静态文件，命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate（或hexo g）</span><br></pre></td></tr></table></figure>\n<p>启动本地服务器：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>如果您想要更改端口，或是在执行时遇到了 EADDRINUSE 错误，可以在执行时使用 -p 选项指定其他端口，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server -p 5000</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置-Github\"><a href=\"#配置-Github\" class=\"headerlink\" title=\"配置 Github\"></a>配置 Github</h2><h3 id=\"建立Repository\"><a href=\"#建立Repository\" class=\"headerlink\" title=\"建立Repository\"></a>建立Repository</h3><p>建立与你用户名对应的仓库，仓库名必须为【your_user_name.github.io】，固定写法。然后建立关联，我的blog在本地/Users/chenhu/Documents/Hexo，这里面有：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_config.yml    node_modules    public        source　　　　</span><br><span class=\"line\">db.json        package.json    scaffolds    themes</span><br></pre></td></tr></table></figure>\n<p>现在我们需要修改_config.yml文件来建立关联，命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim _config.yml</span><br></pre></td></tr></table></figure>\n<p>翻到最下面，改成类似我这样子</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: https://github.com/chenhu1001/chenhu1001.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>执行如下命令才能使用git部署</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>\n<p>网上会有很多说法，有的type是github，还有repository最后面的后缀也不一样，是github.com.git，我也踩了很多坑，我现在的版本是hexo:3.2.2，执行命令hexo -version就出来了，貌似3.0以后全部改成我上面这种格式了。<br>然后，执行配置命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>然后再浏览器中输入<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a>就行了，我的github账户叫chenhu1001，把这个改成你github的账户名就行了。</p>\n<h2 id=\"部署步骤\"><a href=\"#部署步骤\" class=\"headerlink\" title=\"部署步骤\"></a>部署步骤</h2><h3 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h3><p>每次部署的步骤，可按以下三步来进行。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean  </span><br><span class=\"line\">hexo generate  </span><br><span class=\"line\">hexo deploy</span><br></pre></td></tr></table></figure>\n<p>还可以将上面的3个命令封装成一个shell脚本（publish.sh），放在Hexo对应的目录下方便上传部署。</p>\n<h3 id=\"一些常用命令：\"><a href=\"#一些常用命令：\" class=\"headerlink\" title=\"一些常用命令：\"></a>一些常用命令：</h3><p>hexo new “postName”&emsp;&emsp;&emsp;//新建文章<br>hexo new page “pageName”&emsp;&emsp;&emsp;//新建页面<br>hexo generate&emsp;&emsp;&emsp;//生成静态页面至public目录<br>hexo server&emsp;&emsp;&emsp;//开启预览访问端口（默认端口4000，’ctrl + c’关闭server）<br>hexo deploy&emsp;&emsp;&emsp;//将Hexo部署到GitHub<br>hexo help&emsp;&emsp;&emsp;//查看帮助<br>hexo version&emsp;&emsp;&emsp;//查看Hexo的版本<br>&amp;emsp\\;&amp;emsp\\;&emsp;&emsp;&emsp;//段落前空两格(为了显示，没有转移符)<br>&lt;!--more-->&emsp;&emsp;&emsp;//用于文章的隔断，显示更多<br>[iOS,WebRTC,直播,FFMpeg]&emsp;&emsp;&emsp;//用于写文章时增加tag</p>\n<h3 id=\"一些基本路径\"><a href=\"#一些基本路径\" class=\"headerlink\" title=\"一些基本路径\"></a>一些基本路径</h3><p>文章在source/_posts下，支持Markdown语法，可以用Markdown编辑器进行编辑，如果想修改头像可以直接在主题的_config.yml文件里面修改，友情链接之类的都在这里，开始打理你的博客吧，有什么问题或者建议，都可以提出来，我会继续完善的。  </p>\n<h2 id=\"Markdown语法\"><a href=\"#Markdown语法\" class=\"headerlink\" title=\"Markdown语法\"></a>Markdown语法</h2><p><a href=\"https://www.zybuluo.com/mdeditor\" target=\"_blank\" rel=\"noopener\">实用的Markdown语法例子</a></p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>"},{"title":"iOS判断一个库是否包含bitcode","date":"2016-07-01T06:06:05.000Z","_content":"&emsp;&emsp;苹果在 Xcode 7 中引入了 bitcode，在打包提交时，会包含 bitcode。如果项目用到了以二进制格式发布的第三方库，第三方库也需要包含 bitcode 才行。如果没有包含 bitcode，编译时会报错，除非手动关闭 bitcode 特性。  \n<!--more-->\n&emsp;&emsp;除了通过编译时的报错来判断第三方库是否包含 bitcode，我们也可以自己检查。首先需要判断 library 是否是 fat 的，可以用 lipo 命令：\n\n```\nlipo -info libdemo.a\n```\n\n&emsp;&emsp;其中 libdemo.a 就是我们要检查的文件。一般第三方库都会发布 fat library 以支持各个 CPU 架构。\n&emsp;&emsp;接着，如果是 fat library，需要将某个 CPU 架构的 slice 提取出来：\n\n```\nlipo -thin arm64 libdemo.a -output libdemo-arm64.a\n```\n\n&emsp;&emsp;这样，我们就将 arm64 这个 slice 提取出来了。接下来我们需要将这个 slice 里面的目标文件解压出来，可以用 ar 命令：\n\n```\nar -x libdemo-arm64.a\n```\n\n&emsp;&emsp;假设我们解压了 libdemo_la-util.o 这个目标文件。最后，我们检查目标文件中，是否包含 __bicode 这个段（segment）：\n\n```\notool -l libdemo_la-util.o | grep bitcode\n```\n\n&emsp;&emsp;如果找到了，说明第三方库是支持 bitcode 的。 \n \n原文链接：http://www.tuicool.com/articles/nMzABvM","source":"_posts/iOS判断一个库是否包含bitcode.md","raw":"---\ntitle: iOS判断一个库是否包含bitcode\ndate: 2016-07-01 14:06:05\ncategories: iOS\ntags: [iOS]\n---\n&emsp;&emsp;苹果在 Xcode 7 中引入了 bitcode，在打包提交时，会包含 bitcode。如果项目用到了以二进制格式发布的第三方库，第三方库也需要包含 bitcode 才行。如果没有包含 bitcode，编译时会报错，除非手动关闭 bitcode 特性。  \n<!--more-->\n&emsp;&emsp;除了通过编译时的报错来判断第三方库是否包含 bitcode，我们也可以自己检查。首先需要判断 library 是否是 fat 的，可以用 lipo 命令：\n\n```\nlipo -info libdemo.a\n```\n\n&emsp;&emsp;其中 libdemo.a 就是我们要检查的文件。一般第三方库都会发布 fat library 以支持各个 CPU 架构。\n&emsp;&emsp;接着，如果是 fat library，需要将某个 CPU 架构的 slice 提取出来：\n\n```\nlipo -thin arm64 libdemo.a -output libdemo-arm64.a\n```\n\n&emsp;&emsp;这样，我们就将 arm64 这个 slice 提取出来了。接下来我们需要将这个 slice 里面的目标文件解压出来，可以用 ar 命令：\n\n```\nar -x libdemo-arm64.a\n```\n\n&emsp;&emsp;假设我们解压了 libdemo_la-util.o 这个目标文件。最后，我们检查目标文件中，是否包含 __bicode 这个段（segment）：\n\n```\notool -l libdemo_la-util.o | grep bitcode\n```\n\n&emsp;&emsp;如果找到了，说明第三方库是支持 bitcode 的。 \n \n原文链接：http://www.tuicool.com/articles/nMzABvM","slug":"iOS判断一个库是否包含bitcode","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh100005n5xf5jc80wsx","content":"<p>&emsp;&emsp;苹果在 Xcode 7 中引入了 bitcode，在打包提交时，会包含 bitcode。如果项目用到了以二进制格式发布的第三方库，第三方库也需要包含 bitcode 才行。如果没有包含 bitcode，编译时会报错，除非手动关闭 bitcode 特性。<br><a id=\"more\"></a><br>&emsp;&emsp;除了通过编译时的报错来判断第三方库是否包含 bitcode，我们也可以自己检查。首先需要判断 library 是否是 fat 的，可以用 lipo 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lipo -info libdemo.a</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;其中 libdemo.a 就是我们要检查的文件。一般第三方库都会发布 fat library 以支持各个 CPU 架构。<br>&emsp;&emsp;接着，如果是 fat library，需要将某个 CPU 架构的 slice 提取出来：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lipo -thin arm64 libdemo.a -output libdemo-arm64.a</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这样，我们就将 arm64 这个 slice 提取出来了。接下来我们需要将这个 slice 里面的目标文件解压出来，可以用 ar 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ar -x libdemo-arm64.a</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;假设我们解压了 libdemo_la-util.o 这个目标文件。最后，我们检查目标文件中，是否包含 __bicode 这个段（segment）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">otool -l libdemo_la-util.o | grep bitcode</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;如果找到了，说明第三方库是支持 bitcode 的。 </p>\n<p>原文链接：<a href=\"http://www.tuicool.com/articles/nMzABvM\" target=\"_blank\" rel=\"noopener\">http://www.tuicool.com/articles/nMzABvM</a></p>\n","site":{"data":{}},"excerpt":"<p>&emsp;&emsp;苹果在 Xcode 7 中引入了 bitcode，在打包提交时，会包含 bitcode。如果项目用到了以二进制格式发布的第三方库，第三方库也需要包含 bitcode 才行。如果没有包含 bitcode，编译时会报错，除非手动关闭 bitcode 特性。<br>","more":"<br>&emsp;&emsp;除了通过编译时的报错来判断第三方库是否包含 bitcode，我们也可以自己检查。首先需要判断 library 是否是 fat 的，可以用 lipo 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lipo -info libdemo.a</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;其中 libdemo.a 就是我们要检查的文件。一般第三方库都会发布 fat library 以支持各个 CPU 架构。<br>&emsp;&emsp;接着，如果是 fat library，需要将某个 CPU 架构的 slice 提取出来：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lipo -thin arm64 libdemo.a -output libdemo-arm64.a</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这样，我们就将 arm64 这个 slice 提取出来了。接下来我们需要将这个 slice 里面的目标文件解压出来，可以用 ar 命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ar -x libdemo-arm64.a</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;假设我们解压了 libdemo_la-util.o 这个目标文件。最后，我们检查目标文件中，是否包含 __bicode 这个段（segment）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">otool -l libdemo_la-util.o | grep bitcode</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;如果找到了，说明第三方库是支持 bitcode 的。 </p>\n<p>原文链接：<a href=\"http://www.tuicool.com/articles/nMzABvM\" target=\"_blank\" rel=\"noopener\">http://www.tuicool.com/articles/nMzABvM</a></p>"},{"title":"iOS播放动态gif图片","date":"2016-06-20T06:05:55.000Z","_content":"&emsp;&emsp;图片分为静态和动态两种，图片的格式有很多种，在开发中比较常见的是.png和.jpg的静态图片，但有的时候在App中需要播放动态图片，比如.gif格式的小表情头像，在IOS中并没有提供直接显示动态图片的控件，下面就介绍几种显示动态图片的方式。\n<!--more-->\n### 一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\n\n``` \n// 创建UIImageView，添加到界面 \nUIImageView *imageView = [[UIImageView alloc] initWithFrame:CGRectMake(20, 20, 100, 100)];\n[self.view addSubview:imageView]; \n//\n// 创建一个数组，数组中按顺序添加要播放的图片（图片为静态的图片） \nNSMutableArray *imgArray = [NSMutableArray array]; \nfor (int i=1; i<7; i++) { \n    UIImage *image = [UIImage imageNamed:[NSString stringWithFormat:@\"clock%02d.png\",i]]; \n    [imgArray addObject:image]; \n} \n// 把存有UIImage的数组赋给动画图片数组 imageView.animationImages = imgArray; \n// 设置执行一次完整动画的时长\n imageView.animationDuration = 6*0.15; \n// 动画重复次数 （0为重复播放） imageView.animationRepeatCount = 0; \n// 开始播放动画  [imageView startAnimating]; \n// 停止播放动画 - (void)stopAnimating; \n// 判断是否正在执行动画 - (BOOL)isAnimating;\n```\n\n## 二、用UIWebView来显示动态图片\n\n``` \n// 得到图片的路径 \nNSString *path = [[NSBundle mainBundle] pathForResource:@\"happy\" ofType:@\"gif\"]; \n// 将图片转为NSData \nNSData *gifData = [NSData dataWithContentsOfFile:path]; \n// 创建一个webView，添加到界面 \nUIWebView *webView = [[UIWebView alloc] initWithFrame:CGRectMake(0, 150, 200, 200)]; \n[self.view addSubview:webView]; \n// 自动调整尺寸 \nwebView.scalesPageToFit = YES;\n// 禁止滚动\nwebView.scrollView.scrollEnabled = NO; \n// 设置透明效果 \nwebView.backgroundColor = [UIColor clearColor];webView.opaque = 0; \n// 加载数据 \n[webView loadData:gifData MIMEType:@\"image/gif\" textEncodingName:nil baseURL:nil];\n```\n\n## 三、使用第三方FLAnimatedImage\n\n```\nFLAnimatedImage *image = [FLAnimatedImage animatedImageWithGIFData:[NSData dataWithContentsOfURL:[NSURL URLWithString:@\"https://upload.wikimedia.org/wikipedia/commons/2/2c/Rotating_earth_%28large%29.gif\"]]];\nFLAnimatedImageView *imageView = [[FLAnimatedImageView alloc] init];\nimageView.animatedImage = image;\nimageView.frame = CGRectMake(0.0, 0.0, 100.0, 100.0);\n[self.view addSubview:imageView];\n```\n\n## 四、总结\n1、通过UIImageView显示动画效果，实际上是把动态的图拆成了一组静态的图，放到数组中，播放的时候依次从数组中取出。如果播放的图片比较少占得内存比较小或者比较常用（比如工具条上一直显示的动态小图标），可以选择用imageNamed：方式获取图片，但是通过这种方式加到内存中，使用结束，不会自己释放，多次播放动画会造成内存溢出问题。因此，对于大图或经常更换的图，在取图片的时候可以选择imageWithContentsOfFile:方式获取图片，优化内存。  \n2、使用UIWebView显示图片需要注意显示图片的尺寸与UIWebView尺寸的设置，如果只是为了显示动态图片，可以禁止UIWebView滚动。在显示动态图片的时候，即使是动图的背景处为透明，默认显示出来是白色背景，这个时候需要手动设置UIWebView的透明才能达到显示动图背景透明的效果。  \n3、UIImageView与第三方的FLAnimatedImage都是通过定时器来控制图片模拟的动画，播放的时候是设置每一帧的时长，因此在使用的时候，要尽量与动图原本的时长靠近，不然动画效果会有些奇怪。而通过UIWebView加载Gif动图的时候会保持原有的帧速，不需要再次设置。\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","source":"_posts/iOS播放动态gif图片.md","raw":"---\ntitle: iOS播放动态gif图片\ndate: 2016-06-20 14:05:55\ncategories: iOS\ntags: [iOS]\n---\n&emsp;&emsp;图片分为静态和动态两种，图片的格式有很多种，在开发中比较常见的是.png和.jpg的静态图片，但有的时候在App中需要播放动态图片，比如.gif格式的小表情头像，在IOS中并没有提供直接显示动态图片的控件，下面就介绍几种显示动态图片的方式。\n<!--more-->\n### 一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\n\n``` \n// 创建UIImageView，添加到界面 \nUIImageView *imageView = [[UIImageView alloc] initWithFrame:CGRectMake(20, 20, 100, 100)];\n[self.view addSubview:imageView]; \n//\n// 创建一个数组，数组中按顺序添加要播放的图片（图片为静态的图片） \nNSMutableArray *imgArray = [NSMutableArray array]; \nfor (int i=1; i<7; i++) { \n    UIImage *image = [UIImage imageNamed:[NSString stringWithFormat:@\"clock%02d.png\",i]]; \n    [imgArray addObject:image]; \n} \n// 把存有UIImage的数组赋给动画图片数组 imageView.animationImages = imgArray; \n// 设置执行一次完整动画的时长\n imageView.animationDuration = 6*0.15; \n// 动画重复次数 （0为重复播放） imageView.animationRepeatCount = 0; \n// 开始播放动画  [imageView startAnimating]; \n// 停止播放动画 - (void)stopAnimating; \n// 判断是否正在执行动画 - (BOOL)isAnimating;\n```\n\n## 二、用UIWebView来显示动态图片\n\n``` \n// 得到图片的路径 \nNSString *path = [[NSBundle mainBundle] pathForResource:@\"happy\" ofType:@\"gif\"]; \n// 将图片转为NSData \nNSData *gifData = [NSData dataWithContentsOfFile:path]; \n// 创建一个webView，添加到界面 \nUIWebView *webView = [[UIWebView alloc] initWithFrame:CGRectMake(0, 150, 200, 200)]; \n[self.view addSubview:webView]; \n// 自动调整尺寸 \nwebView.scalesPageToFit = YES;\n// 禁止滚动\nwebView.scrollView.scrollEnabled = NO; \n// 设置透明效果 \nwebView.backgroundColor = [UIColor clearColor];webView.opaque = 0; \n// 加载数据 \n[webView loadData:gifData MIMEType:@\"image/gif\" textEncodingName:nil baseURL:nil];\n```\n\n## 三、使用第三方FLAnimatedImage\n\n```\nFLAnimatedImage *image = [FLAnimatedImage animatedImageWithGIFData:[NSData dataWithContentsOfURL:[NSURL URLWithString:@\"https://upload.wikimedia.org/wikipedia/commons/2/2c/Rotating_earth_%28large%29.gif\"]]];\nFLAnimatedImageView *imageView = [[FLAnimatedImageView alloc] init];\nimageView.animatedImage = image;\nimageView.frame = CGRectMake(0.0, 0.0, 100.0, 100.0);\n[self.view addSubview:imageView];\n```\n\n## 四、总结\n1、通过UIImageView显示动画效果，实际上是把动态的图拆成了一组静态的图，放到数组中，播放的时候依次从数组中取出。如果播放的图片比较少占得内存比较小或者比较常用（比如工具条上一直显示的动态小图标），可以选择用imageNamed：方式获取图片，但是通过这种方式加到内存中，使用结束，不会自己释放，多次播放动画会造成内存溢出问题。因此，对于大图或经常更换的图，在取图片的时候可以选择imageWithContentsOfFile:方式获取图片，优化内存。  \n2、使用UIWebView显示图片需要注意显示图片的尺寸与UIWebView尺寸的设置，如果只是为了显示动态图片，可以禁止UIWebView滚动。在显示动态图片的时候，即使是动图的背景处为透明，默认显示出来是白色背景，这个时候需要手动设置UIWebView的透明才能达到显示动图背景透明的效果。  \n3、UIImageView与第三方的FLAnimatedImage都是通过定时器来控制图片模拟的动画，播放的时候是设置每一帧的时长，因此在使用的时候，要尽量与动图原本的时长靠近，不然动画效果会有些奇怪。而通过UIWebView加载Gif动图的时候会保持原有的帧速，不需要再次设置。\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","slug":"iOS播放动态gif图片","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh120006n5xficy6axkc","content":"<p>&emsp;&emsp;图片分为静态和动态两种，图片的格式有很多种，在开发中比较常见的是.png和.jpg的静态图片，但有的时候在App中需要播放动态图片，比如.gif格式的小表情头像，在IOS中并没有提供直接显示动态图片的控件，下面就介绍几种显示动态图片的方式。<br><a id=\"more\"></a></p>\n<h3 id=\"一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\"><a href=\"#一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\" class=\"headerlink\" title=\"一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\"></a>一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 创建UIImageView，添加到界面 </span><br><span class=\"line\">UIImageView *imageView = [[UIImageView alloc] initWithFrame:CGRectMake(20, 20, 100, 100)];</span><br><span class=\"line\">[self.view addSubview:imageView]; </span><br><span class=\"line\">//</span><br><span class=\"line\">// 创建一个数组，数组中按顺序添加要播放的图片（图片为静态的图片） </span><br><span class=\"line\">NSMutableArray *imgArray = [NSMutableArray array]; </span><br><span class=\"line\">for (int i=1; i&lt;7; i++) &#123; </span><br><span class=\"line\">    UIImage *image = [UIImage imageNamed:[NSString stringWithFormat:@&quot;clock%02d.png&quot;,i]]; </span><br><span class=\"line\">    [imgArray addObject:image]; </span><br><span class=\"line\">&#125; </span><br><span class=\"line\">// 把存有UIImage的数组赋给动画图片数组 imageView.animationImages = imgArray; </span><br><span class=\"line\">// 设置执行一次完整动画的时长</span><br><span class=\"line\"> imageView.animationDuration = 6*0.15; </span><br><span class=\"line\">// 动画重复次数 （0为重复播放） imageView.animationRepeatCount = 0; </span><br><span class=\"line\">// 开始播放动画  [imageView startAnimating]; </span><br><span class=\"line\">// 停止播放动画 - (void)stopAnimating; </span><br><span class=\"line\">// 判断是否正在执行动画 - (BOOL)isAnimating;</span><br></pre></td></tr></table></figure>\n<h2 id=\"二、用UIWebView来显示动态图片\"><a href=\"#二、用UIWebView来显示动态图片\" class=\"headerlink\" title=\"二、用UIWebView来显示动态图片\"></a>二、用UIWebView来显示动态图片</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 得到图片的路径 </span><br><span class=\"line\">NSString *path = [[NSBundle mainBundle] pathForResource:@&quot;happy&quot; ofType:@&quot;gif&quot;]; </span><br><span class=\"line\">// 将图片转为NSData </span><br><span class=\"line\">NSData *gifData = [NSData dataWithContentsOfFile:path]; </span><br><span class=\"line\">// 创建一个webView，添加到界面 </span><br><span class=\"line\">UIWebView *webView = [[UIWebView alloc] initWithFrame:CGRectMake(0, 150, 200, 200)]; </span><br><span class=\"line\">[self.view addSubview:webView]; </span><br><span class=\"line\">// 自动调整尺寸 </span><br><span class=\"line\">webView.scalesPageToFit = YES;</span><br><span class=\"line\">// 禁止滚动</span><br><span class=\"line\">webView.scrollView.scrollEnabled = NO; </span><br><span class=\"line\">// 设置透明效果 </span><br><span class=\"line\">webView.backgroundColor = [UIColor clearColor];webView.opaque = 0; </span><br><span class=\"line\">// 加载数据 </span><br><span class=\"line\">[webView loadData:gifData MIMEType:@&quot;image/gif&quot; textEncodingName:nil baseURL:nil];</span><br></pre></td></tr></table></figure>\n<h2 id=\"三、使用第三方FLAnimatedImage\"><a href=\"#三、使用第三方FLAnimatedImage\" class=\"headerlink\" title=\"三、使用第三方FLAnimatedImage\"></a>三、使用第三方FLAnimatedImage</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FLAnimatedImage *image = [FLAnimatedImage animatedImageWithGIFData:[NSData dataWithContentsOfURL:[NSURL URLWithString:@&quot;https://upload.wikimedia.org/wikipedia/commons/2/2c/Rotating_earth_%28large%29.gif&quot;]]];</span><br><span class=\"line\">FLAnimatedImageView *imageView = [[FLAnimatedImageView alloc] init];</span><br><span class=\"line\">imageView.animatedImage = image;</span><br><span class=\"line\">imageView.frame = CGRectMake(0.0, 0.0, 100.0, 100.0);</span><br><span class=\"line\">[self.view addSubview:imageView];</span><br></pre></td></tr></table></figure>\n<h2 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h2><p>1、通过UIImageView显示动画效果，实际上是把动态的图拆成了一组静态的图，放到数组中，播放的时候依次从数组中取出。如果播放的图片比较少占得内存比较小或者比较常用（比如工具条上一直显示的动态小图标），可以选择用imageNamed：方式获取图片，但是通过这种方式加到内存中，使用结束，不会自己释放，多次播放动画会造成内存溢出问题。因此，对于大图或经常更换的图，在取图片的时候可以选择imageWithContentsOfFile:方式获取图片，优化内存。<br>2、使用UIWebView显示图片需要注意显示图片的尺寸与UIWebView尺寸的设置，如果只是为了显示动态图片，可以禁止UIWebView滚动。在显示动态图片的时候，即使是动图的背景处为透明，默认显示出来是白色背景，这个时候需要手动设置UIWebView的透明才能达到显示动图背景透明的效果。<br>3、UIImageView与第三方的FLAnimatedImage都是通过定时器来控制图片模拟的动画，播放的时候是设置每一帧的时长，因此在使用的时候，要尽量与动图原本的时长靠近，不然动画效果会有些奇怪。而通过UIWebView加载Gif动图的时候会保持原有的帧速，不需要再次设置。</p>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>\n","site":{"data":{}},"excerpt":"<p>&emsp;&emsp;图片分为静态和动态两种，图片的格式有很多种，在开发中比较常见的是.png和.jpg的静态图片，但有的时候在App中需要播放动态图片，比如.gif格式的小表情头像，在IOS中并没有提供直接显示动态图片的控件，下面就介绍几种显示动态图片的方式。<br>","more":"</p>\n<h3 id=\"一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\"><a href=\"#一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\" class=\"headerlink\" title=\"一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果\"></a>一、UIImageView用来显示图片，使用UIImageView中的动画数组来实现图片的动画效果</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 创建UIImageView，添加到界面 </span><br><span class=\"line\">UIImageView *imageView = [[UIImageView alloc] initWithFrame:CGRectMake(20, 20, 100, 100)];</span><br><span class=\"line\">[self.view addSubview:imageView]; </span><br><span class=\"line\">//</span><br><span class=\"line\">// 创建一个数组，数组中按顺序添加要播放的图片（图片为静态的图片） </span><br><span class=\"line\">NSMutableArray *imgArray = [NSMutableArray array]; </span><br><span class=\"line\">for (int i=1; i&lt;7; i++) &#123; </span><br><span class=\"line\">    UIImage *image = [UIImage imageNamed:[NSString stringWithFormat:@&quot;clock%02d.png&quot;,i]]; </span><br><span class=\"line\">    [imgArray addObject:image]; </span><br><span class=\"line\">&#125; </span><br><span class=\"line\">// 把存有UIImage的数组赋给动画图片数组 imageView.animationImages = imgArray; </span><br><span class=\"line\">// 设置执行一次完整动画的时长</span><br><span class=\"line\"> imageView.animationDuration = 6*0.15; </span><br><span class=\"line\">// 动画重复次数 （0为重复播放） imageView.animationRepeatCount = 0; </span><br><span class=\"line\">// 开始播放动画  [imageView startAnimating]; </span><br><span class=\"line\">// 停止播放动画 - (void)stopAnimating; </span><br><span class=\"line\">// 判断是否正在执行动画 - (BOOL)isAnimating;</span><br></pre></td></tr></table></figure>\n<h2 id=\"二、用UIWebView来显示动态图片\"><a href=\"#二、用UIWebView来显示动态图片\" class=\"headerlink\" title=\"二、用UIWebView来显示动态图片\"></a>二、用UIWebView来显示动态图片</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 得到图片的路径 </span><br><span class=\"line\">NSString *path = [[NSBundle mainBundle] pathForResource:@&quot;happy&quot; ofType:@&quot;gif&quot;]; </span><br><span class=\"line\">// 将图片转为NSData </span><br><span class=\"line\">NSData *gifData = [NSData dataWithContentsOfFile:path]; </span><br><span class=\"line\">// 创建一个webView，添加到界面 </span><br><span class=\"line\">UIWebView *webView = [[UIWebView alloc] initWithFrame:CGRectMake(0, 150, 200, 200)]; </span><br><span class=\"line\">[self.view addSubview:webView]; </span><br><span class=\"line\">// 自动调整尺寸 </span><br><span class=\"line\">webView.scalesPageToFit = YES;</span><br><span class=\"line\">// 禁止滚动</span><br><span class=\"line\">webView.scrollView.scrollEnabled = NO; </span><br><span class=\"line\">// 设置透明效果 </span><br><span class=\"line\">webView.backgroundColor = [UIColor clearColor];webView.opaque = 0; </span><br><span class=\"line\">// 加载数据 </span><br><span class=\"line\">[webView loadData:gifData MIMEType:@&quot;image/gif&quot; textEncodingName:nil baseURL:nil];</span><br></pre></td></tr></table></figure>\n<h2 id=\"三、使用第三方FLAnimatedImage\"><a href=\"#三、使用第三方FLAnimatedImage\" class=\"headerlink\" title=\"三、使用第三方FLAnimatedImage\"></a>三、使用第三方FLAnimatedImage</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FLAnimatedImage *image = [FLAnimatedImage animatedImageWithGIFData:[NSData dataWithContentsOfURL:[NSURL URLWithString:@&quot;https://upload.wikimedia.org/wikipedia/commons/2/2c/Rotating_earth_%28large%29.gif&quot;]]];</span><br><span class=\"line\">FLAnimatedImageView *imageView = [[FLAnimatedImageView alloc] init];</span><br><span class=\"line\">imageView.animatedImage = image;</span><br><span class=\"line\">imageView.frame = CGRectMake(0.0, 0.0, 100.0, 100.0);</span><br><span class=\"line\">[self.view addSubview:imageView];</span><br></pre></td></tr></table></figure>\n<h2 id=\"四、总结\"><a href=\"#四、总结\" class=\"headerlink\" title=\"四、总结\"></a>四、总结</h2><p>1、通过UIImageView显示动画效果，实际上是把动态的图拆成了一组静态的图，放到数组中，播放的时候依次从数组中取出。如果播放的图片比较少占得内存比较小或者比较常用（比如工具条上一直显示的动态小图标），可以选择用imageNamed：方式获取图片，但是通过这种方式加到内存中，使用结束，不会自己释放，多次播放动画会造成内存溢出问题。因此，对于大图或经常更换的图，在取图片的时候可以选择imageWithContentsOfFile:方式获取图片，优化内存。<br>2、使用UIWebView显示图片需要注意显示图片的尺寸与UIWebView尺寸的设置，如果只是为了显示动态图片，可以禁止UIWebView滚动。在显示动态图片的时候，即使是动图的背景处为透明，默认显示出来是白色背景，这个时候需要手动设置UIWebView的透明才能达到显示动图背景透明的效果。<br>3、UIImageView与第三方的FLAnimatedImage都是通过定时器来控制图片模拟的动画，播放的时候是设置每一帧的时长，因此在使用的时候，要尽量与动图原本的时长靠近，不然动画效果会有些奇怪。而通过UIWebView加载Gif动图的时候会保持原有的帧速，不需要再次设置。</p>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>"},{"title":"iOS直播技术分享-直播播放器（六）","date":"2016-10-25T06:07:25.000Z","_content":"随着互联网技术的飞速发展，移动端播放视频的需求如日中天，由此也催生了一批开源、闭源的播放器，但是无论这个播放器功能是否强大、兼容性是否优秀，它的基本模块通常都是由以下部分组成：事务处理、数据的接收和解复用、音视频解码以及渲染，其基本框架如下图所示：\n<!--more-->\n![直播技术流程](http://7xk4rv.com1.z0.glb.clouddn.com/iOS%E7%9B%B4%E6%92%AD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%9B%B4%E6%92%AD%E6%92%AD%E6%94%BE%E5%99%A8%EF%BC%88%E5%85%AD%EF%BC%89_1.png)\n针对各种铺天盖地的播放器项目，选取了比较出众的ijkplayer进行源码剖析。它是一个基于FFPlay的轻量级Android/iOS视频播放器，实现了跨平台的功能，API易于集成；编译配置可裁剪，方便控制安装包大小。\n\n# 总体说明\n打开ijkplayer，可看到其主要目录结构如下:\n\ntool - 初始化项目工程脚本\nconfig - 编译ffmpeg使用的配置文件\nextra - 存放编译ijkplayer所需的依赖源文件, 如ffmpeg、openssl等\nijkmedia - 核心代码\n&emsp;&emsp;ijkplayer - 播放器数据下载及解码相关\n&emsp;&emsp;ijksdl - 音视频数据渲染相关\nios - iOS平台上的上层接口封装以及平台相关方法\nandroid - android平台上的上层接口封装以及平台相关方法\n\n# 初始化流程\n初始化完成的主要工作就是创建播放器对象，打开ijkplayer/ios/IJKMediaDemo/IJKMediaDemo.xcodeproj工程，可看到IJKMoviePlayerViewController类中viewDidLoad方法中创建了IJKFFMoviePlayerController对象，即iOS平台上的播放器对象。\n\n```\n- (void)viewDidLoad\n{\n    ......\n    self.player = [[IJKFFMoviePlayerController alloc] initWithContentURL:self.url withOptions:options];\n    ......\n}\n```","source":"_posts/iOS直播技术分享-直播播放器（六）.md","raw":"---\ntitle: iOS直播技术分享-直播播放器（六）\ndate: 2016-10-25 14:07:25\ncategories: 音视频\ntags: [音视频]\n---\n随着互联网技术的飞速发展，移动端播放视频的需求如日中天，由此也催生了一批开源、闭源的播放器，但是无论这个播放器功能是否强大、兼容性是否优秀，它的基本模块通常都是由以下部分组成：事务处理、数据的接收和解复用、音视频解码以及渲染，其基本框架如下图所示：\n<!--more-->\n![直播技术流程](http://7xk4rv.com1.z0.glb.clouddn.com/iOS%E7%9B%B4%E6%92%AD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%9B%B4%E6%92%AD%E6%92%AD%E6%94%BE%E5%99%A8%EF%BC%88%E5%85%AD%EF%BC%89_1.png)\n针对各种铺天盖地的播放器项目，选取了比较出众的ijkplayer进行源码剖析。它是一个基于FFPlay的轻量级Android/iOS视频播放器，实现了跨平台的功能，API易于集成；编译配置可裁剪，方便控制安装包大小。\n\n# 总体说明\n打开ijkplayer，可看到其主要目录结构如下:\n\ntool - 初始化项目工程脚本\nconfig - 编译ffmpeg使用的配置文件\nextra - 存放编译ijkplayer所需的依赖源文件, 如ffmpeg、openssl等\nijkmedia - 核心代码\n&emsp;&emsp;ijkplayer - 播放器数据下载及解码相关\n&emsp;&emsp;ijksdl - 音视频数据渲染相关\nios - iOS平台上的上层接口封装以及平台相关方法\nandroid - android平台上的上层接口封装以及平台相关方法\n\n# 初始化流程\n初始化完成的主要工作就是创建播放器对象，打开ijkplayer/ios/IJKMediaDemo/IJKMediaDemo.xcodeproj工程，可看到IJKMoviePlayerViewController类中viewDidLoad方法中创建了IJKFFMoviePlayerController对象，即iOS平台上的播放器对象。\n\n```\n- (void)viewDidLoad\n{\n    ......\n    self.player = [[IJKFFMoviePlayerController alloc] initWithContentURL:self.url withOptions:options];\n    ......\n}\n```","slug":"iOS直播技术分享-直播播放器（六）","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh16000an5xfc2v4w1a7","content":"<p>随着互联网技术的飞速发展，移动端播放视频的需求如日中天，由此也催生了一批开源、闭源的播放器，但是无论这个播放器功能是否强大、兼容性是否优秀，它的基本模块通常都是由以下部分组成：事务处理、数据的接收和解复用、音视频解码以及渲染，其基本框架如下图所示：<br><a id=\"more\"></a><br><img src=\"http://7xk4rv.com1.z0.glb.clouddn.com/iOS%E7%9B%B4%E6%92%AD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%9B%B4%E6%92%AD%E6%92%AD%E6%94%BE%E5%99%A8%EF%BC%88%E5%85%AD%EF%BC%89_1.png\" alt=\"直播技术流程\"><br>针对各种铺天盖地的播放器项目，选取了比较出众的ijkplayer进行源码剖析。它是一个基于FFPlay的轻量级Android/iOS视频播放器，实现了跨平台的功能，API易于集成；编译配置可裁剪，方便控制安装包大小。</p>\n<h1 id=\"总体说明\"><a href=\"#总体说明\" class=\"headerlink\" title=\"总体说明\"></a>总体说明</h1><p>打开ijkplayer，可看到其主要目录结构如下:</p>\n<p>tool - 初始化项目工程脚本<br>config - 编译ffmpeg使用的配置文件<br>extra - 存放编译ijkplayer所需的依赖源文件, 如ffmpeg、openssl等<br>ijkmedia - 核心代码<br>&emsp;&emsp;ijkplayer - 播放器数据下载及解码相关<br>&emsp;&emsp;ijksdl - 音视频数据渲染相关<br>ios - iOS平台上的上层接口封装以及平台相关方法<br>android - android平台上的上层接口封装以及平台相关方法</p>\n<h1 id=\"初始化流程\"><a href=\"#初始化流程\" class=\"headerlink\" title=\"初始化流程\"></a>初始化流程</h1><p>初始化完成的主要工作就是创建播放器对象，打开ijkplayer/ios/IJKMediaDemo/IJKMediaDemo.xcodeproj工程，可看到IJKMoviePlayerViewController类中viewDidLoad方法中创建了IJKFFMoviePlayerController对象，即iOS平台上的播放器对象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)viewDidLoad</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    ......</span><br><span class=\"line\">    self.player = [[IJKFFMoviePlayerController alloc] initWithContentURL:self.url withOptions:options];</span><br><span class=\"line\">    ......</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"<p>随着互联网技术的飞速发展，移动端播放视频的需求如日中天，由此也催生了一批开源、闭源的播放器，但是无论这个播放器功能是否强大、兼容性是否优秀，它的基本模块通常都是由以下部分组成：事务处理、数据的接收和解复用、音视频解码以及渲染，其基本框架如下图所示：<br>","more":"<br><img src=\"http://7xk4rv.com1.z0.glb.clouddn.com/iOS%E7%9B%B4%E6%92%AD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%9B%B4%E6%92%AD%E6%92%AD%E6%94%BE%E5%99%A8%EF%BC%88%E5%85%AD%EF%BC%89_1.png\" alt=\"直播技术流程\"><br>针对各种铺天盖地的播放器项目，选取了比较出众的ijkplayer进行源码剖析。它是一个基于FFPlay的轻量级Android/iOS视频播放器，实现了跨平台的功能，API易于集成；编译配置可裁剪，方便控制安装包大小。</p>\n<h1 id=\"总体说明\"><a href=\"#总体说明\" class=\"headerlink\" title=\"总体说明\"></a>总体说明</h1><p>打开ijkplayer，可看到其主要目录结构如下:</p>\n<p>tool - 初始化项目工程脚本<br>config - 编译ffmpeg使用的配置文件<br>extra - 存放编译ijkplayer所需的依赖源文件, 如ffmpeg、openssl等<br>ijkmedia - 核心代码<br>&emsp;&emsp;ijkplayer - 播放器数据下载及解码相关<br>&emsp;&emsp;ijksdl - 音视频数据渲染相关<br>ios - iOS平台上的上层接口封装以及平台相关方法<br>android - android平台上的上层接口封装以及平台相关方法</p>\n<h1 id=\"初始化流程\"><a href=\"#初始化流程\" class=\"headerlink\" title=\"初始化流程\"></a>初始化流程</h1><p>初始化完成的主要工作就是创建播放器对象，打开ijkplayer/ios/IJKMediaDemo/IJKMediaDemo.xcodeproj工程，可看到IJKMoviePlayerViewController类中viewDidLoad方法中创建了IJKFFMoviePlayerController对象，即iOS平台上的播放器对象。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)viewDidLoad</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    ......</span><br><span class=\"line\">    self.player = [[IJKFFMoviePlayerController alloc] initWithContentURL:self.url withOptions:options];</span><br><span class=\"line\">    ......</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"iOS新的依赖管理工具：Carthage","date":"2016-06-21T06:05:24.000Z","_content":"## 1、什么是[Carthage](https://github.com/Carthage/Carthage)\n* Carthage的目标是用最简单的方式来管理Cocoa第三方框架。\n* 基本的工作流如下：\n  * 创建一个Cartfile文件，包含你希望在项目中使用的框架的列表。\n  * 运行Carthage，将会获取列出的框架并编译它们。\n  * 将编译完成的.framework二进制文件拖拽到你的Xcode项目当中。\n* Carthage编译你的依赖，并提供框架的二进制文件，但你仍然保留对项目的结构和设置的完整控制。Carthage不会自动的修改你的项目文件或编译设置。\n<!--more-->\n\n## 2、Carthage与CocoaPods的不同\n* CocoaPods是已存在很长时间的Cocoa依赖管理器，那么为什么要创建Carthage呢？\n* CocoaPods默认会自动创建并更新你的应用程序和所有依赖的Xcode workspace。Carthage使用xcodebuild来编译框架的二进制文件，但如何集成它们将交由用户自己判断。CocoaPods的方法更易于使用，但Carthage更灵活并且是非侵入性的。\n* Carthage创建的是去中心化的依赖管理器。它没有总项目的列表，这能够减少维护工作并且避免任何中心化带来的问题（如中央服务器宕机）。不过，这样也有一些缺点，就是项目的发现将更困难，用户将依赖于Github的趋势页面或者类似的代码库来寻找项目。\n* CocoaPods项目同时还必须包含一个podspec文件，里面是项目的一些元数据，以及确定项目的编译方式。Carthage使用xcodebuild来编译依赖，而不是将他们集成进一个workspace，因此无需类似的设定文件。不过依赖需要包含自己的Xcode工程文件来描述如何编译。\n* 最后，我们创建Carthage的原因是想要一种尽可能简单的工具（一个只关心本职工作的依赖管理器），而不是取代部分Xcode的功能，或者需要让框架作者做一些额外的工作。CocoaPods提供的一些特性很棒，但由于附加的复杂性，它们将不会被包含在Carthage当中。\n\n## 3、安装Carthage\n* 通过pkg包安装\n  * Carthage提供OS X平台的pkg安装文件，可以从Github的最新[release](https://github.com/Carthage/Carthage/releases)中找到，按照引导一步步安装即可。\n* 通过终端命令安装\n  * 安装brew\n\t安装命令如下：\n\n```\n\tcurl -LsSf http://github.com/mxcl/homebrew/tarball/master | sudo tar xvz -C/usr/local --strip 1\n```\n\n  * 然后执行如下命令获取最新版本：\n\n```\n\tbrew update\n```\n\n  * 安装carthage\n\n```\n\tsudo brew install carthage\n```\n\n  * 卸载的话，命令如下：\n\n```\n\tsudo brew uninstall carthage\n```\n\n## 4、使用Carthage\n* 创建一个Cartfile文件，将你想要使用的框架列在里面\n\t类似于 CocoaPods 中的 Podfile 文件，把需要的包写进去就行了，具体可参阅[官方说明](https://github.com/Carthage/Carthage/blob/master/Documentation/Artifacts.md#cartfile)，如：\n\n```\n\t\\# 必须最低 2.3.1 版本\n\tgithub \"ReactiveCocoa/ReactiveCocoa\" >= 2.3.1\n\n\t\\# 必须 1.x 版本\n\tgithub \"Mantle/Mantle\" ~> 1.0    # (大于或等于 1.0 ，小于 2.0)\n\n\t\\# 必须 0.4.1 版本\n\n\tgithub \"jspahrsummers/libextobjc\" == 0.4.1\n\n\t\\# 使用最新的版本\n\n\tgithub \"jspahrsummers/xcconfigs\"\n\n\t\\# 使用一个私有项目，在 \"development\" 分支\n\tgit \"https://enterprise.local/desktop/git-error-translations.git\" \"development\"\n```\n\n* 运行carthage update，将获取依赖文件到一个Carthage.checkout文件夹，然后编译每个依赖\n* 在项目中引入依赖的 Framkework，只需要在对应Target中的Build Setting中的Framework Search Path项加入以下路径，Xcode 便会自动搜索目录下的Framework（$(SRCROOT)/Carthage/Build/iOS）\n\n![更新carthage](http://upload-images.jianshu.io/upload_images/2014909-e5d64c47efab9c7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","source":"_posts/iOS新的依赖管理工具：Carthage.md","raw":"---\ntitle: iOS新的依赖管理工具：Carthage\ndate: 2016-06-21 14:05:24\ncategories: iOS\ntags: [iOS]\n---\n## 1、什么是[Carthage](https://github.com/Carthage/Carthage)\n* Carthage的目标是用最简单的方式来管理Cocoa第三方框架。\n* 基本的工作流如下：\n  * 创建一个Cartfile文件，包含你希望在项目中使用的框架的列表。\n  * 运行Carthage，将会获取列出的框架并编译它们。\n  * 将编译完成的.framework二进制文件拖拽到你的Xcode项目当中。\n* Carthage编译你的依赖，并提供框架的二进制文件，但你仍然保留对项目的结构和设置的完整控制。Carthage不会自动的修改你的项目文件或编译设置。\n<!--more-->\n\n## 2、Carthage与CocoaPods的不同\n* CocoaPods是已存在很长时间的Cocoa依赖管理器，那么为什么要创建Carthage呢？\n* CocoaPods默认会自动创建并更新你的应用程序和所有依赖的Xcode workspace。Carthage使用xcodebuild来编译框架的二进制文件，但如何集成它们将交由用户自己判断。CocoaPods的方法更易于使用，但Carthage更灵活并且是非侵入性的。\n* Carthage创建的是去中心化的依赖管理器。它没有总项目的列表，这能够减少维护工作并且避免任何中心化带来的问题（如中央服务器宕机）。不过，这样也有一些缺点，就是项目的发现将更困难，用户将依赖于Github的趋势页面或者类似的代码库来寻找项目。\n* CocoaPods项目同时还必须包含一个podspec文件，里面是项目的一些元数据，以及确定项目的编译方式。Carthage使用xcodebuild来编译依赖，而不是将他们集成进一个workspace，因此无需类似的设定文件。不过依赖需要包含自己的Xcode工程文件来描述如何编译。\n* 最后，我们创建Carthage的原因是想要一种尽可能简单的工具（一个只关心本职工作的依赖管理器），而不是取代部分Xcode的功能，或者需要让框架作者做一些额外的工作。CocoaPods提供的一些特性很棒，但由于附加的复杂性，它们将不会被包含在Carthage当中。\n\n## 3、安装Carthage\n* 通过pkg包安装\n  * Carthage提供OS X平台的pkg安装文件，可以从Github的最新[release](https://github.com/Carthage/Carthage/releases)中找到，按照引导一步步安装即可。\n* 通过终端命令安装\n  * 安装brew\n\t安装命令如下：\n\n```\n\tcurl -LsSf http://github.com/mxcl/homebrew/tarball/master | sudo tar xvz -C/usr/local --strip 1\n```\n\n  * 然后执行如下命令获取最新版本：\n\n```\n\tbrew update\n```\n\n  * 安装carthage\n\n```\n\tsudo brew install carthage\n```\n\n  * 卸载的话，命令如下：\n\n```\n\tsudo brew uninstall carthage\n```\n\n## 4、使用Carthage\n* 创建一个Cartfile文件，将你想要使用的框架列在里面\n\t类似于 CocoaPods 中的 Podfile 文件，把需要的包写进去就行了，具体可参阅[官方说明](https://github.com/Carthage/Carthage/blob/master/Documentation/Artifacts.md#cartfile)，如：\n\n```\n\t\\# 必须最低 2.3.1 版本\n\tgithub \"ReactiveCocoa/ReactiveCocoa\" >= 2.3.1\n\n\t\\# 必须 1.x 版本\n\tgithub \"Mantle/Mantle\" ~> 1.0    # (大于或等于 1.0 ，小于 2.0)\n\n\t\\# 必须 0.4.1 版本\n\n\tgithub \"jspahrsummers/libextobjc\" == 0.4.1\n\n\t\\# 使用最新的版本\n\n\tgithub \"jspahrsummers/xcconfigs\"\n\n\t\\# 使用一个私有项目，在 \"development\" 分支\n\tgit \"https://enterprise.local/desktop/git-error-translations.git\" \"development\"\n```\n\n* 运行carthage update，将获取依赖文件到一个Carthage.checkout文件夹，然后编译每个依赖\n* 在项目中引入依赖的 Framkework，只需要在对应Target中的Build Setting中的Framework Search Path项加入以下路径，Xcode 便会自动搜索目录下的Framework（$(SRCROOT)/Carthage/Build/iOS）\n\n![更新carthage](http://upload-images.jianshu.io/upload_images/2014909-e5d64c47efab9c7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","slug":"iOS新的依赖管理工具：Carthage","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh17000cn5xfxqlrmiyn","content":"<h2 id=\"1、什么是Carthage\"><a href=\"#1、什么是Carthage\" class=\"headerlink\" title=\"1、什么是Carthage\"></a>1、什么是<a href=\"https://github.com/Carthage/Carthage\" target=\"_blank\" rel=\"noopener\">Carthage</a></h2><ul>\n<li>Carthage的目标是用最简单的方式来管理Cocoa第三方框架。</li>\n<li>基本的工作流如下：<ul>\n<li>创建一个Cartfile文件，包含你希望在项目中使用的框架的列表。</li>\n<li>运行Carthage，将会获取列出的框架并编译它们。</li>\n<li>将编译完成的.framework二进制文件拖拽到你的Xcode项目当中。</li>\n</ul>\n</li>\n<li>Carthage编译你的依赖，并提供框架的二进制文件，但你仍然保留对项目的结构和设置的完整控制。Carthage不会自动的修改你的项目文件或编译设置。<a id=\"more\"></a>\n</li>\n</ul>\n<h2 id=\"2、Carthage与CocoaPods的不同\"><a href=\"#2、Carthage与CocoaPods的不同\" class=\"headerlink\" title=\"2、Carthage与CocoaPods的不同\"></a>2、Carthage与CocoaPods的不同</h2><ul>\n<li>CocoaPods是已存在很长时间的Cocoa依赖管理器，那么为什么要创建Carthage呢？</li>\n<li>CocoaPods默认会自动创建并更新你的应用程序和所有依赖的Xcode workspace。Carthage使用xcodebuild来编译框架的二进制文件，但如何集成它们将交由用户自己判断。CocoaPods的方法更易于使用，但Carthage更灵活并且是非侵入性的。</li>\n<li>Carthage创建的是去中心化的依赖管理器。它没有总项目的列表，这能够减少维护工作并且避免任何中心化带来的问题（如中央服务器宕机）。不过，这样也有一些缺点，就是项目的发现将更困难，用户将依赖于Github的趋势页面或者类似的代码库来寻找项目。</li>\n<li>CocoaPods项目同时还必须包含一个podspec文件，里面是项目的一些元数据，以及确定项目的编译方式。Carthage使用xcodebuild来编译依赖，而不是将他们集成进一个workspace，因此无需类似的设定文件。不过依赖需要包含自己的Xcode工程文件来描述如何编译。</li>\n<li>最后，我们创建Carthage的原因是想要一种尽可能简单的工具（一个只关心本职工作的依赖管理器），而不是取代部分Xcode的功能，或者需要让框架作者做一些额外的工作。CocoaPods提供的一些特性很棒，但由于附加的复杂性，它们将不会被包含在Carthage当中。</li>\n</ul>\n<h2 id=\"3、安装Carthage\"><a href=\"#3、安装Carthage\" class=\"headerlink\" title=\"3、安装Carthage\"></a>3、安装Carthage</h2><ul>\n<li>通过pkg包安装<ul>\n<li>Carthage提供OS X平台的pkg安装文件，可以从Github的最新<a href=\"https://github.com/Carthage/Carthage/releases\" target=\"_blank\" rel=\"noopener\">release</a>中找到，按照引导一步步安装即可。</li>\n</ul>\n</li>\n<li>通过终端命令安装<ul>\n<li>安装brew<br>安装命令如下：</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -LsSf http://github.com/mxcl/homebrew/tarball/master | sudo tar xvz -C/usr/local --strip 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>然后执行如下命令获取最新版本：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew update</span><br></pre></td></tr></table></figure>\n<ul>\n<li>安装carthage</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo brew install carthage</span><br></pre></td></tr></table></figure>\n<ul>\n<li>卸载的话，命令如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo brew uninstall carthage</span><br></pre></td></tr></table></figure>\n<h2 id=\"4、使用Carthage\"><a href=\"#4、使用Carthage\" class=\"headerlink\" title=\"4、使用Carthage\"></a>4、使用Carthage</h2><ul>\n<li>创建一个Cartfile文件，将你想要使用的框架列在里面<br>  类似于 CocoaPods 中的 Podfile 文件，把需要的包写进去就行了，具体可参阅<a href=\"https://github.com/Carthage/Carthage/blob/master/Documentation/Artifacts.md#cartfile\" target=\"_blank\" rel=\"noopener\">官方说明</a>，如：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\# 必须最低 2.3.1 版本</span><br><span class=\"line\">github &quot;ReactiveCocoa/ReactiveCocoa&quot; &gt;= 2.3.1</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 必须 1.x 版本</span><br><span class=\"line\">github &quot;Mantle/Mantle&quot; ~&gt; 1.0    # (大于或等于 1.0 ，小于 2.0)</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 必须 0.4.1 版本</span><br><span class=\"line\"></span><br><span class=\"line\">github &quot;jspahrsummers/libextobjc&quot; == 0.4.1</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 使用最新的版本</span><br><span class=\"line\"></span><br><span class=\"line\">github &quot;jspahrsummers/xcconfigs&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 使用一个私有项目，在 &quot;development&quot; 分支</span><br><span class=\"line\">git &quot;https://enterprise.local/desktop/git-error-translations.git&quot; &quot;development&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>运行carthage update，将获取依赖文件到一个Carthage.checkout文件夹，然后编译每个依赖</li>\n<li>在项目中引入依赖的 Framkework，只需要在对应Target中的Build Setting中的Framework Search Path项加入以下路径，Xcode 便会自动搜索目录下的Framework（$(SRCROOT)/Carthage/Build/iOS）</li>\n</ul>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/2014909-e5d64c47efab9c7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"更新carthage\"></p>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1、什么是Carthage\"><a href=\"#1、什么是Carthage\" class=\"headerlink\" title=\"1、什么是Carthage\"></a>1、什么是<a href=\"https://github.com/Carthage/Carthage\" target=\"_blank\" rel=\"noopener\">Carthage</a></h2><ul>\n<li>Carthage的目标是用最简单的方式来管理Cocoa第三方框架。</li>\n<li>基本的工作流如下：<ul>\n<li>创建一个Cartfile文件，包含你希望在项目中使用的框架的列表。</li>\n<li>运行Carthage，将会获取列出的框架并编译它们。</li>\n<li>将编译完成的.framework二进制文件拖拽到你的Xcode项目当中。</li>\n</ul>\n</li>\n<li>Carthage编译你的依赖，并提供框架的二进制文件，但你仍然保留对项目的结构和设置的完整控制。Carthage不会自动的修改你的项目文件或编译设置。","more":"</li>\n</ul>\n<h2 id=\"2、Carthage与CocoaPods的不同\"><a href=\"#2、Carthage与CocoaPods的不同\" class=\"headerlink\" title=\"2、Carthage与CocoaPods的不同\"></a>2、Carthage与CocoaPods的不同</h2><ul>\n<li>CocoaPods是已存在很长时间的Cocoa依赖管理器，那么为什么要创建Carthage呢？</li>\n<li>CocoaPods默认会自动创建并更新你的应用程序和所有依赖的Xcode workspace。Carthage使用xcodebuild来编译框架的二进制文件，但如何集成它们将交由用户自己判断。CocoaPods的方法更易于使用，但Carthage更灵活并且是非侵入性的。</li>\n<li>Carthage创建的是去中心化的依赖管理器。它没有总项目的列表，这能够减少维护工作并且避免任何中心化带来的问题（如中央服务器宕机）。不过，这样也有一些缺点，就是项目的发现将更困难，用户将依赖于Github的趋势页面或者类似的代码库来寻找项目。</li>\n<li>CocoaPods项目同时还必须包含一个podspec文件，里面是项目的一些元数据，以及确定项目的编译方式。Carthage使用xcodebuild来编译依赖，而不是将他们集成进一个workspace，因此无需类似的设定文件。不过依赖需要包含自己的Xcode工程文件来描述如何编译。</li>\n<li>最后，我们创建Carthage的原因是想要一种尽可能简单的工具（一个只关心本职工作的依赖管理器），而不是取代部分Xcode的功能，或者需要让框架作者做一些额外的工作。CocoaPods提供的一些特性很棒，但由于附加的复杂性，它们将不会被包含在Carthage当中。</li>\n</ul>\n<h2 id=\"3、安装Carthage\"><a href=\"#3、安装Carthage\" class=\"headerlink\" title=\"3、安装Carthage\"></a>3、安装Carthage</h2><ul>\n<li>通过pkg包安装<ul>\n<li>Carthage提供OS X平台的pkg安装文件，可以从Github的最新<a href=\"https://github.com/Carthage/Carthage/releases\" target=\"_blank\" rel=\"noopener\">release</a>中找到，按照引导一步步安装即可。</li>\n</ul>\n</li>\n<li>通过终端命令安装<ul>\n<li>安装brew<br>安装命令如下：</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -LsSf http://github.com/mxcl/homebrew/tarball/master | sudo tar xvz -C/usr/local --strip 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>然后执行如下命令获取最新版本：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew update</span><br></pre></td></tr></table></figure>\n<ul>\n<li>安装carthage</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo brew install carthage</span><br></pre></td></tr></table></figure>\n<ul>\n<li>卸载的话，命令如下：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo brew uninstall carthage</span><br></pre></td></tr></table></figure>\n<h2 id=\"4、使用Carthage\"><a href=\"#4、使用Carthage\" class=\"headerlink\" title=\"4、使用Carthage\"></a>4、使用Carthage</h2><ul>\n<li>创建一个Cartfile文件，将你想要使用的框架列在里面<br>  类似于 CocoaPods 中的 Podfile 文件，把需要的包写进去就行了，具体可参阅<a href=\"https://github.com/Carthage/Carthage/blob/master/Documentation/Artifacts.md#cartfile\" target=\"_blank\" rel=\"noopener\">官方说明</a>，如：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\# 必须最低 2.3.1 版本</span><br><span class=\"line\">github &quot;ReactiveCocoa/ReactiveCocoa&quot; &gt;= 2.3.1</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 必须 1.x 版本</span><br><span class=\"line\">github &quot;Mantle/Mantle&quot; ~&gt; 1.0    # (大于或等于 1.0 ，小于 2.0)</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 必须 0.4.1 版本</span><br><span class=\"line\"></span><br><span class=\"line\">github &quot;jspahrsummers/libextobjc&quot; == 0.4.1</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 使用最新的版本</span><br><span class=\"line\"></span><br><span class=\"line\">github &quot;jspahrsummers/xcconfigs&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">\\# 使用一个私有项目，在 &quot;development&quot; 分支</span><br><span class=\"line\">git &quot;https://enterprise.local/desktop/git-error-translations.git&quot; &quot;development&quot;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>运行carthage update，将获取依赖文件到一个Carthage.checkout文件夹，然后编译每个依赖</li>\n<li>在项目中引入依赖的 Framkework，只需要在对应Target中的Build Setting中的Framework Search Path项加入以下路径，Xcode 便会自动搜索目录下的Framework（$(SRCROOT)/Carthage/Build/iOS）</li>\n</ul>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/2014909-e5d64c47efab9c7d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"更新carthage\"></p>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>"},{"title":"iOS直播技术分享-延迟优化（五）","date":"2016-10-25T06:07:10.000Z","_content":"音视频的直播系统是一个复杂的工程系统，要做到非常低延迟的直播，需要复杂的系统工程优化和对各组件非常熟悉的掌握。这里分享几个简单而常用的调优技巧。\n<!--more-->\n## 编码优化\n1、确保 Codec 开启了最低延迟的设置。Codec 一般都会有低延迟优化的开关，对于 H.264 来说其效果尤其明显。很多人可能不知道 H.264 的解码器正常情况下会在显示之前缓存一定的视频帧，对于 QCIF 分辨率大小的视频（176 × 144）一般会缓存 16 帧，对于 720P 的视频则缓存 5 帧。对于第一帧的读取来说，这是一个很大的延迟。如果你的视频不是使用 H.264 来编码压缩的，确保没有使用到 B 帧，它对延迟也会有较大的影响，因为视频中 B 帧的解码依赖于前后的视频帧，会增加延迟。\n2、编码器一般都会有码控造成的延迟，一般也叫做初始化延迟或者视频缓存检验器 VBV 的缓存大小，把它当成编码器和解码器比特流之间的缓存，在不影响视频质量的情况下可以将其设置得尽可能小也可以降低延迟。\n3、如果是仅仅优化首开延迟，可以在视频帧间插入较多的关键帧，这样客户端收到视频流之后可以尽快解码。但如果需要优化传输过程中的累计延迟，尽可能少使用关键帧也就是 I 帧（GOP 变大），在保证同等视频质量的情况下，I 帧越多，码率越大，传输所需的网络带宽越多，也就意味着累计延迟可能越大。这个优化效果可能在秒级延迟的系统中不是很明显，但是在 100 ms 甚至更低延迟的系统中就会非常明显。同时，尽量使用 ACC-LC Codec 来编码音频，HE-ACC 或者 HE-ACC 2 虽然编码效率高，但是编码所需时间更长，而产生更大体积的音频造成的传输延迟对于视频流的传输来说影响更小。\n4、不要使用视频 MJPEG 的视频压缩格式，至少使用不带 B 帧的 MPEG4 视频压缩格式（Simple profile），甚至最好使用 H.264 baseline profile（X264 还有一个「-tune zerolatency」的优化开关）。这样一个简单的优化可以降低延迟，因为它能够以更低的码率编码全帧率视频。\n5、如果使用了 FFmpeg，降低「-probesize 」和「 -analyze duration」参数的值，这两个值用于视频帧信息监测和用于监测的时长，这两个值越大对编码延迟的影响越大，在直播场景下对于视频流来说 analyzeduration 参数甚至没有必要设定。 \n6、固定码率编码 CBR 可以一定程度上消除网络抖动影响，如果能够使用可变码率编码 VBR 可以节省一些不必要的网络带宽，降低一定的延迟。因此建议尽量使用 VBR 进行编码。\n## 传输协议优化\n1、在服务端节点和节点之间尽量使用 RTMP 而非基于 HTTP 的 HLS 协议进行传输，这样可以降低整体的传输延迟。这个主要针对终端用户使用 HLS 进行播放的情况。\n2、如果终端用户使用 RTMP 来播放，尽量在靠近推流端的收流节点进行转码，这样传输的视频流比原始视频流更小。\n3、如果有必要，可以使用定制的 UDP 协议来替换 TCP 协议，省去弱网环节下的丢包重传可以降低延迟。它的主要缺点在于，基于 UDP 协议进行定制的协议的视频流的传输和分发不够通用，CDN 厂商支持的是标准的传输协议。另一个缺点在于可能出现丢包导致的花屏或者模糊（缺少关键帧的解码参考），这就要求协议定制方在 UDP 基础之上做好丢包控制。 \n## 传输网络优化\n1、我们曾经介绍过七牛直播云的实时流传输网络，它是一种新型的节点自组织的网状传输网络，既适合国内多运营商网络条件下的传输优化，也适合众多海外直播的需求。\n2、在服务端节点中缓存当前 GOP，配合播放器端优化视频首开时间。\n3、服务端实时记录每个视频流流向每个环节时的秒级帧率和码率，实时监控码率和帧率的波动。\n4、客户端（推流和播放）通过查询服务端准实时获取当前最优节点（5 秒一次），准实时下线当前故障节点和线路。\n## 推流、播放优化\n1、考察发送端系统自带的网络 buffer 大小，系统可能在发送数据之前缓存数据，这个参数的调优也需要找到一个平衡点。\n2、播放端缓存控制对于视频的首开延迟也有较大影响，如果仅优化首开延迟，可以在 0 缓存情况下在数据到达的时候立即解码。但如果在弱网环境下为了消除网络抖动造成的影响，设置一定的缓存也有必要，因此需要在直播的稳定性和首开延迟优化上找到平衡，调整优化缓冲区大小这个值。\n3、播放端动态 buffer 策略，这是上面播放端缓存控制的改进版本。如果只是做 0 缓存和固定大小的缓存之间进行选择找到平衡，最终还是会选择一个固定大小的缓存，这对亿级的移动互联网终端用户来说并不公平，他们不同的网络状况决定了这个固定大小的缓存并不完全合适。因此，我们可以考虑一种「动态 buffer 策略」，在播放器开启的时候采用非常小甚至 0 缓存的策略，通过对下载首片视频的耗时来决定下一个时间片的缓存大小，同时在播放过程中实时监测当前网络，实时调整播放过程中缓存的大小。这样即可做到极低的首开时间，又可能够尽量消除网络抖动造成的影响。\n4、动态码率播放策略。除了动态调整 buffer 大小的策略之外，也可以利用实时监测的网络信息来动态调整播放过程中的码率，在网络带宽不足的情况下降低码率进行播放，减少延迟。\n \n&emsp;&emsp;以上，是在低延迟优化方面的部分技巧。实际上我们优化低延迟的时候并不是只关注「低延迟」，而是在保证其它条件不影响用户体验的情况下尽量做到低延迟，因此它的内容涉及到更多广泛的话题。而视频直播的优化也包含方方面面，这里只分享了其中经过我们实践的部分。随着实践的积累，我们接下来会在线上和线下分享更多关于视频直播甚至点播的优化技巧。\n","source":"_posts/iOS直播技术分享-延迟优化（五）.md","raw":"---\ntitle: iOS直播技术分享-延迟优化（五）\ndate: 2016-10-25 14:07:10\ncategories: 音视频\ntags: [音视频]\n---\n音视频的直播系统是一个复杂的工程系统，要做到非常低延迟的直播，需要复杂的系统工程优化和对各组件非常熟悉的掌握。这里分享几个简单而常用的调优技巧。\n<!--more-->\n## 编码优化\n1、确保 Codec 开启了最低延迟的设置。Codec 一般都会有低延迟优化的开关，对于 H.264 来说其效果尤其明显。很多人可能不知道 H.264 的解码器正常情况下会在显示之前缓存一定的视频帧，对于 QCIF 分辨率大小的视频（176 × 144）一般会缓存 16 帧，对于 720P 的视频则缓存 5 帧。对于第一帧的读取来说，这是一个很大的延迟。如果你的视频不是使用 H.264 来编码压缩的，确保没有使用到 B 帧，它对延迟也会有较大的影响，因为视频中 B 帧的解码依赖于前后的视频帧，会增加延迟。\n2、编码器一般都会有码控造成的延迟，一般也叫做初始化延迟或者视频缓存检验器 VBV 的缓存大小，把它当成编码器和解码器比特流之间的缓存，在不影响视频质量的情况下可以将其设置得尽可能小也可以降低延迟。\n3、如果是仅仅优化首开延迟，可以在视频帧间插入较多的关键帧，这样客户端收到视频流之后可以尽快解码。但如果需要优化传输过程中的累计延迟，尽可能少使用关键帧也就是 I 帧（GOP 变大），在保证同等视频质量的情况下，I 帧越多，码率越大，传输所需的网络带宽越多，也就意味着累计延迟可能越大。这个优化效果可能在秒级延迟的系统中不是很明显，但是在 100 ms 甚至更低延迟的系统中就会非常明显。同时，尽量使用 ACC-LC Codec 来编码音频，HE-ACC 或者 HE-ACC 2 虽然编码效率高，但是编码所需时间更长，而产生更大体积的音频造成的传输延迟对于视频流的传输来说影响更小。\n4、不要使用视频 MJPEG 的视频压缩格式，至少使用不带 B 帧的 MPEG4 视频压缩格式（Simple profile），甚至最好使用 H.264 baseline profile（X264 还有一个「-tune zerolatency」的优化开关）。这样一个简单的优化可以降低延迟，因为它能够以更低的码率编码全帧率视频。\n5、如果使用了 FFmpeg，降低「-probesize 」和「 -analyze duration」参数的值，这两个值用于视频帧信息监测和用于监测的时长，这两个值越大对编码延迟的影响越大，在直播场景下对于视频流来说 analyzeduration 参数甚至没有必要设定。 \n6、固定码率编码 CBR 可以一定程度上消除网络抖动影响，如果能够使用可变码率编码 VBR 可以节省一些不必要的网络带宽，降低一定的延迟。因此建议尽量使用 VBR 进行编码。\n## 传输协议优化\n1、在服务端节点和节点之间尽量使用 RTMP 而非基于 HTTP 的 HLS 协议进行传输，这样可以降低整体的传输延迟。这个主要针对终端用户使用 HLS 进行播放的情况。\n2、如果终端用户使用 RTMP 来播放，尽量在靠近推流端的收流节点进行转码，这样传输的视频流比原始视频流更小。\n3、如果有必要，可以使用定制的 UDP 协议来替换 TCP 协议，省去弱网环节下的丢包重传可以降低延迟。它的主要缺点在于，基于 UDP 协议进行定制的协议的视频流的传输和分发不够通用，CDN 厂商支持的是标准的传输协议。另一个缺点在于可能出现丢包导致的花屏或者模糊（缺少关键帧的解码参考），这就要求协议定制方在 UDP 基础之上做好丢包控制。 \n## 传输网络优化\n1、我们曾经介绍过七牛直播云的实时流传输网络，它是一种新型的节点自组织的网状传输网络，既适合国内多运营商网络条件下的传输优化，也适合众多海外直播的需求。\n2、在服务端节点中缓存当前 GOP，配合播放器端优化视频首开时间。\n3、服务端实时记录每个视频流流向每个环节时的秒级帧率和码率，实时监控码率和帧率的波动。\n4、客户端（推流和播放）通过查询服务端准实时获取当前最优节点（5 秒一次），准实时下线当前故障节点和线路。\n## 推流、播放优化\n1、考察发送端系统自带的网络 buffer 大小，系统可能在发送数据之前缓存数据，这个参数的调优也需要找到一个平衡点。\n2、播放端缓存控制对于视频的首开延迟也有较大影响，如果仅优化首开延迟，可以在 0 缓存情况下在数据到达的时候立即解码。但如果在弱网环境下为了消除网络抖动造成的影响，设置一定的缓存也有必要，因此需要在直播的稳定性和首开延迟优化上找到平衡，调整优化缓冲区大小这个值。\n3、播放端动态 buffer 策略，这是上面播放端缓存控制的改进版本。如果只是做 0 缓存和固定大小的缓存之间进行选择找到平衡，最终还是会选择一个固定大小的缓存，这对亿级的移动互联网终端用户来说并不公平，他们不同的网络状况决定了这个固定大小的缓存并不完全合适。因此，我们可以考虑一种「动态 buffer 策略」，在播放器开启的时候采用非常小甚至 0 缓存的策略，通过对下载首片视频的耗时来决定下一个时间片的缓存大小，同时在播放过程中实时监测当前网络，实时调整播放过程中缓存的大小。这样即可做到极低的首开时间，又可能够尽量消除网络抖动造成的影响。\n4、动态码率播放策略。除了动态调整 buffer 大小的策略之外，也可以利用实时监测的网络信息来动态调整播放过程中的码率，在网络带宽不足的情况下降低码率进行播放，减少延迟。\n \n&emsp;&emsp;以上，是在低延迟优化方面的部分技巧。实际上我们优化低延迟的时候并不是只关注「低延迟」，而是在保证其它条件不影响用户体验的情况下尽量做到低延迟，因此它的内容涉及到更多广泛的话题。而视频直播的优化也包含方方面面，这里只分享了其中经过我们实践的部分。随着实践的积累，我们接下来会在线上和线下分享更多关于视频直播甚至点播的优化技巧。\n","slug":"iOS直播技术分享-延迟优化（五）","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh19000hn5xfpzhm8ftw","content":"<p>音视频的直播系统是一个复杂的工程系统，要做到非常低延迟的直播，需要复杂的系统工程优化和对各组件非常熟悉的掌握。这里分享几个简单而常用的调优技巧。<br><a id=\"more\"></a></p>\n<h2 id=\"编码优化\"><a href=\"#编码优化\" class=\"headerlink\" title=\"编码优化\"></a>编码优化</h2><p>1、确保 Codec 开启了最低延迟的设置。Codec 一般都会有低延迟优化的开关，对于 H.264 来说其效果尤其明显。很多人可能不知道 H.264 的解码器正常情况下会在显示之前缓存一定的视频帧，对于 QCIF 分辨率大小的视频（176 × 144）一般会缓存 16 帧，对于 720P 的视频则缓存 5 帧。对于第一帧的读取来说，这是一个很大的延迟。如果你的视频不是使用 H.264 来编码压缩的，确保没有使用到 B 帧，它对延迟也会有较大的影响，因为视频中 B 帧的解码依赖于前后的视频帧，会增加延迟。<br>2、编码器一般都会有码控造成的延迟，一般也叫做初始化延迟或者视频缓存检验器 VBV 的缓存大小，把它当成编码器和解码器比特流之间的缓存，在不影响视频质量的情况下可以将其设置得尽可能小也可以降低延迟。<br>3、如果是仅仅优化首开延迟，可以在视频帧间插入较多的关键帧，这样客户端收到视频流之后可以尽快解码。但如果需要优化传输过程中的累计延迟，尽可能少使用关键帧也就是 I 帧（GOP 变大），在保证同等视频质量的情况下，I 帧越多，码率越大，传输所需的网络带宽越多，也就意味着累计延迟可能越大。这个优化效果可能在秒级延迟的系统中不是很明显，但是在 100 ms 甚至更低延迟的系统中就会非常明显。同时，尽量使用 ACC-LC Codec 来编码音频，HE-ACC 或者 HE-ACC 2 虽然编码效率高，但是编码所需时间更长，而产生更大体积的音频造成的传输延迟对于视频流的传输来说影响更小。<br>4、不要使用视频 MJPEG 的视频压缩格式，至少使用不带 B 帧的 MPEG4 视频压缩格式（Simple profile），甚至最好使用 H.264 baseline profile（X264 还有一个「-tune zerolatency」的优化开关）。这样一个简单的优化可以降低延迟，因为它能够以更低的码率编码全帧率视频。<br>5、如果使用了 FFmpeg，降低「-probesize 」和「 -analyze duration」参数的值，这两个值用于视频帧信息监测和用于监测的时长，这两个值越大对编码延迟的影响越大，在直播场景下对于视频流来说 analyzeduration 参数甚至没有必要设定。<br>6、固定码率编码 CBR 可以一定程度上消除网络抖动影响，如果能够使用可变码率编码 VBR 可以节省一些不必要的网络带宽，降低一定的延迟。因此建议尽量使用 VBR 进行编码。</p>\n<h2 id=\"传输协议优化\"><a href=\"#传输协议优化\" class=\"headerlink\" title=\"传输协议优化\"></a>传输协议优化</h2><p>1、在服务端节点和节点之间尽量使用 RTMP 而非基于 HTTP 的 HLS 协议进行传输，这样可以降低整体的传输延迟。这个主要针对终端用户使用 HLS 进行播放的情况。<br>2、如果终端用户使用 RTMP 来播放，尽量在靠近推流端的收流节点进行转码，这样传输的视频流比原始视频流更小。<br>3、如果有必要，可以使用定制的 UDP 协议来替换 TCP 协议，省去弱网环节下的丢包重传可以降低延迟。它的主要缺点在于，基于 UDP 协议进行定制的协议的视频流的传输和分发不够通用，CDN 厂商支持的是标准的传输协议。另一个缺点在于可能出现丢包导致的花屏或者模糊（缺少关键帧的解码参考），这就要求协议定制方在 UDP 基础之上做好丢包控制。 </p>\n<h2 id=\"传输网络优化\"><a href=\"#传输网络优化\" class=\"headerlink\" title=\"传输网络优化\"></a>传输网络优化</h2><p>1、我们曾经介绍过七牛直播云的实时流传输网络，它是一种新型的节点自组织的网状传输网络，既适合国内多运营商网络条件下的传输优化，也适合众多海外直播的需求。<br>2、在服务端节点中缓存当前 GOP，配合播放器端优化视频首开时间。<br>3、服务端实时记录每个视频流流向每个环节时的秒级帧率和码率，实时监控码率和帧率的波动。<br>4、客户端（推流和播放）通过查询服务端准实时获取当前最优节点（5 秒一次），准实时下线当前故障节点和线路。</p>\n<h2 id=\"推流、播放优化\"><a href=\"#推流、播放优化\" class=\"headerlink\" title=\"推流、播放优化\"></a>推流、播放优化</h2><p>1、考察发送端系统自带的网络 buffer 大小，系统可能在发送数据之前缓存数据，这个参数的调优也需要找到一个平衡点。<br>2、播放端缓存控制对于视频的首开延迟也有较大影响，如果仅优化首开延迟，可以在 0 缓存情况下在数据到达的时候立即解码。但如果在弱网环境下为了消除网络抖动造成的影响，设置一定的缓存也有必要，因此需要在直播的稳定性和首开延迟优化上找到平衡，调整优化缓冲区大小这个值。<br>3、播放端动态 buffer 策略，这是上面播放端缓存控制的改进版本。如果只是做 0 缓存和固定大小的缓存之间进行选择找到平衡，最终还是会选择一个固定大小的缓存，这对亿级的移动互联网终端用户来说并不公平，他们不同的网络状况决定了这个固定大小的缓存并不完全合适。因此，我们可以考虑一种「动态 buffer 策略」，在播放器开启的时候采用非常小甚至 0 缓存的策略，通过对下载首片视频的耗时来决定下一个时间片的缓存大小，同时在播放过程中实时监测当前网络，实时调整播放过程中缓存的大小。这样即可做到极低的首开时间，又可能够尽量消除网络抖动造成的影响。<br>4、动态码率播放策略。除了动态调整 buffer 大小的策略之外，也可以利用实时监测的网络信息来动态调整播放过程中的码率，在网络带宽不足的情况下降低码率进行播放，减少延迟。</p>\n<p>&emsp;&emsp;以上，是在低延迟优化方面的部分技巧。实际上我们优化低延迟的时候并不是只关注「低延迟」，而是在保证其它条件不影响用户体验的情况下尽量做到低延迟，因此它的内容涉及到更多广泛的话题。而视频直播的优化也包含方方面面，这里只分享了其中经过我们实践的部分。随着实践的积累，我们接下来会在线上和线下分享更多关于视频直播甚至点播的优化技巧。</p>\n","site":{"data":{}},"excerpt":"<p>音视频的直播系统是一个复杂的工程系统，要做到非常低延迟的直播，需要复杂的系统工程优化和对各组件非常熟悉的掌握。这里分享几个简单而常用的调优技巧。<br>","more":"</p>\n<h2 id=\"编码优化\"><a href=\"#编码优化\" class=\"headerlink\" title=\"编码优化\"></a>编码优化</h2><p>1、确保 Codec 开启了最低延迟的设置。Codec 一般都会有低延迟优化的开关，对于 H.264 来说其效果尤其明显。很多人可能不知道 H.264 的解码器正常情况下会在显示之前缓存一定的视频帧，对于 QCIF 分辨率大小的视频（176 × 144）一般会缓存 16 帧，对于 720P 的视频则缓存 5 帧。对于第一帧的读取来说，这是一个很大的延迟。如果你的视频不是使用 H.264 来编码压缩的，确保没有使用到 B 帧，它对延迟也会有较大的影响，因为视频中 B 帧的解码依赖于前后的视频帧，会增加延迟。<br>2、编码器一般都会有码控造成的延迟，一般也叫做初始化延迟或者视频缓存检验器 VBV 的缓存大小，把它当成编码器和解码器比特流之间的缓存，在不影响视频质量的情况下可以将其设置得尽可能小也可以降低延迟。<br>3、如果是仅仅优化首开延迟，可以在视频帧间插入较多的关键帧，这样客户端收到视频流之后可以尽快解码。但如果需要优化传输过程中的累计延迟，尽可能少使用关键帧也就是 I 帧（GOP 变大），在保证同等视频质量的情况下，I 帧越多，码率越大，传输所需的网络带宽越多，也就意味着累计延迟可能越大。这个优化效果可能在秒级延迟的系统中不是很明显，但是在 100 ms 甚至更低延迟的系统中就会非常明显。同时，尽量使用 ACC-LC Codec 来编码音频，HE-ACC 或者 HE-ACC 2 虽然编码效率高，但是编码所需时间更长，而产生更大体积的音频造成的传输延迟对于视频流的传输来说影响更小。<br>4、不要使用视频 MJPEG 的视频压缩格式，至少使用不带 B 帧的 MPEG4 视频压缩格式（Simple profile），甚至最好使用 H.264 baseline profile（X264 还有一个「-tune zerolatency」的优化开关）。这样一个简单的优化可以降低延迟，因为它能够以更低的码率编码全帧率视频。<br>5、如果使用了 FFmpeg，降低「-probesize 」和「 -analyze duration」参数的值，这两个值用于视频帧信息监测和用于监测的时长，这两个值越大对编码延迟的影响越大，在直播场景下对于视频流来说 analyzeduration 参数甚至没有必要设定。<br>6、固定码率编码 CBR 可以一定程度上消除网络抖动影响，如果能够使用可变码率编码 VBR 可以节省一些不必要的网络带宽，降低一定的延迟。因此建议尽量使用 VBR 进行编码。</p>\n<h2 id=\"传输协议优化\"><a href=\"#传输协议优化\" class=\"headerlink\" title=\"传输协议优化\"></a>传输协议优化</h2><p>1、在服务端节点和节点之间尽量使用 RTMP 而非基于 HTTP 的 HLS 协议进行传输，这样可以降低整体的传输延迟。这个主要针对终端用户使用 HLS 进行播放的情况。<br>2、如果终端用户使用 RTMP 来播放，尽量在靠近推流端的收流节点进行转码，这样传输的视频流比原始视频流更小。<br>3、如果有必要，可以使用定制的 UDP 协议来替换 TCP 协议，省去弱网环节下的丢包重传可以降低延迟。它的主要缺点在于，基于 UDP 协议进行定制的协议的视频流的传输和分发不够通用，CDN 厂商支持的是标准的传输协议。另一个缺点在于可能出现丢包导致的花屏或者模糊（缺少关键帧的解码参考），这就要求协议定制方在 UDP 基础之上做好丢包控制。 </p>\n<h2 id=\"传输网络优化\"><a href=\"#传输网络优化\" class=\"headerlink\" title=\"传输网络优化\"></a>传输网络优化</h2><p>1、我们曾经介绍过七牛直播云的实时流传输网络，它是一种新型的节点自组织的网状传输网络，既适合国内多运营商网络条件下的传输优化，也适合众多海外直播的需求。<br>2、在服务端节点中缓存当前 GOP，配合播放器端优化视频首开时间。<br>3、服务端实时记录每个视频流流向每个环节时的秒级帧率和码率，实时监控码率和帧率的波动。<br>4、客户端（推流和播放）通过查询服务端准实时获取当前最优节点（5 秒一次），准实时下线当前故障节点和线路。</p>\n<h2 id=\"推流、播放优化\"><a href=\"#推流、播放优化\" class=\"headerlink\" title=\"推流、播放优化\"></a>推流、播放优化</h2><p>1、考察发送端系统自带的网络 buffer 大小，系统可能在发送数据之前缓存数据，这个参数的调优也需要找到一个平衡点。<br>2、播放端缓存控制对于视频的首开延迟也有较大影响，如果仅优化首开延迟，可以在 0 缓存情况下在数据到达的时候立即解码。但如果在弱网环境下为了消除网络抖动造成的影响，设置一定的缓存也有必要，因此需要在直播的稳定性和首开延迟优化上找到平衡，调整优化缓冲区大小这个值。<br>3、播放端动态 buffer 策略，这是上面播放端缓存控制的改进版本。如果只是做 0 缓存和固定大小的缓存之间进行选择找到平衡，最终还是会选择一个固定大小的缓存，这对亿级的移动互联网终端用户来说并不公平，他们不同的网络状况决定了这个固定大小的缓存并不完全合适。因此，我们可以考虑一种「动态 buffer 策略」，在播放器开启的时候采用非常小甚至 0 缓存的策略，通过对下载首片视频的耗时来决定下一个时间片的缓存大小，同时在播放过程中实时监测当前网络，实时调整播放过程中缓存的大小。这样即可做到极低的首开时间，又可能够尽量消除网络抖动造成的影响。<br>4、动态码率播放策略。除了动态调整 buffer 大小的策略之外，也可以利用实时监测的网络信息来动态调整播放过程中的码率，在网络带宽不足的情况下降低码率进行播放，减少延迟。</p>\n<p>&emsp;&emsp;以上，是在低延迟优化方面的部分技巧。实际上我们优化低延迟的时候并不是只关注「低延迟」，而是在保证其它条件不影响用户体验的情况下尽量做到低延迟，因此它的内容涉及到更多广泛的话题。而视频直播的优化也包含方方面面，这里只分享了其中经过我们实践的部分。随着实践的积累，我们接下来会在线上和线下分享更多关于视频直播甚至点播的优化技巧。</p>"},{"title":"iOS直播技术分享-音频编码（二）","date":"2016-07-11T06:06:35.000Z","_content":"## 音频基础知识\n### PCM格式\npcm是经过话筒录音后直接得到的未经压缩的数据流\n数据大小=采样频率*采样位数*声道*秒数/8\n采样频率一般是44k，位数一般是8位或者16位，声道一般是单声道或者双声道\npcm属于编码格式，就是一串由多个样本值组成的数据流，本身没有任何头信息或者帧的概念。如果不是音频的录制者，光凭一段PCM数据，是没有办法知道它的采样率等信息的。\n<!--more-->\n### AAC格式\n初步了解，AAC文件可以没有文件头，全部由帧序列组成，每个帧由帧头和数据部分组成。帧头包含采样率、声道数、帧长度等，有点类似MP3格式。\n## AAC编码\n### 初始化编码转换器\n\n```\n-(BOOL)createAudioConvert{ //根据输入样本初始化一个编码转换器\n    if (m_converter != nil){\n        return TRUE;\n    }\n    \n    AudioStreamBasicDescription inputFormat = {0};\n    inputFormat.mSampleRate = _configuration.audioSampleRate;\n    inputFormat.mFormatID = kAudioFormatLinearPCM;\n    inputFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;\n    inputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;\n    inputFormat.mFramesPerPacket = 1;\n    inputFormat.mBitsPerChannel = 16;\n    inputFormat.mBytesPerFrame = inputFormat.mBitsPerChannel / 8 * inputFormat.mChannelsPerFrame;\n    inputFormat.mBytesPerPacket = inputFormat.mBytesPerFrame * inputFormat.mFramesPerPacket;\n    \n    AudioStreamBasicDescription outputFormat; // 这里开始是输出音频格式\n    memset(&outputFormat, 0, sizeof(outputFormat));\n    outputFormat.mSampleRate       = inputFormat.mSampleRate; // 采样率保持一致\n    outputFormat.mFormatID         = kAudioFormatMPEG4AAC;    // AAC编码 kAudioFormatMPEG4AAC kAudioFormatMPEG4AAC_HE_V2\n    outputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;;\n    outputFormat.mFramesPerPacket  = 1024;                    // AAC一帧是1024个字节\n    \n    const OSType subtype = kAudioFormatMPEG4AAC;\n    AudioClassDescription requestedCodecs[2] = {\n        {\n            kAudioEncoderComponentType,\n            subtype,\n            kAppleSoftwareAudioCodecManufacturer\n        },\n        {\n            kAudioEncoderComponentType,\n            subtype,\n            kAppleHardwareAudioCodecManufacturer\n        }\n    };\n    OSStatus result = AudioConverterNewSpecific(&inputFormat, &outputFormat, 2, requestedCodecs, &m_converter);\n    \n    \n    if(result != noErr) return NO;\n    \n    return YES;\n}\n```\n\n### 编码转换\n\n```\nchar *aacBuf;\n\nif(!aacBuf){\n        aacBuf = malloc(inBufferList.mBuffers[0].mDataByteSize);\n    }\n    \n    // 初始化一个输出缓冲列表\n    AudioBufferList outBufferList;\n    outBufferList.mNumberBuffers              = 1;\n    outBufferList.mBuffers[0].mNumberChannels = inBufferList.mBuffers[0].mNumberChannels;\n    outBufferList.mBuffers[0].mDataByteSize   = inBufferList.mBuffers[0].mDataByteSize; // 设置缓冲区大小\n    outBufferList.mBuffers[0].mData           = aacBuf; // 设置AAC缓冲区\n    UInt32 outputDataPacketSize               = 1;\n    if (AudioConverterFillComplexBuffer(m_converter, inputDataProc, &inBufferList, &outputDataPacketSize, &outBufferList, NULL) != noErr){\n        return;\n    }\n    AudioFrame *audioFrame = [AudioFrame new];\n    audioFrame.timestamp = timeStamp;\n    audioFrame.data = [NSData dataWithBytes:aacBuf length:outBufferList.mBuffers[0].mDataByteSize];\n\n    char exeData[2];\n    exeData[0] = _configuration.asc[0];\n    exeData[1] = _configuration.asc[1];\n    audioFrame.audioInfo =[NSData dataWithBytes:exeData length:2];\n```\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","source":"_posts/iOS直播技术分享-音频编码（二）.md","raw":"---\ntitle: iOS直播技术分享-音频编码（二）\ndate: 2016-07-11 14:06:35\ncategories: 音视频\ntags: [音视频]\n---\n## 音频基础知识\n### PCM格式\npcm是经过话筒录音后直接得到的未经压缩的数据流\n数据大小=采样频率*采样位数*声道*秒数/8\n采样频率一般是44k，位数一般是8位或者16位，声道一般是单声道或者双声道\npcm属于编码格式，就是一串由多个样本值组成的数据流，本身没有任何头信息或者帧的概念。如果不是音频的录制者，光凭一段PCM数据，是没有办法知道它的采样率等信息的。\n<!--more-->\n### AAC格式\n初步了解，AAC文件可以没有文件头，全部由帧序列组成，每个帧由帧头和数据部分组成。帧头包含采样率、声道数、帧长度等，有点类似MP3格式。\n## AAC编码\n### 初始化编码转换器\n\n```\n-(BOOL)createAudioConvert{ //根据输入样本初始化一个编码转换器\n    if (m_converter != nil){\n        return TRUE;\n    }\n    \n    AudioStreamBasicDescription inputFormat = {0};\n    inputFormat.mSampleRate = _configuration.audioSampleRate;\n    inputFormat.mFormatID = kAudioFormatLinearPCM;\n    inputFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;\n    inputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;\n    inputFormat.mFramesPerPacket = 1;\n    inputFormat.mBitsPerChannel = 16;\n    inputFormat.mBytesPerFrame = inputFormat.mBitsPerChannel / 8 * inputFormat.mChannelsPerFrame;\n    inputFormat.mBytesPerPacket = inputFormat.mBytesPerFrame * inputFormat.mFramesPerPacket;\n    \n    AudioStreamBasicDescription outputFormat; // 这里开始是输出音频格式\n    memset(&outputFormat, 0, sizeof(outputFormat));\n    outputFormat.mSampleRate       = inputFormat.mSampleRate; // 采样率保持一致\n    outputFormat.mFormatID         = kAudioFormatMPEG4AAC;    // AAC编码 kAudioFormatMPEG4AAC kAudioFormatMPEG4AAC_HE_V2\n    outputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;;\n    outputFormat.mFramesPerPacket  = 1024;                    // AAC一帧是1024个字节\n    \n    const OSType subtype = kAudioFormatMPEG4AAC;\n    AudioClassDescription requestedCodecs[2] = {\n        {\n            kAudioEncoderComponentType,\n            subtype,\n            kAppleSoftwareAudioCodecManufacturer\n        },\n        {\n            kAudioEncoderComponentType,\n            subtype,\n            kAppleHardwareAudioCodecManufacturer\n        }\n    };\n    OSStatus result = AudioConverterNewSpecific(&inputFormat, &outputFormat, 2, requestedCodecs, &m_converter);\n    \n    \n    if(result != noErr) return NO;\n    \n    return YES;\n}\n```\n\n### 编码转换\n\n```\nchar *aacBuf;\n\nif(!aacBuf){\n        aacBuf = malloc(inBufferList.mBuffers[0].mDataByteSize);\n    }\n    \n    // 初始化一个输出缓冲列表\n    AudioBufferList outBufferList;\n    outBufferList.mNumberBuffers              = 1;\n    outBufferList.mBuffers[0].mNumberChannels = inBufferList.mBuffers[0].mNumberChannels;\n    outBufferList.mBuffers[0].mDataByteSize   = inBufferList.mBuffers[0].mDataByteSize; // 设置缓冲区大小\n    outBufferList.mBuffers[0].mData           = aacBuf; // 设置AAC缓冲区\n    UInt32 outputDataPacketSize               = 1;\n    if (AudioConverterFillComplexBuffer(m_converter, inputDataProc, &inBufferList, &outputDataPacketSize, &outBufferList, NULL) != noErr){\n        return;\n    }\n    AudioFrame *audioFrame = [AudioFrame new];\n    audioFrame.timestamp = timeStamp;\n    audioFrame.data = [NSData dataWithBytes:aacBuf length:outBufferList.mBuffers[0].mDataByteSize];\n\n    char exeData[2];\n    exeData[0] = _configuration.asc[0];\n    exeData[1] = _configuration.asc[1];\n    audioFrame.audioInfo =[NSData dataWithBytes:exeData length:2];\n```\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","slug":"iOS直播技术分享-音频编码（二）","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1b000kn5xfji36856b","content":"<h2 id=\"音频基础知识\"><a href=\"#音频基础知识\" class=\"headerlink\" title=\"音频基础知识\"></a>音频基础知识</h2><h3 id=\"PCM格式\"><a href=\"#PCM格式\" class=\"headerlink\" title=\"PCM格式\"></a>PCM格式</h3><p>pcm是经过话筒录音后直接得到的未经压缩的数据流<br>数据大小=采样频率<em>采样位数</em>声道*秒数/8<br>采样频率一般是44k，位数一般是8位或者16位，声道一般是单声道或者双声道<br>pcm属于编码格式，就是一串由多个样本值组成的数据流，本身没有任何头信息或者帧的概念。如果不是音频的录制者，光凭一段PCM数据，是没有办法知道它的采样率等信息的。<br><a id=\"more\"></a></p>\n<h3 id=\"AAC格式\"><a href=\"#AAC格式\" class=\"headerlink\" title=\"AAC格式\"></a>AAC格式</h3><p>初步了解，AAC文件可以没有文件头，全部由帧序列组成，每个帧由帧头和数据部分组成。帧头包含采样率、声道数、帧长度等，有点类似MP3格式。</p>\n<h2 id=\"AAC编码\"><a href=\"#AAC编码\" class=\"headerlink\" title=\"AAC编码\"></a>AAC编码</h2><h3 id=\"初始化编码转换器\"><a href=\"#初始化编码转换器\" class=\"headerlink\" title=\"初始化编码转换器\"></a>初始化编码转换器</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-(BOOL)createAudioConvert&#123; //根据输入样本初始化一个编码转换器</span><br><span class=\"line\">    if (m_converter != nil)&#123;</span><br><span class=\"line\">        return TRUE;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    AudioStreamBasicDescription inputFormat = &#123;0&#125;;</span><br><span class=\"line\">    inputFormat.mSampleRate = _configuration.audioSampleRate;</span><br><span class=\"line\">    inputFormat.mFormatID = kAudioFormatLinearPCM;</span><br><span class=\"line\">    inputFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;</span><br><span class=\"line\">    inputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;</span><br><span class=\"line\">    inputFormat.mFramesPerPacket = 1;</span><br><span class=\"line\">    inputFormat.mBitsPerChannel = 16;</span><br><span class=\"line\">    inputFormat.mBytesPerFrame = inputFormat.mBitsPerChannel / 8 * inputFormat.mChannelsPerFrame;</span><br><span class=\"line\">    inputFormat.mBytesPerPacket = inputFormat.mBytesPerFrame * inputFormat.mFramesPerPacket;</span><br><span class=\"line\">    </span><br><span class=\"line\">    AudioStreamBasicDescription outputFormat; // 这里开始是输出音频格式</span><br><span class=\"line\">    memset(&amp;outputFormat, 0, sizeof(outputFormat));</span><br><span class=\"line\">    outputFormat.mSampleRate       = inputFormat.mSampleRate; // 采样率保持一致</span><br><span class=\"line\">    outputFormat.mFormatID         = kAudioFormatMPEG4AAC;    // AAC编码 kAudioFormatMPEG4AAC kAudioFormatMPEG4AAC_HE_V2</span><br><span class=\"line\">    outputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;;</span><br><span class=\"line\">    outputFormat.mFramesPerPacket  = 1024;                    // AAC一帧是1024个字节</span><br><span class=\"line\">    </span><br><span class=\"line\">    const OSType subtype = kAudioFormatMPEG4AAC;</span><br><span class=\"line\">    AudioClassDescription requestedCodecs[2] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            kAudioEncoderComponentType,</span><br><span class=\"line\">            subtype,</span><br><span class=\"line\">            kAppleSoftwareAudioCodecManufacturer</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            kAudioEncoderComponentType,</span><br><span class=\"line\">            subtype,</span><br><span class=\"line\">            kAppleHardwareAudioCodecManufacturer</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    OSStatus result = AudioConverterNewSpecific(&amp;inputFormat, &amp;outputFormat, 2, requestedCodecs, &amp;m_converter);</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    if(result != noErr) return NO;</span><br><span class=\"line\">    </span><br><span class=\"line\">    return YES;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"编码转换\"><a href=\"#编码转换\" class=\"headerlink\" title=\"编码转换\"></a>编码转换</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">char *aacBuf;</span><br><span class=\"line\"></span><br><span class=\"line\">if(!aacBuf)&#123;</span><br><span class=\"line\">        aacBuf = malloc(inBufferList.mBuffers[0].mDataByteSize);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 初始化一个输出缓冲列表</span><br><span class=\"line\">    AudioBufferList outBufferList;</span><br><span class=\"line\">    outBufferList.mNumberBuffers              = 1;</span><br><span class=\"line\">    outBufferList.mBuffers[0].mNumberChannels = inBufferList.mBuffers[0].mNumberChannels;</span><br><span class=\"line\">    outBufferList.mBuffers[0].mDataByteSize   = inBufferList.mBuffers[0].mDataByteSize; // 设置缓冲区大小</span><br><span class=\"line\">    outBufferList.mBuffers[0].mData           = aacBuf; // 设置AAC缓冲区</span><br><span class=\"line\">    UInt32 outputDataPacketSize               = 1;</span><br><span class=\"line\">    if (AudioConverterFillComplexBuffer(m_converter, inputDataProc, &amp;inBufferList, &amp;outputDataPacketSize, &amp;outBufferList, NULL) != noErr)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    AudioFrame *audioFrame = [AudioFrame new];</span><br><span class=\"line\">    audioFrame.timestamp = timeStamp;</span><br><span class=\"line\">    audioFrame.data = [NSData dataWithBytes:aacBuf length:outBufferList.mBuffers[0].mDataByteSize];</span><br><span class=\"line\"></span><br><span class=\"line\">    char exeData[2];</span><br><span class=\"line\">    exeData[0] = _configuration.asc[0];</span><br><span class=\"line\">    exeData[1] = _configuration.asc[1];</span><br><span class=\"line\">    audioFrame.audioInfo =[NSData dataWithBytes:exeData length:2];</span><br></pre></td></tr></table></figure>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"音频基础知识\"><a href=\"#音频基础知识\" class=\"headerlink\" title=\"音频基础知识\"></a>音频基础知识</h2><h3 id=\"PCM格式\"><a href=\"#PCM格式\" class=\"headerlink\" title=\"PCM格式\"></a>PCM格式</h3><p>pcm是经过话筒录音后直接得到的未经压缩的数据流<br>数据大小=采样频率<em>采样位数</em>声道*秒数/8<br>采样频率一般是44k，位数一般是8位或者16位，声道一般是单声道或者双声道<br>pcm属于编码格式，就是一串由多个样本值组成的数据流，本身没有任何头信息或者帧的概念。如果不是音频的录制者，光凭一段PCM数据，是没有办法知道它的采样率等信息的。<br>","more":"</p>\n<h3 id=\"AAC格式\"><a href=\"#AAC格式\" class=\"headerlink\" title=\"AAC格式\"></a>AAC格式</h3><p>初步了解，AAC文件可以没有文件头，全部由帧序列组成，每个帧由帧头和数据部分组成。帧头包含采样率、声道数、帧长度等，有点类似MP3格式。</p>\n<h2 id=\"AAC编码\"><a href=\"#AAC编码\" class=\"headerlink\" title=\"AAC编码\"></a>AAC编码</h2><h3 id=\"初始化编码转换器\"><a href=\"#初始化编码转换器\" class=\"headerlink\" title=\"初始化编码转换器\"></a>初始化编码转换器</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-(BOOL)createAudioConvert&#123; //根据输入样本初始化一个编码转换器</span><br><span class=\"line\">    if (m_converter != nil)&#123;</span><br><span class=\"line\">        return TRUE;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    AudioStreamBasicDescription inputFormat = &#123;0&#125;;</span><br><span class=\"line\">    inputFormat.mSampleRate = _configuration.audioSampleRate;</span><br><span class=\"line\">    inputFormat.mFormatID = kAudioFormatLinearPCM;</span><br><span class=\"line\">    inputFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;</span><br><span class=\"line\">    inputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;</span><br><span class=\"line\">    inputFormat.mFramesPerPacket = 1;</span><br><span class=\"line\">    inputFormat.mBitsPerChannel = 16;</span><br><span class=\"line\">    inputFormat.mBytesPerFrame = inputFormat.mBitsPerChannel / 8 * inputFormat.mChannelsPerFrame;</span><br><span class=\"line\">    inputFormat.mBytesPerPacket = inputFormat.mBytesPerFrame * inputFormat.mFramesPerPacket;</span><br><span class=\"line\">    </span><br><span class=\"line\">    AudioStreamBasicDescription outputFormat; // 这里开始是输出音频格式</span><br><span class=\"line\">    memset(&amp;outputFormat, 0, sizeof(outputFormat));</span><br><span class=\"line\">    outputFormat.mSampleRate       = inputFormat.mSampleRate; // 采样率保持一致</span><br><span class=\"line\">    outputFormat.mFormatID         = kAudioFormatMPEG4AAC;    // AAC编码 kAudioFormatMPEG4AAC kAudioFormatMPEG4AAC_HE_V2</span><br><span class=\"line\">    outputFormat.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;;</span><br><span class=\"line\">    outputFormat.mFramesPerPacket  = 1024;                    // AAC一帧是1024个字节</span><br><span class=\"line\">    </span><br><span class=\"line\">    const OSType subtype = kAudioFormatMPEG4AAC;</span><br><span class=\"line\">    AudioClassDescription requestedCodecs[2] = &#123;</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            kAudioEncoderComponentType,</span><br><span class=\"line\">            subtype,</span><br><span class=\"line\">            kAppleSoftwareAudioCodecManufacturer</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            kAudioEncoderComponentType,</span><br><span class=\"line\">            subtype,</span><br><span class=\"line\">            kAppleHardwareAudioCodecManufacturer</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    OSStatus result = AudioConverterNewSpecific(&amp;inputFormat, &amp;outputFormat, 2, requestedCodecs, &amp;m_converter);</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    if(result != noErr) return NO;</span><br><span class=\"line\">    </span><br><span class=\"line\">    return YES;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"编码转换\"><a href=\"#编码转换\" class=\"headerlink\" title=\"编码转换\"></a>编码转换</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">char *aacBuf;</span><br><span class=\"line\"></span><br><span class=\"line\">if(!aacBuf)&#123;</span><br><span class=\"line\">        aacBuf = malloc(inBufferList.mBuffers[0].mDataByteSize);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 初始化一个输出缓冲列表</span><br><span class=\"line\">    AudioBufferList outBufferList;</span><br><span class=\"line\">    outBufferList.mNumberBuffers              = 1;</span><br><span class=\"line\">    outBufferList.mBuffers[0].mNumberChannels = inBufferList.mBuffers[0].mNumberChannels;</span><br><span class=\"line\">    outBufferList.mBuffers[0].mDataByteSize   = inBufferList.mBuffers[0].mDataByteSize; // 设置缓冲区大小</span><br><span class=\"line\">    outBufferList.mBuffers[0].mData           = aacBuf; // 设置AAC缓冲区</span><br><span class=\"line\">    UInt32 outputDataPacketSize               = 1;</span><br><span class=\"line\">    if (AudioConverterFillComplexBuffer(m_converter, inputDataProc, &amp;inBufferList, &amp;outputDataPacketSize, &amp;outBufferList, NULL) != noErr)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    AudioFrame *audioFrame = [AudioFrame new];</span><br><span class=\"line\">    audioFrame.timestamp = timeStamp;</span><br><span class=\"line\">    audioFrame.data = [NSData dataWithBytes:aacBuf length:outBufferList.mBuffers[0].mDataByteSize];</span><br><span class=\"line\"></span><br><span class=\"line\">    char exeData[2];</span><br><span class=\"line\">    exeData[0] = _configuration.asc[0];</span><br><span class=\"line\">    exeData[1] = _configuration.asc[1];</span><br><span class=\"line\">    audioFrame.audioInfo =[NSData dataWithBytes:exeData length:2];</span><br></pre></td></tr></table></figure>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>"},{"title":"iOS直播技术分享-音视频采集（一）","date":"2016-07-02T06:06:16.000Z","_content":"## 1、iOS直播技术的流程\n&emsp;&emsp;直播技术的流程大致可以分为几个步骤：数据采集、图像处理（实时滤镜）、视频编码、封包、上传、云端（转码、录制、分发）、直播播放器。  \n<!--more-->\n* 数据采集：通过摄像头和麦克风获得实时的音视频数据；  \n* 图像处理：将数据采集的输入流进行实时滤镜，得到我们美化之后的视频帧； \n* 视频编码：编码分为软编码和硬编码。现在一般的编码方式都是H.264，比较新的H.265据说压缩率比较高，但算法也相当要复杂一些，使用还不够广泛。软编码是利用CPU进行编码，硬编码就是使用GPU进行编码，软编码支持现在所有的系统版本，由于苹果在iOS8才开放硬编码的API，故硬编码只支持iOS8以上的系统；  \n* 封包：现在直播推流中，一般采用的格式是FLV；  \n* 上传：常用的协议是利用RTMP协议进行推流；  \n* 云端：进行流的转码、分发和录制；  \n* 直播播放器：负责拉流、解码、播放。\n  \n用一张腾讯云的图来说明上面的流程：  \n![直播技术流程](http://upload-images.jianshu.io/upload_images/2014909-fc4efbc9b1ffdd45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n## 2、获取系统的授权\n直播的第一步就是采集数据，包含视频和音频数据，由于iOS权限的要求，需要先获取访问摄像头和麦克风的权限：\n\n请求获取访问摄像头权限\n\n```\n__weak typeof(self) _self = self;\n    AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo];\n    switch (status) {\n        case AVAuthorizationStatusNotDetermined:{\n            // 许可对话没有出现，发起授权许可\n            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) {\n                if (granted) {\n                    dispatch_async(dispatch_get_main_queue(), ^{\n                        [_self.session setRunning:YES];\n                    });\n                }\n            }];\n            break;\n        }\n        case AVAuthorizationStatusAuthorized:{\n            // 已经开启授权，可继续\n            [_self.session setRunning:YES];\n            break;\n        }\n        case AVAuthorizationStatusDenied:\n        case AVAuthorizationStatusRestricted:\n            // 用户明确地拒绝授权，或者相机设备无法访问\n            break;\n        default:\n            break;\n    }\n```\n\n请求获取访问麦克风权限\n\n```\nAVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeAudio];\n    switch (status) {\n        case AVAuthorizationStatusNotDetermined:{\n            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeAudio completionHandler:^(BOOL granted) {\n            }];\n            break;\n        }\n        case AVAuthorizationStatusAuthorized:{\n            break;\n        }\n        case AVAuthorizationStatusDenied:\n        case AVAuthorizationStatusRestricted:\n            break;\n        default:\n            break;\n    }\n ```\n \n ## 3、配置采样参数\n \n 音频：需要配置码率、采样率；\n 视频：需要配置视频分辨率、视频的帧率、视频的码率。\n \n ## 4、音视频的录制   \n 音频的录制\n \n ```\n self.taskQueue = dispatch_queue_create(\"com.1905.live.audioCapture.Queue\", NULL);\n        \n        AVAudioSession *session = [AVAudioSession sharedInstance];\n        [session setActive:YES withOptions:kAudioSessionSetActiveFlag_NotifyOthersOnDeactivation error:nil];\n        \n        [[NSNotificationCenter defaultCenter] addObserver: self\n                                                 selector: @selector(handleRouteChange:)\n                                                     name: AVAudioSessionRouteChangeNotification\n                                                   object: session];\n        [[NSNotificationCenter defaultCenter] addObserver: self\n                                                 selector: @selector(handleInterruption:)\n                                                     name: AVAudioSessionInterruptionNotification\n                                                   object: session];\n        \n        NSError *error = nil;\n        \n        [session setCategory:AVAudioSessionCategoryPlayAndRecord withOptions:AVAudioSessionCategoryOptionDefaultToSpeaker | AVAudioSessionCategoryOptionMixWithOthers error:nil];\n        \n        [session setMode:AVAudioSessionModeVideoRecording error:&error];\n        \n        if (![session setActive:YES error:&error]) {\n            [self handleAudioComponentCreationFailure];\n        }\n        \n        AudioComponentDescription acd;\n        acd.componentType = kAudioUnitType_Output;\n        acd.componentSubType = kAudioUnitSubType_RemoteIO;\n        acd.componentManufacturer = kAudioUnitManufacturer_Apple;\n        acd.componentFlags = 0;\n        acd.componentFlagsMask = 0;\n        \n        self.component = AudioComponentFindNext(NULL, &acd);\n        \n        OSStatus status = noErr;\n        status = AudioComponentInstanceNew(self.component, &_componetInstance);\n        \n        if (noErr != status) {\n            [self handleAudioComponentCreationFailure];\n        }\n        \n        UInt32 flagOne = 1;\n        \n        AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Input, 1, &flagOne, sizeof(flagOne));\n        \n        AudioStreamBasicDescription desc = {0};\n        desc.mSampleRate = _configuration.audioSampleRate;\n        desc.mFormatID = kAudioFormatLinearPCM;\n        desc.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;\n        desc.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;\n        desc.mFramesPerPacket = 1;\n        desc.mBitsPerChannel = 16;\n        desc.mBytesPerFrame = desc.mBitsPerChannel / 8 * desc.mChannelsPerFrame;\n        desc.mBytesPerPacket = desc.mBytesPerFrame * desc.mFramesPerPacket;\n        \n        AURenderCallbackStruct cb;\n        cb.inputProcRefCon = (__bridge void *)(self);\n        cb.inputProc = handleInputBuffer;\n        status = AudioUnitSetProperty(self.componetInstance, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, &desc, sizeof(desc));\n        status = AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_SetInputCallback, kAudioUnitScope_Global, 1, &cb, sizeof(cb));\n        \n        status = AudioUnitInitialize(self.componetInstance);\n        \n        if (noErr != status) {\n            [self handleAudioComponentCreationFailure];\n        }\n        \n        [session setPreferredSampleRate:_configuration.audioSampleRate error:nil];\n        \n        \n        [session setActive:YES error:nil];\n```\n\n视频的录制：调用GPUImage中的GPUImageVideoCamera\n\n```\n_videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:_configuration.avSessionPreset cameraPosition:AVCaptureDevicePositionFront];\n_videoCamera.outputImageOrientation = _configuration.orientation;\n_videoCamera.horizontallyMirrorFrontFacingCamera = NO;\n_videoCamera.horizontallyMirrorRearFacingCamera = NO;\n_videoCamera.frameRate = (int32_t)_configuration.videoFrameRate;\n        \n_gpuImageView = [[GPUImageView alloc] initWithFrame:[UIScreen mainScreen].bounds];\n[_gpuImageView setFillMode:kGPUImageFillModePreserveAspectRatioAndFill];\n[_gpuImageView setAutoresizingMask:UIViewAutoresizingFlexibleWidth | UIViewAutoresizingFlexibleHeight];\n        [_gpuImageView setInputRotation:kGPUImageFlipHorizonal atIndex:0];\n```\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","source":"_posts/iOS直播技术分享-音视频采集（一）.md","raw":"---\ntitle: iOS直播技术分享-音视频采集（一）\ndate: 2016-07-02 14:06:16\ncategories: 音视频\ntags: [音视频]\n---\n## 1、iOS直播技术的流程\n&emsp;&emsp;直播技术的流程大致可以分为几个步骤：数据采集、图像处理（实时滤镜）、视频编码、封包、上传、云端（转码、录制、分发）、直播播放器。  \n<!--more-->\n* 数据采集：通过摄像头和麦克风获得实时的音视频数据；  \n* 图像处理：将数据采集的输入流进行实时滤镜，得到我们美化之后的视频帧； \n* 视频编码：编码分为软编码和硬编码。现在一般的编码方式都是H.264，比较新的H.265据说压缩率比较高，但算法也相当要复杂一些，使用还不够广泛。软编码是利用CPU进行编码，硬编码就是使用GPU进行编码，软编码支持现在所有的系统版本，由于苹果在iOS8才开放硬编码的API，故硬编码只支持iOS8以上的系统；  \n* 封包：现在直播推流中，一般采用的格式是FLV；  \n* 上传：常用的协议是利用RTMP协议进行推流；  \n* 云端：进行流的转码、分发和录制；  \n* 直播播放器：负责拉流、解码、播放。\n  \n用一张腾讯云的图来说明上面的流程：  \n![直播技术流程](http://upload-images.jianshu.io/upload_images/2014909-fc4efbc9b1ffdd45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n## 2、获取系统的授权\n直播的第一步就是采集数据，包含视频和音频数据，由于iOS权限的要求，需要先获取访问摄像头和麦克风的权限：\n\n请求获取访问摄像头权限\n\n```\n__weak typeof(self) _self = self;\n    AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo];\n    switch (status) {\n        case AVAuthorizationStatusNotDetermined:{\n            // 许可对话没有出现，发起授权许可\n            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) {\n                if (granted) {\n                    dispatch_async(dispatch_get_main_queue(), ^{\n                        [_self.session setRunning:YES];\n                    });\n                }\n            }];\n            break;\n        }\n        case AVAuthorizationStatusAuthorized:{\n            // 已经开启授权，可继续\n            [_self.session setRunning:YES];\n            break;\n        }\n        case AVAuthorizationStatusDenied:\n        case AVAuthorizationStatusRestricted:\n            // 用户明确地拒绝授权，或者相机设备无法访问\n            break;\n        default:\n            break;\n    }\n```\n\n请求获取访问麦克风权限\n\n```\nAVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeAudio];\n    switch (status) {\n        case AVAuthorizationStatusNotDetermined:{\n            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeAudio completionHandler:^(BOOL granted) {\n            }];\n            break;\n        }\n        case AVAuthorizationStatusAuthorized:{\n            break;\n        }\n        case AVAuthorizationStatusDenied:\n        case AVAuthorizationStatusRestricted:\n            break;\n        default:\n            break;\n    }\n ```\n \n ## 3、配置采样参数\n \n 音频：需要配置码率、采样率；\n 视频：需要配置视频分辨率、视频的帧率、视频的码率。\n \n ## 4、音视频的录制   \n 音频的录制\n \n ```\n self.taskQueue = dispatch_queue_create(\"com.1905.live.audioCapture.Queue\", NULL);\n        \n        AVAudioSession *session = [AVAudioSession sharedInstance];\n        [session setActive:YES withOptions:kAudioSessionSetActiveFlag_NotifyOthersOnDeactivation error:nil];\n        \n        [[NSNotificationCenter defaultCenter] addObserver: self\n                                                 selector: @selector(handleRouteChange:)\n                                                     name: AVAudioSessionRouteChangeNotification\n                                                   object: session];\n        [[NSNotificationCenter defaultCenter] addObserver: self\n                                                 selector: @selector(handleInterruption:)\n                                                     name: AVAudioSessionInterruptionNotification\n                                                   object: session];\n        \n        NSError *error = nil;\n        \n        [session setCategory:AVAudioSessionCategoryPlayAndRecord withOptions:AVAudioSessionCategoryOptionDefaultToSpeaker | AVAudioSessionCategoryOptionMixWithOthers error:nil];\n        \n        [session setMode:AVAudioSessionModeVideoRecording error:&error];\n        \n        if (![session setActive:YES error:&error]) {\n            [self handleAudioComponentCreationFailure];\n        }\n        \n        AudioComponentDescription acd;\n        acd.componentType = kAudioUnitType_Output;\n        acd.componentSubType = kAudioUnitSubType_RemoteIO;\n        acd.componentManufacturer = kAudioUnitManufacturer_Apple;\n        acd.componentFlags = 0;\n        acd.componentFlagsMask = 0;\n        \n        self.component = AudioComponentFindNext(NULL, &acd);\n        \n        OSStatus status = noErr;\n        status = AudioComponentInstanceNew(self.component, &_componetInstance);\n        \n        if (noErr != status) {\n            [self handleAudioComponentCreationFailure];\n        }\n        \n        UInt32 flagOne = 1;\n        \n        AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Input, 1, &flagOne, sizeof(flagOne));\n        \n        AudioStreamBasicDescription desc = {0};\n        desc.mSampleRate = _configuration.audioSampleRate;\n        desc.mFormatID = kAudioFormatLinearPCM;\n        desc.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;\n        desc.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;\n        desc.mFramesPerPacket = 1;\n        desc.mBitsPerChannel = 16;\n        desc.mBytesPerFrame = desc.mBitsPerChannel / 8 * desc.mChannelsPerFrame;\n        desc.mBytesPerPacket = desc.mBytesPerFrame * desc.mFramesPerPacket;\n        \n        AURenderCallbackStruct cb;\n        cb.inputProcRefCon = (__bridge void *)(self);\n        cb.inputProc = handleInputBuffer;\n        status = AudioUnitSetProperty(self.componetInstance, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, &desc, sizeof(desc));\n        status = AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_SetInputCallback, kAudioUnitScope_Global, 1, &cb, sizeof(cb));\n        \n        status = AudioUnitInitialize(self.componetInstance);\n        \n        if (noErr != status) {\n            [self handleAudioComponentCreationFailure];\n        }\n        \n        [session setPreferredSampleRate:_configuration.audioSampleRate error:nil];\n        \n        \n        [session setActive:YES error:nil];\n```\n\n视频的录制：调用GPUImage中的GPUImageVideoCamera\n\n```\n_videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:_configuration.avSessionPreset cameraPosition:AVCaptureDevicePositionFront];\n_videoCamera.outputImageOrientation = _configuration.orientation;\n_videoCamera.horizontallyMirrorFrontFacingCamera = NO;\n_videoCamera.horizontallyMirrorRearFacingCamera = NO;\n_videoCamera.frameRate = (int32_t)_configuration.videoFrameRate;\n        \n_gpuImageView = [[GPUImageView alloc] initWithFrame:[UIScreen mainScreen].bounds];\n[_gpuImageView setFillMode:kGPUImageFillModePreserveAspectRatioAndFill];\n[_gpuImageView setAutoresizingMask:UIViewAutoresizingFlexibleWidth | UIViewAutoresizingFlexibleHeight];\n        [_gpuImageView setInputRotation:kGPUImageFlipHorizonal atIndex:0];\n```\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","slug":"iOS直播技术分享-音视频采集（一）","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1d000pn5xf1afkawzx","content":"<h2 id=\"1、iOS直播技术的流程\"><a href=\"#1、iOS直播技术的流程\" class=\"headerlink\" title=\"1、iOS直播技术的流程\"></a>1、iOS直播技术的流程</h2><p>&emsp;&emsp;直播技术的流程大致可以分为几个步骤：数据采集、图像处理（实时滤镜）、视频编码、封包、上传、云端（转码、录制、分发）、直播播放器。<br><a id=\"more\"></a></p>\n<ul>\n<li>数据采集：通过摄像头和麦克风获得实时的音视频数据；  </li>\n<li>图像处理：将数据采集的输入流进行实时滤镜，得到我们美化之后的视频帧； </li>\n<li>视频编码：编码分为软编码和硬编码。现在一般的编码方式都是H.264，比较新的H.265据说压缩率比较高，但算法也相当要复杂一些，使用还不够广泛。软编码是利用CPU进行编码，硬编码就是使用GPU进行编码，软编码支持现在所有的系统版本，由于苹果在iOS8才开放硬编码的API，故硬编码只支持iOS8以上的系统；  </li>\n<li>封包：现在直播推流中，一般采用的格式是FLV；  </li>\n<li>上传：常用的协议是利用RTMP协议进行推流；  </li>\n<li>云端：进行流的转码、分发和录制；  </li>\n<li>直播播放器：负责拉流、解码、播放。</li>\n</ul>\n<p>用一张腾讯云的图来说明上面的流程：<br><img src=\"http://upload-images.jianshu.io/upload_images/2014909-fc4efbc9b1ffdd45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"直播技术流程\"></p>\n<h2 id=\"2、获取系统的授权\"><a href=\"#2、获取系统的授权\" class=\"headerlink\" title=\"2、获取系统的授权\"></a>2、获取系统的授权</h2><p>直播的第一步就是采集数据，包含视频和音频数据，由于iOS权限的要求，需要先获取访问摄像头和麦克风的权限：</p>\n<p>请求获取访问摄像头权限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__weak typeof(self) _self = self;</span><br><span class=\"line\">    AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo];</span><br><span class=\"line\">    switch (status) &#123;</span><br><span class=\"line\">        case AVAuthorizationStatusNotDetermined:&#123;</span><br><span class=\"line\">            // 许可对话没有出现，发起授权许可</span><br><span class=\"line\">            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) &#123;</span><br><span class=\"line\">                if (granted) &#123;</span><br><span class=\"line\">                    dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class=\"line\">                        [_self.session setRunning:YES];</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;];</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusAuthorized:&#123;</span><br><span class=\"line\">            // 已经开启授权，可继续</span><br><span class=\"line\">            [_self.session setRunning:YES];</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusDenied:</span><br><span class=\"line\">        case AVAuthorizationStatusRestricted:</span><br><span class=\"line\">            // 用户明确地拒绝授权，或者相机设备无法访问</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>请求获取访问麦克风权限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeAudio];</span><br><span class=\"line\">    switch (status) &#123;</span><br><span class=\"line\">        case AVAuthorizationStatusNotDetermined:&#123;</span><br><span class=\"line\">            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeAudio completionHandler:^(BOOL granted) &#123;</span><br><span class=\"line\">            &#125;];</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusAuthorized:&#123;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusDenied:</span><br><span class=\"line\">        case AVAuthorizationStatusRestricted:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、配置采样参数\"><a href=\"#3、配置采样参数\" class=\"headerlink\" title=\"3、配置采样参数\"></a>3、配置采样参数</h2><p> 音频：需要配置码率、采样率；<br> 视频：需要配置视频分辨率、视频的帧率、视频的码率。</p>\n<h2 id=\"4、音视频的录制\"><a href=\"#4、音视频的录制\" class=\"headerlink\" title=\"4、音视频的录制\"></a>4、音视频的录制</h2><p> 音频的录制</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">self.taskQueue = dispatch_queue_create(&quot;com.1905.live.audioCapture.Queue&quot;, NULL);</span><br><span class=\"line\">       </span><br><span class=\"line\">       AVAudioSession *session = [AVAudioSession sharedInstance];</span><br><span class=\"line\">       [session setActive:YES withOptions:kAudioSessionSetActiveFlag_NotifyOthersOnDeactivation error:nil];</span><br><span class=\"line\">       </span><br><span class=\"line\">       [[NSNotificationCenter defaultCenter] addObserver: self</span><br><span class=\"line\">                                                selector: @selector(handleRouteChange:)</span><br><span class=\"line\">                                                    name: AVAudioSessionRouteChangeNotification</span><br><span class=\"line\">                                                  object: session];</span><br><span class=\"line\">       [[NSNotificationCenter defaultCenter] addObserver: self</span><br><span class=\"line\">                                                selector: @selector(handleInterruption:)</span><br><span class=\"line\">                                                    name: AVAudioSessionInterruptionNotification</span><br><span class=\"line\">                                                  object: session];</span><br><span class=\"line\">       </span><br><span class=\"line\">       NSError *error = nil;</span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setCategory:AVAudioSessionCategoryPlayAndRecord withOptions:AVAudioSessionCategoryOptionDefaultToSpeaker | AVAudioSessionCategoryOptionMixWithOthers error:nil];</span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setMode:AVAudioSessionModeVideoRecording error:&amp;error];</span><br><span class=\"line\">       </span><br><span class=\"line\">       if (![session setActive:YES error:&amp;error]) &#123;</span><br><span class=\"line\">           [self handleAudioComponentCreationFailure];</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       </span><br><span class=\"line\">       AudioComponentDescription acd;</span><br><span class=\"line\">       acd.componentType = kAudioUnitType_Output;</span><br><span class=\"line\">       acd.componentSubType = kAudioUnitSubType_RemoteIO;</span><br><span class=\"line\">       acd.componentManufacturer = kAudioUnitManufacturer_Apple;</span><br><span class=\"line\">       acd.componentFlags = 0;</span><br><span class=\"line\">       acd.componentFlagsMask = 0;</span><br><span class=\"line\">       </span><br><span class=\"line\">       self.component = AudioComponentFindNext(NULL, &amp;acd);</span><br><span class=\"line\">       </span><br><span class=\"line\">       OSStatus status = noErr;</span><br><span class=\"line\">       status = AudioComponentInstanceNew(self.component, &amp;_componetInstance);</span><br><span class=\"line\">       </span><br><span class=\"line\">       if (noErr != status) &#123;</span><br><span class=\"line\">           [self handleAudioComponentCreationFailure];</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       </span><br><span class=\"line\">       UInt32 flagOne = 1;</span><br><span class=\"line\">       </span><br><span class=\"line\">       AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Input, 1, &amp;flagOne, sizeof(flagOne));</span><br><span class=\"line\">       </span><br><span class=\"line\">       AudioStreamBasicDescription desc = &#123;0&#125;;</span><br><span class=\"line\">       desc.mSampleRate = _configuration.audioSampleRate;</span><br><span class=\"line\">       desc.mFormatID = kAudioFormatLinearPCM;</span><br><span class=\"line\">       desc.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;</span><br><span class=\"line\">       desc.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;</span><br><span class=\"line\">       desc.mFramesPerPacket = 1;</span><br><span class=\"line\">       desc.mBitsPerChannel = 16;</span><br><span class=\"line\">       desc.mBytesPerFrame = desc.mBitsPerChannel / 8 * desc.mChannelsPerFrame;</span><br><span class=\"line\">       desc.mBytesPerPacket = desc.mBytesPerFrame * desc.mFramesPerPacket;</span><br><span class=\"line\">       </span><br><span class=\"line\">       AURenderCallbackStruct cb;</span><br><span class=\"line\">       cb.inputProcRefCon = (__bridge void *)(self);</span><br><span class=\"line\">       cb.inputProc = handleInputBuffer;</span><br><span class=\"line\">       status = AudioUnitSetProperty(self.componetInstance, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, &amp;desc, sizeof(desc));</span><br><span class=\"line\">       status = AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_SetInputCallback, kAudioUnitScope_Global, 1, &amp;cb, sizeof(cb));</span><br><span class=\"line\">       </span><br><span class=\"line\">       status = AudioUnitInitialize(self.componetInstance);</span><br><span class=\"line\">       </span><br><span class=\"line\">       if (noErr != status) &#123;</span><br><span class=\"line\">           [self handleAudioComponentCreationFailure];</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setPreferredSampleRate:_configuration.audioSampleRate error:nil];</span><br><span class=\"line\">       </span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setActive:YES error:nil];</span><br></pre></td></tr></table></figure>\n<p>视频的录制：调用GPUImage中的GPUImageVideoCamera</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:_configuration.avSessionPreset cameraPosition:AVCaptureDevicePositionFront];</span><br><span class=\"line\">_videoCamera.outputImageOrientation = _configuration.orientation;</span><br><span class=\"line\">_videoCamera.horizontallyMirrorFrontFacingCamera = NO;</span><br><span class=\"line\">_videoCamera.horizontallyMirrorRearFacingCamera = NO;</span><br><span class=\"line\">_videoCamera.frameRate = (int32_t)_configuration.videoFrameRate;</span><br><span class=\"line\">        </span><br><span class=\"line\">_gpuImageView = [[GPUImageView alloc] initWithFrame:[UIScreen mainScreen].bounds];</span><br><span class=\"line\">[_gpuImageView setFillMode:kGPUImageFillModePreserveAspectRatioAndFill];</span><br><span class=\"line\">[_gpuImageView setAutoresizingMask:UIViewAutoresizingFlexibleWidth | UIViewAutoresizingFlexibleHeight];</span><br><span class=\"line\">        [_gpuImageView setInputRotation:kGPUImageFlipHorizonal atIndex:0];</span><br></pre></td></tr></table></figure>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1、iOS直播技术的流程\"><a href=\"#1、iOS直播技术的流程\" class=\"headerlink\" title=\"1、iOS直播技术的流程\"></a>1、iOS直播技术的流程</h2><p>&emsp;&emsp;直播技术的流程大致可以分为几个步骤：数据采集、图像处理（实时滤镜）、视频编码、封包、上传、云端（转码、录制、分发）、直播播放器。<br>","more":"</p>\n<ul>\n<li>数据采集：通过摄像头和麦克风获得实时的音视频数据；  </li>\n<li>图像处理：将数据采集的输入流进行实时滤镜，得到我们美化之后的视频帧； </li>\n<li>视频编码：编码分为软编码和硬编码。现在一般的编码方式都是H.264，比较新的H.265据说压缩率比较高，但算法也相当要复杂一些，使用还不够广泛。软编码是利用CPU进行编码，硬编码就是使用GPU进行编码，软编码支持现在所有的系统版本，由于苹果在iOS8才开放硬编码的API，故硬编码只支持iOS8以上的系统；  </li>\n<li>封包：现在直播推流中，一般采用的格式是FLV；  </li>\n<li>上传：常用的协议是利用RTMP协议进行推流；  </li>\n<li>云端：进行流的转码、分发和录制；  </li>\n<li>直播播放器：负责拉流、解码、播放。</li>\n</ul>\n<p>用一张腾讯云的图来说明上面的流程：<br><img src=\"http://upload-images.jianshu.io/upload_images/2014909-fc4efbc9b1ffdd45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"直播技术流程\"></p>\n<h2 id=\"2、获取系统的授权\"><a href=\"#2、获取系统的授权\" class=\"headerlink\" title=\"2、获取系统的授权\"></a>2、获取系统的授权</h2><p>直播的第一步就是采集数据，包含视频和音频数据，由于iOS权限的要求，需要先获取访问摄像头和麦克风的权限：</p>\n<p>请求获取访问摄像头权限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__weak typeof(self) _self = self;</span><br><span class=\"line\">    AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo];</span><br><span class=\"line\">    switch (status) &#123;</span><br><span class=\"line\">        case AVAuthorizationStatusNotDetermined:&#123;</span><br><span class=\"line\">            // 许可对话没有出现，发起授权许可</span><br><span class=\"line\">            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) &#123;</span><br><span class=\"line\">                if (granted) &#123;</span><br><span class=\"line\">                    dispatch_async(dispatch_get_main_queue(), ^&#123;</span><br><span class=\"line\">                        [_self.session setRunning:YES];</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;];</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusAuthorized:&#123;</span><br><span class=\"line\">            // 已经开启授权，可继续</span><br><span class=\"line\">            [_self.session setRunning:YES];</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusDenied:</span><br><span class=\"line\">        case AVAuthorizationStatusRestricted:</span><br><span class=\"line\">            // 用户明确地拒绝授权，或者相机设备无法访问</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>请求获取访问麦克风权限</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeAudio];</span><br><span class=\"line\">    switch (status) &#123;</span><br><span class=\"line\">        case AVAuthorizationStatusNotDetermined:&#123;</span><br><span class=\"line\">            [AVCaptureDevice requestAccessForMediaType:AVMediaTypeAudio completionHandler:^(BOOL granted) &#123;</span><br><span class=\"line\">            &#125;];</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusAuthorized:&#123;</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        case AVAuthorizationStatusDenied:</span><br><span class=\"line\">        case AVAuthorizationStatusRestricted:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">        default:</span><br><span class=\"line\">            break;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、配置采样参数\"><a href=\"#3、配置采样参数\" class=\"headerlink\" title=\"3、配置采样参数\"></a>3、配置采样参数</h2><p> 音频：需要配置码率、采样率；<br> 视频：需要配置视频分辨率、视频的帧率、视频的码率。</p>\n<h2 id=\"4、音视频的录制\"><a href=\"#4、音视频的录制\" class=\"headerlink\" title=\"4、音视频的录制\"></a>4、音视频的录制</h2><p> 音频的录制</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">self.taskQueue = dispatch_queue_create(&quot;com.1905.live.audioCapture.Queue&quot;, NULL);</span><br><span class=\"line\">       </span><br><span class=\"line\">       AVAudioSession *session = [AVAudioSession sharedInstance];</span><br><span class=\"line\">       [session setActive:YES withOptions:kAudioSessionSetActiveFlag_NotifyOthersOnDeactivation error:nil];</span><br><span class=\"line\">       </span><br><span class=\"line\">       [[NSNotificationCenter defaultCenter] addObserver: self</span><br><span class=\"line\">                                                selector: @selector(handleRouteChange:)</span><br><span class=\"line\">                                                    name: AVAudioSessionRouteChangeNotification</span><br><span class=\"line\">                                                  object: session];</span><br><span class=\"line\">       [[NSNotificationCenter defaultCenter] addObserver: self</span><br><span class=\"line\">                                                selector: @selector(handleInterruption:)</span><br><span class=\"line\">                                                    name: AVAudioSessionInterruptionNotification</span><br><span class=\"line\">                                                  object: session];</span><br><span class=\"line\">       </span><br><span class=\"line\">       NSError *error = nil;</span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setCategory:AVAudioSessionCategoryPlayAndRecord withOptions:AVAudioSessionCategoryOptionDefaultToSpeaker | AVAudioSessionCategoryOptionMixWithOthers error:nil];</span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setMode:AVAudioSessionModeVideoRecording error:&amp;error];</span><br><span class=\"line\">       </span><br><span class=\"line\">       if (![session setActive:YES error:&amp;error]) &#123;</span><br><span class=\"line\">           [self handleAudioComponentCreationFailure];</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       </span><br><span class=\"line\">       AudioComponentDescription acd;</span><br><span class=\"line\">       acd.componentType = kAudioUnitType_Output;</span><br><span class=\"line\">       acd.componentSubType = kAudioUnitSubType_RemoteIO;</span><br><span class=\"line\">       acd.componentManufacturer = kAudioUnitManufacturer_Apple;</span><br><span class=\"line\">       acd.componentFlags = 0;</span><br><span class=\"line\">       acd.componentFlagsMask = 0;</span><br><span class=\"line\">       </span><br><span class=\"line\">       self.component = AudioComponentFindNext(NULL, &amp;acd);</span><br><span class=\"line\">       </span><br><span class=\"line\">       OSStatus status = noErr;</span><br><span class=\"line\">       status = AudioComponentInstanceNew(self.component, &amp;_componetInstance);</span><br><span class=\"line\">       </span><br><span class=\"line\">       if (noErr != status) &#123;</span><br><span class=\"line\">           [self handleAudioComponentCreationFailure];</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       </span><br><span class=\"line\">       UInt32 flagOne = 1;</span><br><span class=\"line\">       </span><br><span class=\"line\">       AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_EnableIO, kAudioUnitScope_Input, 1, &amp;flagOne, sizeof(flagOne));</span><br><span class=\"line\">       </span><br><span class=\"line\">       AudioStreamBasicDescription desc = &#123;0&#125;;</span><br><span class=\"line\">       desc.mSampleRate = _configuration.audioSampleRate;</span><br><span class=\"line\">       desc.mFormatID = kAudioFormatLinearPCM;</span><br><span class=\"line\">       desc.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagsNativeEndian | kAudioFormatFlagIsPacked;</span><br><span class=\"line\">       desc.mChannelsPerFrame = (UInt32)_configuration.numberOfChannels;</span><br><span class=\"line\">       desc.mFramesPerPacket = 1;</span><br><span class=\"line\">       desc.mBitsPerChannel = 16;</span><br><span class=\"line\">       desc.mBytesPerFrame = desc.mBitsPerChannel / 8 * desc.mChannelsPerFrame;</span><br><span class=\"line\">       desc.mBytesPerPacket = desc.mBytesPerFrame * desc.mFramesPerPacket;</span><br><span class=\"line\">       </span><br><span class=\"line\">       AURenderCallbackStruct cb;</span><br><span class=\"line\">       cb.inputProcRefCon = (__bridge void *)(self);</span><br><span class=\"line\">       cb.inputProc = handleInputBuffer;</span><br><span class=\"line\">       status = AudioUnitSetProperty(self.componetInstance, kAudioUnitProperty_StreamFormat, kAudioUnitScope_Output, 1, &amp;desc, sizeof(desc));</span><br><span class=\"line\">       status = AudioUnitSetProperty(self.componetInstance, kAudioOutputUnitProperty_SetInputCallback, kAudioUnitScope_Global, 1, &amp;cb, sizeof(cb));</span><br><span class=\"line\">       </span><br><span class=\"line\">       status = AudioUnitInitialize(self.componetInstance);</span><br><span class=\"line\">       </span><br><span class=\"line\">       if (noErr != status) &#123;</span><br><span class=\"line\">           [self handleAudioComponentCreationFailure];</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setPreferredSampleRate:_configuration.audioSampleRate error:nil];</span><br><span class=\"line\">       </span><br><span class=\"line\">       </span><br><span class=\"line\">       [session setActive:YES error:nil];</span><br></pre></td></tr></table></figure>\n<p>视频的录制：调用GPUImage中的GPUImageVideoCamera</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">_videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:_configuration.avSessionPreset cameraPosition:AVCaptureDevicePositionFront];</span><br><span class=\"line\">_videoCamera.outputImageOrientation = _configuration.orientation;</span><br><span class=\"line\">_videoCamera.horizontallyMirrorFrontFacingCamera = NO;</span><br><span class=\"line\">_videoCamera.horizontallyMirrorRearFacingCamera = NO;</span><br><span class=\"line\">_videoCamera.frameRate = (int32_t)_configuration.videoFrameRate;</span><br><span class=\"line\">        </span><br><span class=\"line\">_gpuImageView = [[GPUImageView alloc] initWithFrame:[UIScreen mainScreen].bounds];</span><br><span class=\"line\">[_gpuImageView setFillMode:kGPUImageFillModePreserveAspectRatioAndFill];</span><br><span class=\"line\">[_gpuImageView setAutoresizingMask:UIViewAutoresizingFlexibleWidth | UIViewAutoresizingFlexibleHeight];</span><br><span class=\"line\">        [_gpuImageView setInputRotation:kGPUImageFlipHorizonal atIndex:0];</span><br></pre></td></tr></table></figure>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>"},{"title":"macOS下如何编译FFmpeg for macOS APP","date":"2017-08-11T06:39:15.000Z","_content":"我们今天来说说如何编译出适用于macOS APP的库，包括动态库和静态库。\n## 一、基本编译\n1、首先我们下载一个最新的ffmpeg源码。\n\n```\ngit clone https://git.ffmpeg.org/ffmpeg.git\n```\n\n2、配置./configure选项，这个要注意需要设置对macOS最低版本的要求，否则是默认当前本机的最新系统如，这样的话在使用库的时候，如果是APP要运行在10.10及之下的系统时候，就会报错。\n<!--more-->\n\n```\n--extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8\n```\n\n3、执行./configure内容如下：\n\n```\n./configure --target-os=darwin --enable-static --enable-swscale --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8 \n```\n\n4、执行编译和安装\n\n```\nmake && sudo make install  \n```\n\n5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。\n\n## 二、高级编译\n\n前面的之所以说是基本编译，主要都是ffmpeg自带的库的编译，包括了几乎全部的大部分的Decoder解码编译器，但是对于Encoder编码编译器，却不是特别多，比如aac就只有解码器没有编码器，如果想要对一个音频转换到aac格式，那么这时候就需要用的aac编码器。\n\n1、下载和编译aac库\n\n```\ngit clone https://github.com/mstorsjo/fdk-aac.git\ncd fdk-aac\n./autogen.sh /* 执行这个一步的需要automake，如果没有可以直接brew install automake */\n./configure —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/\nmake && sudo make install\n```\n\n当然也可以直接通过brew安装编译后的aac库，下面是我使用的命令\n\n```\nbrew install fdk-aac\n```\n\n2、下载和编译x264库\n\n```\ngit clone http://git.videolan.org/git/x264.git.\ncd x264\n./configure —disable-asm —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/\nmake && sudo make install\n ```\n\n当然也可以直接通过brew安装编译后的x264库，下面是我使用的命令行\n\n```\nbrew install x264\n```\n\n3、./configure配置\n这里要注意，需要把acc、x264的库文件和头文件的路径加到配置里面，要不回出错，提示aac not found。\n\n```\n./configure --target-os=darwin --enable-static --enable-swscale --enable-libfdk-aac --enable-libx264 --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8 --extra-cflags=-I/Users/forcetech/Downloads/opt/include --extra-ldflags=-L/Users/forcetech/Downloads/opt/lib --prefix=/Users/forcetech/Downloads/opt/\n```\n\n4、执行编译和安装\n\n```\nmake && sudo make install  \n```\n\n5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。\n\n","source":"_posts/macOS下如何编译FFmpeg-for-macOS-APP.md","raw":"---\ntitle: macOS下如何编译FFmpeg for macOS APP\ndate: 2017-08-11 14:39:15\ncategories: 音视频\ntags: [音视频]\n---\n我们今天来说说如何编译出适用于macOS APP的库，包括动态库和静态库。\n## 一、基本编译\n1、首先我们下载一个最新的ffmpeg源码。\n\n```\ngit clone https://git.ffmpeg.org/ffmpeg.git\n```\n\n2、配置./configure选项，这个要注意需要设置对macOS最低版本的要求，否则是默认当前本机的最新系统如，这样的话在使用库的时候，如果是APP要运行在10.10及之下的系统时候，就会报错。\n<!--more-->\n\n```\n--extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8\n```\n\n3、执行./configure内容如下：\n\n```\n./configure --target-os=darwin --enable-static --enable-swscale --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8 \n```\n\n4、执行编译和安装\n\n```\nmake && sudo make install  \n```\n\n5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。\n\n## 二、高级编译\n\n前面的之所以说是基本编译，主要都是ffmpeg自带的库的编译，包括了几乎全部的大部分的Decoder解码编译器，但是对于Encoder编码编译器，却不是特别多，比如aac就只有解码器没有编码器，如果想要对一个音频转换到aac格式，那么这时候就需要用的aac编码器。\n\n1、下载和编译aac库\n\n```\ngit clone https://github.com/mstorsjo/fdk-aac.git\ncd fdk-aac\n./autogen.sh /* 执行这个一步的需要automake，如果没有可以直接brew install automake */\n./configure —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/\nmake && sudo make install\n```\n\n当然也可以直接通过brew安装编译后的aac库，下面是我使用的命令\n\n```\nbrew install fdk-aac\n```\n\n2、下载和编译x264库\n\n```\ngit clone http://git.videolan.org/git/x264.git.\ncd x264\n./configure —disable-asm —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/\nmake && sudo make install\n ```\n\n当然也可以直接通过brew安装编译后的x264库，下面是我使用的命令行\n\n```\nbrew install x264\n```\n\n3、./configure配置\n这里要注意，需要把acc、x264的库文件和头文件的路径加到配置里面，要不回出错，提示aac not found。\n\n```\n./configure --target-os=darwin --enable-static --enable-swscale --enable-libfdk-aac --enable-libx264 --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8 --extra-cflags=-I/Users/forcetech/Downloads/opt/include --extra-ldflags=-L/Users/forcetech/Downloads/opt/lib --prefix=/Users/forcetech/Downloads/opt/\n```\n\n4、执行编译和安装\n\n```\nmake && sudo make install  \n```\n\n5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。\n\n","slug":"macOS下如何编译FFmpeg-for-macOS-APP","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1f000sn5xfa1o746xi","content":"<p>我们今天来说说如何编译出适用于macOS APP的库，包括动态库和静态库。</p>\n<h2 id=\"一、基本编译\"><a href=\"#一、基本编译\" class=\"headerlink\" title=\"一、基本编译\"></a>一、基本编译</h2><p>1、首先我们下载一个最新的ffmpeg源码。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://git.ffmpeg.org/ffmpeg.git</span><br></pre></td></tr></table></figure>\n<p>2、配置./configure选项，这个要注意需要设置对macOS最低版本的要求，否则是默认当前本机的最新系统如，这样的话在使用库的时候，如果是APP要运行在10.10及之下的系统时候，就会报错。<br><a id=\"more\"></a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8</span><br></pre></td></tr></table></figure>\n<p>3、执行./configure内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --target-os=darwin --enable-static --enable-swscale --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8</span><br></pre></td></tr></table></figure>\n<p>4、执行编译和安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。</p>\n<h2 id=\"二、高级编译\"><a href=\"#二、高级编译\" class=\"headerlink\" title=\"二、高级编译\"></a>二、高级编译</h2><p>前面的之所以说是基本编译，主要都是ffmpeg自带的库的编译，包括了几乎全部的大部分的Decoder解码编译器，但是对于Encoder编码编译器，却不是特别多，比如aac就只有解码器没有编码器，如果想要对一个音频转换到aac格式，那么这时候就需要用的aac编码器。</p>\n<p>1、下载和编译aac库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/mstorsjo/fdk-aac.git</span><br><span class=\"line\">cd fdk-aac</span><br><span class=\"line\">./autogen.sh /* 执行这个一步的需要automake，如果没有可以直接brew install automake */</span><br><span class=\"line\">./configure —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/</span><br><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>当然也可以直接通过brew安装编译后的aac库，下面是我使用的命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install fdk-aac</span><br></pre></td></tr></table></figure>\n<p>2、下载和编译x264库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone http://git.videolan.org/git/x264.git.</span><br><span class=\"line\">cd x264</span><br><span class=\"line\">./configure —disable-asm —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/</span><br><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>当然也可以直接通过brew安装编译后的x264库，下面是我使用的命令行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install x264</span><br></pre></td></tr></table></figure>\n<p>3、./configure配置<br>这里要注意，需要把acc、x264的库文件和头文件的路径加到配置里面，要不回出错，提示aac not found。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --target-os=darwin --enable-static --enable-swscale --enable-libfdk-aac --enable-libx264 --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8 --extra-cflags=-I/Users/forcetech/Downloads/opt/include --extra-ldflags=-L/Users/forcetech/Downloads/opt/lib --prefix=/Users/forcetech/Downloads/opt/</span><br></pre></td></tr></table></figure>\n<p>4、执行编译和安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。</p>\n","site":{"data":{}},"excerpt":"<p>我们今天来说说如何编译出适用于macOS APP的库，包括动态库和静态库。</p>\n<h2 id=\"一、基本编译\"><a href=\"#一、基本编译\" class=\"headerlink\" title=\"一、基本编译\"></a>一、基本编译</h2><p>1、首先我们下载一个最新的ffmpeg源码。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://git.ffmpeg.org/ffmpeg.git</span><br></pre></td></tr></table></figure>\n<p>2、配置./configure选项，这个要注意需要设置对macOS最低版本的要求，否则是默认当前本机的最新系统如，这样的话在使用库的时候，如果是APP要运行在10.10及之下的系统时候，就会报错。<br>","more":"</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8</span><br></pre></td></tr></table></figure>\n<p>3、执行./configure内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --target-os=darwin --enable-static --enable-swscale --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8</span><br></pre></td></tr></table></figure>\n<p>4、执行编译和安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。</p>\n<h2 id=\"二、高级编译\"><a href=\"#二、高级编译\" class=\"headerlink\" title=\"二、高级编译\"></a>二、高级编译</h2><p>前面的之所以说是基本编译，主要都是ffmpeg自带的库的编译，包括了几乎全部的大部分的Decoder解码编译器，但是对于Encoder编码编译器，却不是特别多，比如aac就只有解码器没有编码器，如果想要对一个音频转换到aac格式，那么这时候就需要用的aac编码器。</p>\n<p>1、下载和编译aac库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/mstorsjo/fdk-aac.git</span><br><span class=\"line\">cd fdk-aac</span><br><span class=\"line\">./autogen.sh /* 执行这个一步的需要automake，如果没有可以直接brew install automake */</span><br><span class=\"line\">./configure —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/</span><br><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>当然也可以直接通过brew安装编译后的aac库，下面是我使用的命令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install fdk-aac</span><br></pre></td></tr></table></figure>\n<p>2、下载和编译x264库</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone http://git.videolan.org/git/x264.git.</span><br><span class=\"line\">cd x264</span><br><span class=\"line\">./configure —disable-asm —enable-shared —enable-static —prefix=/Users/forcetech/Downloads/opt/</span><br><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>当然也可以直接通过brew安装编译后的x264库，下面是我使用的命令行</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">brew install x264</span><br></pre></td></tr></table></figure>\n<p>3、./configure配置<br>这里要注意，需要把acc、x264的库文件和头文件的路径加到配置里面，要不回出错，提示aac not found。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./configure --target-os=darwin --enable-static --enable-swscale --enable-libfdk-aac --enable-libx264 --enable-nonfree  --enable-gpl --enable-version3 --enable-nonfree --disable-programs  --libdir=/ffmpegbuild/lib --incdir=/ffmpegbuild/include --enable-shared --extra-cflags=-mmacosx-version-min=10.8 --extra-ldflags=-mmacosx-version-min=10.8 --extra-cflags=-I/Users/forcetech/Downloads/opt/include --extra-ldflags=-L/Users/forcetech/Downloads/opt/lib --prefix=/Users/forcetech/Downloads/opt/</span><br></pre></td></tr></table></figure>\n<p>4、执行编译和安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make &amp;&amp; sudo make install</span><br></pre></td></tr></table></figure>\n<p>5、在根目录下的ffmpegbuild目录中，就是编译好的头文件和库文件，包括静态库和动态库。</p>"},{"title":"iOS直播技术分享-视频编码（三）","date":"2016-07-11T06:06:46.000Z","_content":"&emsp;&emsp;x264是一种免费的、具有更优秀算法的符合H.264/MPEG-4 AVC视频压缩编码标准格式的编码库。它同xvid一样都是开源项目，但x264是采用H.264标准的，而xvid是采用MPEG-4早期标准的。由于H.264是2003年正式发布的最新的视频编码标准，因此，在通常情况下，x264压缩出的视频文件在相同质量下要比xvid压缩出的文件要小，或者也可以说，在相同体积下比xvid压缩出的文件质量要好。它符合GPL许可证。 \n<!--more-->\n&emsp;&emsp;iOS视频编码分为硬编码和软编码：硬编码就是利用手机专用的硬件进行编码，软编码是用CPU进行编码。由于苹果在iOS8开放的硬编码的API，故现在大多数的直播应用都是采用的硬编码。\n## iOS硬编码\n\n &emsp;&emsp;从iOS8开始，苹果开放了硬解码和硬编码API，框架为 VideoToolbox.framework， 此框架需要在iOS8及以上的系统上才能使用。\n       此框架中的硬解码API是几个纯C函数，在任何OC或者 C++代码里都可以使用。使用的时候，首先，要把VideoToolbox.framework 添加到工程里，并且在要使用该API的文件中包含头文件#include <VideoToolbox/VideoToolbox.h>，然后，就可以畅快的高效的对视频流进行硬编码了。\n\n直接上代码来说明，首先是定义了编码所需的变量\n```\n@interface CLHardwareVideoEncoder (){\n    VTCompressionSessionRef compressionSession;\n    NSInteger frameCount;\n    NSData *sps;\n    NSData *pps;\n    FILE *fp;\n    BOOL enabledWriteVideoFile;\n}\n\n@property (nonatomic, strong) CLLiveVideoConfiguration *configuration;\n@property (nonatomic,weak) id<CLVideoEncodingDelegate> h264Delegate;\n@property (nonatomic) BOOL isBackGround;\n@property (nonatomic) NSInteger currentVideoBitRate;\n\n@end\n```\n\n初始化编码session\n```\n- (void)initCompressionSession{\n    if(compressionSession){\n        VTCompressionSessionCompleteFrames(compressionSession, kCMTimeInvalid);\n        \n        VTCompressionSessionInvalidate(compressionSession);\n        CFRelease(compressionSession);\n        compressionSession = NULL;\n    }\n    \n    OSStatus status = VTCompressionSessionCreate(NULL, _configuration.videoSize.width, _configuration.videoSize.height, kCMVideoCodecType_H264, NULL, NULL, NULL, VideoCompressonOutputCallback, (__bridge void *)self, &compressionSession);\n    if(status != noErr){\n        return;\n    }\n    \n    _currentVideoBitRate = _configuration.videoBitRate;\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameInterval,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ExpectedFrameRate, (__bridge CFTypeRef)@(_configuration.videoFrameRate));\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AverageBitRate, (__bridge CFTypeRef)@(_configuration.videoBitRate));\n    NSArray *limit = @[@(_configuration.videoBitRate * 1.5/8),@(1)];\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_DataRateLimits, (__bridge CFArrayRef)limit);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_RealTime, kCFBooleanFalse);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ProfileLevel, kVTProfileLevel_H264_Main_AutoLevel);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AllowFrameReordering, kCFBooleanFalse);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_H264EntropyMode, kVTH264EntropyMode_CABAC);\n    VTCompressionSessionPrepareToEncodeFrames(compressionSession);\n}\n```\n\n编码输入\n```\n- (void)encodeVideoData:(CVImageBufferRef)pixelBuffer timeStamp:(uint64_t)timeStamp{\n    if(_isBackGround) return;\n    \n    frameCount ++;\n    CMTime presentationTimeStamp = CMTimeMake(frameCount, (int32_t)_configuration.videoFrameRate);\n    VTEncodeInfoFlags flags;\n    CMTime duration = CMTimeMake(1, (int32_t)_configuration.videoFrameRate);\n    \n    NSDictionary *properties = nil;\n    if(frameCount % (int32_t)_configuration.videoMaxKeyframeInterval == 0){\n        properties = @{(__bridge NSString *)kVTEncodeFrameOptionKey_ForceKeyFrame: @YES};\n    }\n    NSNumber *timeNumber = @(timeStamp);\n    \n    VTCompressionSessionEncodeFrame(compressionSession, pixelBuffer, presentationTimeStamp, duration, (__bridge CFDictionaryRef)properties, (__bridge_retained void *)timeNumber, &flags);\n}\n```\n\n回调\n```\nstatic void VideoCompressonOutputCallback(void *VTref, void *VTFrameRef, OSStatus status, VTEncodeInfoFlags infoFlags, CMSampleBufferRef sampleBuffer)\n{\n    if(!sampleBuffer) return;\n    CFArrayRef array = CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, true);\n    if(!array) return;\n    CFDictionaryRef dic = (CFDictionaryRef)CFArrayGetValueAtIndex(array, 0);\n    if(!dic) return;\n    \n    BOOL keyframe = !CFDictionaryContainsKey(dic, kCMSampleAttachmentKey_NotSync);\n    uint64_t timeStamp = [((__bridge_transfer NSNumber*)VTFrameRef) longLongValue];\n    \n    CLHardwareVideoEncoder *videoEncoder = (__bridge CLHardwareVideoEncoder *)VTref;\n    if(status != noErr){\n        return;\n    }\n    \n    if (keyframe && !videoEncoder->sps)\n    {\n        CMFormatDescriptionRef format = CMSampleBufferGetFormatDescription(sampleBuffer);\n        \n        size_t sparameterSetSize, sparameterSetCount;\n        const uint8_t *sparameterSet;\n        OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 0, &sparameterSet, &sparameterSetSize, &sparameterSetCount, 0 );\n        if (statusCode == noErr)\n        {\n            size_t pparameterSetSize, pparameterSetCount;\n            const uint8_t *pparameterSet;\n            OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 1, &pparameterSet, &pparameterSetSize, &pparameterSetCount, 0 );\n            if (statusCode == noErr)\n            {\n                videoEncoder->sps = [NSData dataWithBytes:sparameterSet length:sparameterSetSize];\n                videoEncoder->pps = [NSData dataWithBytes:pparameterSet length:pparameterSetSize];\n                \n                if(videoEncoder->enabledWriteVideoFile){\n                    NSMutableData *data = [[NSMutableData alloc] init];\n                    uint8_t header[] = {0x00,0x00,0x00,0x01};\n                    [data appendBytes:header length:4];\n                    [data appendData:videoEncoder->sps];\n                    [data appendBytes:header length:4];\n                    [data appendData:videoEncoder->pps];\n                    fwrite(data.bytes, 1,data.length,videoEncoder->fp);\n                }\n            }\n        }\n    }\n    \n    \n    CMBlockBufferRef dataBuffer = CMSampleBufferGetDataBuffer(sampleBuffer);\n    size_t length, totalLength;\n    char *dataPointer;\n    OSStatus statusCodeRet = CMBlockBufferGetDataPointer(dataBuffer, 0, &length, &totalLength, &dataPointer);\n    if (statusCodeRet == noErr) {\n        size_t bufferOffset = 0;\n        static const int AVCCHeaderLength = 4;\n        while (bufferOffset < totalLength - AVCCHeaderLength) {\n            // Read the NAL unit length\n            uint32_t NALUnitLength = 0;\n            memcpy(&NALUnitLength, dataPointer + bufferOffset, AVCCHeaderLength);\n            \n            NALUnitLength = CFSwapInt32BigToHost(NALUnitLength);\n\n            CLVideoFrame *videoFrame = [CLVideoFrame new];\n            videoFrame.timestamp = timeStamp;\n            videoFrame.data = [[NSData alloc] initWithBytes:(dataPointer + bufferOffset + AVCCHeaderLength) length:NALUnitLength];\n            videoFrame.isKeyFrame = keyframe;\n            videoFrame.sps = videoEncoder->sps;\n            videoFrame.pps = videoEncoder->pps;\n            \n            if(videoEncoder.h264Delegate && [videoEncoder.h264Delegate respondsToSelector:@selector(videoEncoder:videoFrame:)]){\n                [videoEncoder.h264Delegate videoEncoder:videoEncoder videoFrame:videoFrame];\n            }\n            \n            if(videoEncoder->enabledWriteVideoFile){\n                NSMutableData *data = [[NSMutableData alloc] init];\n                if(keyframe){\n                    uint8_t header[] = {0x00,0x00,0x00,0x01};\n                    [data appendBytes:header length:4];\n                }else{\n                    uint8_t header[] = {0x00,0x00,0x01};\n                    [data appendBytes:header length:3];\n                }\n                [data appendData:videoFrame.data];\n                fwrite(data.bytes, 1,data.length,videoEncoder->fp);\n            }\n            bufferOffset += AVCCHeaderLength + NALUnitLength;\n        }\n    }\n}\n```\n\n## iOS软编码(待续)\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","source":"_posts/iOS直播技术分享-视频编码（三）.md","raw":"---\ntitle: iOS直播技术分享-视频编码（三）\ndate: 2016-07-11 14:06:46\ncategories: 音视频\ntags: [音视频]\n---\n&emsp;&emsp;x264是一种免费的、具有更优秀算法的符合H.264/MPEG-4 AVC视频压缩编码标准格式的编码库。它同xvid一样都是开源项目，但x264是采用H.264标准的，而xvid是采用MPEG-4早期标准的。由于H.264是2003年正式发布的最新的视频编码标准，因此，在通常情况下，x264压缩出的视频文件在相同质量下要比xvid压缩出的文件要小，或者也可以说，在相同体积下比xvid压缩出的文件质量要好。它符合GPL许可证。 \n<!--more-->\n&emsp;&emsp;iOS视频编码分为硬编码和软编码：硬编码就是利用手机专用的硬件进行编码，软编码是用CPU进行编码。由于苹果在iOS8开放的硬编码的API，故现在大多数的直播应用都是采用的硬编码。\n## iOS硬编码\n\n &emsp;&emsp;从iOS8开始，苹果开放了硬解码和硬编码API，框架为 VideoToolbox.framework， 此框架需要在iOS8及以上的系统上才能使用。\n       此框架中的硬解码API是几个纯C函数，在任何OC或者 C++代码里都可以使用。使用的时候，首先，要把VideoToolbox.framework 添加到工程里，并且在要使用该API的文件中包含头文件#include <VideoToolbox/VideoToolbox.h>，然后，就可以畅快的高效的对视频流进行硬编码了。\n\n直接上代码来说明，首先是定义了编码所需的变量\n```\n@interface CLHardwareVideoEncoder (){\n    VTCompressionSessionRef compressionSession;\n    NSInteger frameCount;\n    NSData *sps;\n    NSData *pps;\n    FILE *fp;\n    BOOL enabledWriteVideoFile;\n}\n\n@property (nonatomic, strong) CLLiveVideoConfiguration *configuration;\n@property (nonatomic,weak) id<CLVideoEncodingDelegate> h264Delegate;\n@property (nonatomic) BOOL isBackGround;\n@property (nonatomic) NSInteger currentVideoBitRate;\n\n@end\n```\n\n初始化编码session\n```\n- (void)initCompressionSession{\n    if(compressionSession){\n        VTCompressionSessionCompleteFrames(compressionSession, kCMTimeInvalid);\n        \n        VTCompressionSessionInvalidate(compressionSession);\n        CFRelease(compressionSession);\n        compressionSession = NULL;\n    }\n    \n    OSStatus status = VTCompressionSessionCreate(NULL, _configuration.videoSize.width, _configuration.videoSize.height, kCMVideoCodecType_H264, NULL, NULL, NULL, VideoCompressonOutputCallback, (__bridge void *)self, &compressionSession);\n    if(status != noErr){\n        return;\n    }\n    \n    _currentVideoBitRate = _configuration.videoBitRate;\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameInterval,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ExpectedFrameRate, (__bridge CFTypeRef)@(_configuration.videoFrameRate));\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AverageBitRate, (__bridge CFTypeRef)@(_configuration.videoBitRate));\n    NSArray *limit = @[@(_configuration.videoBitRate * 1.5/8),@(1)];\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_DataRateLimits, (__bridge CFArrayRef)limit);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_RealTime, kCFBooleanFalse);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ProfileLevel, kVTProfileLevel_H264_Main_AutoLevel);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AllowFrameReordering, kCFBooleanFalse);\n    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_H264EntropyMode, kVTH264EntropyMode_CABAC);\n    VTCompressionSessionPrepareToEncodeFrames(compressionSession);\n}\n```\n\n编码输入\n```\n- (void)encodeVideoData:(CVImageBufferRef)pixelBuffer timeStamp:(uint64_t)timeStamp{\n    if(_isBackGround) return;\n    \n    frameCount ++;\n    CMTime presentationTimeStamp = CMTimeMake(frameCount, (int32_t)_configuration.videoFrameRate);\n    VTEncodeInfoFlags flags;\n    CMTime duration = CMTimeMake(1, (int32_t)_configuration.videoFrameRate);\n    \n    NSDictionary *properties = nil;\n    if(frameCount % (int32_t)_configuration.videoMaxKeyframeInterval == 0){\n        properties = @{(__bridge NSString *)kVTEncodeFrameOptionKey_ForceKeyFrame: @YES};\n    }\n    NSNumber *timeNumber = @(timeStamp);\n    \n    VTCompressionSessionEncodeFrame(compressionSession, pixelBuffer, presentationTimeStamp, duration, (__bridge CFDictionaryRef)properties, (__bridge_retained void *)timeNumber, &flags);\n}\n```\n\n回调\n```\nstatic void VideoCompressonOutputCallback(void *VTref, void *VTFrameRef, OSStatus status, VTEncodeInfoFlags infoFlags, CMSampleBufferRef sampleBuffer)\n{\n    if(!sampleBuffer) return;\n    CFArrayRef array = CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, true);\n    if(!array) return;\n    CFDictionaryRef dic = (CFDictionaryRef)CFArrayGetValueAtIndex(array, 0);\n    if(!dic) return;\n    \n    BOOL keyframe = !CFDictionaryContainsKey(dic, kCMSampleAttachmentKey_NotSync);\n    uint64_t timeStamp = [((__bridge_transfer NSNumber*)VTFrameRef) longLongValue];\n    \n    CLHardwareVideoEncoder *videoEncoder = (__bridge CLHardwareVideoEncoder *)VTref;\n    if(status != noErr){\n        return;\n    }\n    \n    if (keyframe && !videoEncoder->sps)\n    {\n        CMFormatDescriptionRef format = CMSampleBufferGetFormatDescription(sampleBuffer);\n        \n        size_t sparameterSetSize, sparameterSetCount;\n        const uint8_t *sparameterSet;\n        OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 0, &sparameterSet, &sparameterSetSize, &sparameterSetCount, 0 );\n        if (statusCode == noErr)\n        {\n            size_t pparameterSetSize, pparameterSetCount;\n            const uint8_t *pparameterSet;\n            OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 1, &pparameterSet, &pparameterSetSize, &pparameterSetCount, 0 );\n            if (statusCode == noErr)\n            {\n                videoEncoder->sps = [NSData dataWithBytes:sparameterSet length:sparameterSetSize];\n                videoEncoder->pps = [NSData dataWithBytes:pparameterSet length:pparameterSetSize];\n                \n                if(videoEncoder->enabledWriteVideoFile){\n                    NSMutableData *data = [[NSMutableData alloc] init];\n                    uint8_t header[] = {0x00,0x00,0x00,0x01};\n                    [data appendBytes:header length:4];\n                    [data appendData:videoEncoder->sps];\n                    [data appendBytes:header length:4];\n                    [data appendData:videoEncoder->pps];\n                    fwrite(data.bytes, 1,data.length,videoEncoder->fp);\n                }\n            }\n        }\n    }\n    \n    \n    CMBlockBufferRef dataBuffer = CMSampleBufferGetDataBuffer(sampleBuffer);\n    size_t length, totalLength;\n    char *dataPointer;\n    OSStatus statusCodeRet = CMBlockBufferGetDataPointer(dataBuffer, 0, &length, &totalLength, &dataPointer);\n    if (statusCodeRet == noErr) {\n        size_t bufferOffset = 0;\n        static const int AVCCHeaderLength = 4;\n        while (bufferOffset < totalLength - AVCCHeaderLength) {\n            // Read the NAL unit length\n            uint32_t NALUnitLength = 0;\n            memcpy(&NALUnitLength, dataPointer + bufferOffset, AVCCHeaderLength);\n            \n            NALUnitLength = CFSwapInt32BigToHost(NALUnitLength);\n\n            CLVideoFrame *videoFrame = [CLVideoFrame new];\n            videoFrame.timestamp = timeStamp;\n            videoFrame.data = [[NSData alloc] initWithBytes:(dataPointer + bufferOffset + AVCCHeaderLength) length:NALUnitLength];\n            videoFrame.isKeyFrame = keyframe;\n            videoFrame.sps = videoEncoder->sps;\n            videoFrame.pps = videoEncoder->pps;\n            \n            if(videoEncoder.h264Delegate && [videoEncoder.h264Delegate respondsToSelector:@selector(videoEncoder:videoFrame:)]){\n                [videoEncoder.h264Delegate videoEncoder:videoEncoder videoFrame:videoFrame];\n            }\n            \n            if(videoEncoder->enabledWriteVideoFile){\n                NSMutableData *data = [[NSMutableData alloc] init];\n                if(keyframe){\n                    uint8_t header[] = {0x00,0x00,0x00,0x01};\n                    [data appendBytes:header length:4];\n                }else{\n                    uint8_t header[] = {0x00,0x00,0x01};\n                    [data appendBytes:header length:3];\n                }\n                [data appendData:videoFrame.data];\n                fwrite(data.bytes, 1,data.length,videoEncoder->fp);\n            }\n            bufferOffset += AVCCHeaderLength + NALUnitLength;\n        }\n    }\n}\n```\n\n## iOS软编码(待续)\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","slug":"iOS直播技术分享-视频编码（三）","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1h000xn5xf73mq0nto","content":"<p>&emsp;&emsp;x264是一种免费的、具有更优秀算法的符合H.264/MPEG-4 AVC视频压缩编码标准格式的编码库。它同xvid一样都是开源项目，但x264是采用H.264标准的，而xvid是采用MPEG-4早期标准的。由于H.264是2003年正式发布的最新的视频编码标准，因此，在通常情况下，x264压缩出的视频文件在相同质量下要比xvid压缩出的文件要小，或者也可以说，在相同体积下比xvid压缩出的文件质量要好。它符合GPL许可证。<br><a id=\"more\"></a><br>&emsp;&emsp;iOS视频编码分为硬编码和软编码：硬编码就是利用手机专用的硬件进行编码，软编码是用CPU进行编码。由于苹果在iOS8开放的硬编码的API，故现在大多数的直播应用都是采用的硬编码。</p>\n<h2 id=\"iOS硬编码\"><a href=\"#iOS硬编码\" class=\"headerlink\" title=\"iOS硬编码\"></a>iOS硬编码</h2><p> &emsp;&emsp;从iOS8开始，苹果开放了硬解码和硬编码API，框架为 VideoToolbox.framework， 此框架需要在iOS8及以上的系统上才能使用。<br>       此框架中的硬解码API是几个纯C函数，在任何OC或者 C++代码里都可以使用。使用的时候，首先，要把VideoToolbox.framework 添加到工程里，并且在要使用该API的文件中包含头文件#include &lt;VideoToolbox/VideoToolbox.h&gt;，然后，就可以畅快的高效的对视频流进行硬编码了。</p>\n<p>直接上代码来说明，首先是定义了编码所需的变量<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@interface CLHardwareVideoEncoder ()&#123;</span><br><span class=\"line\">    VTCompressionSessionRef compressionSession;</span><br><span class=\"line\">    NSInteger frameCount;</span><br><span class=\"line\">    NSData *sps;</span><br><span class=\"line\">    NSData *pps;</span><br><span class=\"line\">    FILE *fp;</span><br><span class=\"line\">    BOOL enabledWriteVideoFile;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@property (nonatomic, strong) CLLiveVideoConfiguration *configuration;</span><br><span class=\"line\">@property (nonatomic,weak) id&lt;CLVideoEncodingDelegate&gt; h264Delegate;</span><br><span class=\"line\">@property (nonatomic) BOOL isBackGround;</span><br><span class=\"line\">@property (nonatomic) NSInteger currentVideoBitRate;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure></p>\n<p>初始化编码session<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)initCompressionSession&#123;</span><br><span class=\"line\">    if(compressionSession)&#123;</span><br><span class=\"line\">        VTCompressionSessionCompleteFrames(compressionSession, kCMTimeInvalid);</span><br><span class=\"line\">        </span><br><span class=\"line\">        VTCompressionSessionInvalidate(compressionSession);</span><br><span class=\"line\">        CFRelease(compressionSession);</span><br><span class=\"line\">        compressionSession = NULL;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    OSStatus status = VTCompressionSessionCreate(NULL, _configuration.videoSize.width, _configuration.videoSize.height, kCMVideoCodecType_H264, NULL, NULL, NULL, VideoCompressonOutputCallback, (__bridge void *)self, &amp;compressionSession);</span><br><span class=\"line\">    if(status != noErr)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    _currentVideoBitRate = _configuration.videoBitRate;</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameInterval,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ExpectedFrameRate, (__bridge CFTypeRef)@(_configuration.videoFrameRate));</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AverageBitRate, (__bridge CFTypeRef)@(_configuration.videoBitRate));</span><br><span class=\"line\">    NSArray *limit = @[@(_configuration.videoBitRate * 1.5/8),@(1)];</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_DataRateLimits, (__bridge CFArrayRef)limit);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_RealTime, kCFBooleanFalse);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ProfileLevel, kVTProfileLevel_H264_Main_AutoLevel);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AllowFrameReordering, kCFBooleanFalse);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_H264EntropyMode, kVTH264EntropyMode_CABAC);</span><br><span class=\"line\">    VTCompressionSessionPrepareToEncodeFrames(compressionSession);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>编码输入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)encodeVideoData:(CVImageBufferRef)pixelBuffer timeStamp:(uint64_t)timeStamp&#123;</span><br><span class=\"line\">    if(_isBackGround) return;</span><br><span class=\"line\">    </span><br><span class=\"line\">    frameCount ++;</span><br><span class=\"line\">    CMTime presentationTimeStamp = CMTimeMake(frameCount, (int32_t)_configuration.videoFrameRate);</span><br><span class=\"line\">    VTEncodeInfoFlags flags;</span><br><span class=\"line\">    CMTime duration = CMTimeMake(1, (int32_t)_configuration.videoFrameRate);</span><br><span class=\"line\">    </span><br><span class=\"line\">    NSDictionary *properties = nil;</span><br><span class=\"line\">    if(frameCount % (int32_t)_configuration.videoMaxKeyframeInterval == 0)&#123;</span><br><span class=\"line\">        properties = @&#123;(__bridge NSString *)kVTEncodeFrameOptionKey_ForceKeyFrame: @YES&#125;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    NSNumber *timeNumber = @(timeStamp);</span><br><span class=\"line\">    </span><br><span class=\"line\">    VTCompressionSessionEncodeFrame(compressionSession, pixelBuffer, presentationTimeStamp, duration, (__bridge CFDictionaryRef)properties, (__bridge_retained void *)timeNumber, &amp;flags);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>回调<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static void VideoCompressonOutputCallback(void *VTref, void *VTFrameRef, OSStatus status, VTEncodeInfoFlags infoFlags, CMSampleBufferRef sampleBuffer)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    if(!sampleBuffer) return;</span><br><span class=\"line\">    CFArrayRef array = CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, true);</span><br><span class=\"line\">    if(!array) return;</span><br><span class=\"line\">    CFDictionaryRef dic = (CFDictionaryRef)CFArrayGetValueAtIndex(array, 0);</span><br><span class=\"line\">    if(!dic) return;</span><br><span class=\"line\">    </span><br><span class=\"line\">    BOOL keyframe = !CFDictionaryContainsKey(dic, kCMSampleAttachmentKey_NotSync);</span><br><span class=\"line\">    uint64_t timeStamp = [((__bridge_transfer NSNumber*)VTFrameRef) longLongValue];</span><br><span class=\"line\">    </span><br><span class=\"line\">    CLHardwareVideoEncoder *videoEncoder = (__bridge CLHardwareVideoEncoder *)VTref;</span><br><span class=\"line\">    if(status != noErr)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    if (keyframe &amp;&amp; !videoEncoder-&gt;sps)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        CMFormatDescriptionRef format = CMSampleBufferGetFormatDescription(sampleBuffer);</span><br><span class=\"line\">        </span><br><span class=\"line\">        size_t sparameterSetSize, sparameterSetCount;</span><br><span class=\"line\">        const uint8_t *sparameterSet;</span><br><span class=\"line\">        OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 0, &amp;sparameterSet, &amp;sparameterSetSize, &amp;sparameterSetCount, 0 );</span><br><span class=\"line\">        if (statusCode == noErr)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            size_t pparameterSetSize, pparameterSetCount;</span><br><span class=\"line\">            const uint8_t *pparameterSet;</span><br><span class=\"line\">            OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 1, &amp;pparameterSet, &amp;pparameterSetSize, &amp;pparameterSetCount, 0 );</span><br><span class=\"line\">            if (statusCode == noErr)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                videoEncoder-&gt;sps = [NSData dataWithBytes:sparameterSet length:sparameterSetSize];</span><br><span class=\"line\">                videoEncoder-&gt;pps = [NSData dataWithBytes:pparameterSet length:pparameterSetSize];</span><br><span class=\"line\">                </span><br><span class=\"line\">                if(videoEncoder-&gt;enabledWriteVideoFile)&#123;</span><br><span class=\"line\">                    NSMutableData *data = [[NSMutableData alloc] init];</span><br><span class=\"line\">                    uint8_t header[] = &#123;0x00,0x00,0x00,0x01&#125;;</span><br><span class=\"line\">                    [data appendBytes:header length:4];</span><br><span class=\"line\">                    [data appendData:videoEncoder-&gt;sps];</span><br><span class=\"line\">                    [data appendBytes:header length:4];</span><br><span class=\"line\">                    [data appendData:videoEncoder-&gt;pps];</span><br><span class=\"line\">                    fwrite(data.bytes, 1,data.length,videoEncoder-&gt;fp);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    CMBlockBufferRef dataBuffer = CMSampleBufferGetDataBuffer(sampleBuffer);</span><br><span class=\"line\">    size_t length, totalLength;</span><br><span class=\"line\">    char *dataPointer;</span><br><span class=\"line\">    OSStatus statusCodeRet = CMBlockBufferGetDataPointer(dataBuffer, 0, &amp;length, &amp;totalLength, &amp;dataPointer);</span><br><span class=\"line\">    if (statusCodeRet == noErr) &#123;</span><br><span class=\"line\">        size_t bufferOffset = 0;</span><br><span class=\"line\">        static const int AVCCHeaderLength = 4;</span><br><span class=\"line\">        while (bufferOffset &lt; totalLength - AVCCHeaderLength) &#123;</span><br><span class=\"line\">            // Read the NAL unit length</span><br><span class=\"line\">            uint32_t NALUnitLength = 0;</span><br><span class=\"line\">            memcpy(&amp;NALUnitLength, dataPointer + bufferOffset, AVCCHeaderLength);</span><br><span class=\"line\">            </span><br><span class=\"line\">            NALUnitLength = CFSwapInt32BigToHost(NALUnitLength);</span><br><span class=\"line\"></span><br><span class=\"line\">            CLVideoFrame *videoFrame = [CLVideoFrame new];</span><br><span class=\"line\">            videoFrame.timestamp = timeStamp;</span><br><span class=\"line\">            videoFrame.data = [[NSData alloc] initWithBytes:(dataPointer + bufferOffset + AVCCHeaderLength) length:NALUnitLength];</span><br><span class=\"line\">            videoFrame.isKeyFrame = keyframe;</span><br><span class=\"line\">            videoFrame.sps = videoEncoder-&gt;sps;</span><br><span class=\"line\">            videoFrame.pps = videoEncoder-&gt;pps;</span><br><span class=\"line\">            </span><br><span class=\"line\">            if(videoEncoder.h264Delegate &amp;&amp; [videoEncoder.h264Delegate respondsToSelector:@selector(videoEncoder:videoFrame:)])&#123;</span><br><span class=\"line\">                [videoEncoder.h264Delegate videoEncoder:videoEncoder videoFrame:videoFrame];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            </span><br><span class=\"line\">            if(videoEncoder-&gt;enabledWriteVideoFile)&#123;</span><br><span class=\"line\">                NSMutableData *data = [[NSMutableData alloc] init];</span><br><span class=\"line\">                if(keyframe)&#123;</span><br><span class=\"line\">                    uint8_t header[] = &#123;0x00,0x00,0x00,0x01&#125;;</span><br><span class=\"line\">                    [data appendBytes:header length:4];</span><br><span class=\"line\">                &#125;else&#123;</span><br><span class=\"line\">                    uint8_t header[] = &#123;0x00,0x00,0x01&#125;;</span><br><span class=\"line\">                    [data appendBytes:header length:3];</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                [data appendData:videoFrame.data];</span><br><span class=\"line\">                fwrite(data.bytes, 1,data.length,videoEncoder-&gt;fp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            bufferOffset += AVCCHeaderLength + NALUnitLength;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"iOS软编码-待续\"><a href=\"#iOS软编码-待续\" class=\"headerlink\" title=\"iOS软编码(待续)\"></a>iOS软编码(待续)</h2><p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>\n","site":{"data":{}},"excerpt":"<p>&emsp;&emsp;x264是一种免费的、具有更优秀算法的符合H.264/MPEG-4 AVC视频压缩编码标准格式的编码库。它同xvid一样都是开源项目，但x264是采用H.264标准的，而xvid是采用MPEG-4早期标准的。由于H.264是2003年正式发布的最新的视频编码标准，因此，在通常情况下，x264压缩出的视频文件在相同质量下要比xvid压缩出的文件要小，或者也可以说，在相同体积下比xvid压缩出的文件质量要好。它符合GPL许可证。<br>","more":"<br>&emsp;&emsp;iOS视频编码分为硬编码和软编码：硬编码就是利用手机专用的硬件进行编码，软编码是用CPU进行编码。由于苹果在iOS8开放的硬编码的API，故现在大多数的直播应用都是采用的硬编码。</p>\n<h2 id=\"iOS硬编码\"><a href=\"#iOS硬编码\" class=\"headerlink\" title=\"iOS硬编码\"></a>iOS硬编码</h2><p> &emsp;&emsp;从iOS8开始，苹果开放了硬解码和硬编码API，框架为 VideoToolbox.framework， 此框架需要在iOS8及以上的系统上才能使用。<br>       此框架中的硬解码API是几个纯C函数，在任何OC或者 C++代码里都可以使用。使用的时候，首先，要把VideoToolbox.framework 添加到工程里，并且在要使用该API的文件中包含头文件#include &lt;VideoToolbox/VideoToolbox.h&gt;，然后，就可以畅快的高效的对视频流进行硬编码了。</p>\n<p>直接上代码来说明，首先是定义了编码所需的变量<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@interface CLHardwareVideoEncoder ()&#123;</span><br><span class=\"line\">    VTCompressionSessionRef compressionSession;</span><br><span class=\"line\">    NSInteger frameCount;</span><br><span class=\"line\">    NSData *sps;</span><br><span class=\"line\">    NSData *pps;</span><br><span class=\"line\">    FILE *fp;</span><br><span class=\"line\">    BOOL enabledWriteVideoFile;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">@property (nonatomic, strong) CLLiveVideoConfiguration *configuration;</span><br><span class=\"line\">@property (nonatomic,weak) id&lt;CLVideoEncodingDelegate&gt; h264Delegate;</span><br><span class=\"line\">@property (nonatomic) BOOL isBackGround;</span><br><span class=\"line\">@property (nonatomic) NSInteger currentVideoBitRate;</span><br><span class=\"line\"></span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure></p>\n<p>初始化编码session<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)initCompressionSession&#123;</span><br><span class=\"line\">    if(compressionSession)&#123;</span><br><span class=\"line\">        VTCompressionSessionCompleteFrames(compressionSession, kCMTimeInvalid);</span><br><span class=\"line\">        </span><br><span class=\"line\">        VTCompressionSessionInvalidate(compressionSession);</span><br><span class=\"line\">        CFRelease(compressionSession);</span><br><span class=\"line\">        compressionSession = NULL;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    OSStatus status = VTCompressionSessionCreate(NULL, _configuration.videoSize.width, _configuration.videoSize.height, kCMVideoCodecType_H264, NULL, NULL, NULL, VideoCompressonOutputCallback, (__bridge void *)self, &amp;compressionSession);</span><br><span class=\"line\">    if(status != noErr)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    _currentVideoBitRate = _configuration.videoBitRate;</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameInterval,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration,(__bridge CFTypeRef)@(_configuration.videoMaxKeyframeInterval));</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ExpectedFrameRate, (__bridge CFTypeRef)@(_configuration.videoFrameRate));</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AverageBitRate, (__bridge CFTypeRef)@(_configuration.videoBitRate));</span><br><span class=\"line\">    NSArray *limit = @[@(_configuration.videoBitRate * 1.5/8),@(1)];</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_DataRateLimits, (__bridge CFArrayRef)limit);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_RealTime, kCFBooleanFalse);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_ProfileLevel, kVTProfileLevel_H264_Main_AutoLevel);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_AllowFrameReordering, kCFBooleanFalse);</span><br><span class=\"line\">    VTSessionSetProperty(compressionSession, kVTCompressionPropertyKey_H264EntropyMode, kVTH264EntropyMode_CABAC);</span><br><span class=\"line\">    VTCompressionSessionPrepareToEncodeFrames(compressionSession);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>编码输入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- (void)encodeVideoData:(CVImageBufferRef)pixelBuffer timeStamp:(uint64_t)timeStamp&#123;</span><br><span class=\"line\">    if(_isBackGround) return;</span><br><span class=\"line\">    </span><br><span class=\"line\">    frameCount ++;</span><br><span class=\"line\">    CMTime presentationTimeStamp = CMTimeMake(frameCount, (int32_t)_configuration.videoFrameRate);</span><br><span class=\"line\">    VTEncodeInfoFlags flags;</span><br><span class=\"line\">    CMTime duration = CMTimeMake(1, (int32_t)_configuration.videoFrameRate);</span><br><span class=\"line\">    </span><br><span class=\"line\">    NSDictionary *properties = nil;</span><br><span class=\"line\">    if(frameCount % (int32_t)_configuration.videoMaxKeyframeInterval == 0)&#123;</span><br><span class=\"line\">        properties = @&#123;(__bridge NSString *)kVTEncodeFrameOptionKey_ForceKeyFrame: @YES&#125;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    NSNumber *timeNumber = @(timeStamp);</span><br><span class=\"line\">    </span><br><span class=\"line\">    VTCompressionSessionEncodeFrame(compressionSession, pixelBuffer, presentationTimeStamp, duration, (__bridge CFDictionaryRef)properties, (__bridge_retained void *)timeNumber, &amp;flags);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>回调<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static void VideoCompressonOutputCallback(void *VTref, void *VTFrameRef, OSStatus status, VTEncodeInfoFlags infoFlags, CMSampleBufferRef sampleBuffer)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    if(!sampleBuffer) return;</span><br><span class=\"line\">    CFArrayRef array = CMSampleBufferGetSampleAttachmentsArray(sampleBuffer, true);</span><br><span class=\"line\">    if(!array) return;</span><br><span class=\"line\">    CFDictionaryRef dic = (CFDictionaryRef)CFArrayGetValueAtIndex(array, 0);</span><br><span class=\"line\">    if(!dic) return;</span><br><span class=\"line\">    </span><br><span class=\"line\">    BOOL keyframe = !CFDictionaryContainsKey(dic, kCMSampleAttachmentKey_NotSync);</span><br><span class=\"line\">    uint64_t timeStamp = [((__bridge_transfer NSNumber*)VTFrameRef) longLongValue];</span><br><span class=\"line\">    </span><br><span class=\"line\">    CLHardwareVideoEncoder *videoEncoder = (__bridge CLHardwareVideoEncoder *)VTref;</span><br><span class=\"line\">    if(status != noErr)&#123;</span><br><span class=\"line\">        return;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    if (keyframe &amp;&amp; !videoEncoder-&gt;sps)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        CMFormatDescriptionRef format = CMSampleBufferGetFormatDescription(sampleBuffer);</span><br><span class=\"line\">        </span><br><span class=\"line\">        size_t sparameterSetSize, sparameterSetCount;</span><br><span class=\"line\">        const uint8_t *sparameterSet;</span><br><span class=\"line\">        OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 0, &amp;sparameterSet, &amp;sparameterSetSize, &amp;sparameterSetCount, 0 );</span><br><span class=\"line\">        if (statusCode == noErr)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            size_t pparameterSetSize, pparameterSetCount;</span><br><span class=\"line\">            const uint8_t *pparameterSet;</span><br><span class=\"line\">            OSStatus statusCode = CMVideoFormatDescriptionGetH264ParameterSetAtIndex(format, 1, &amp;pparameterSet, &amp;pparameterSetSize, &amp;pparameterSetCount, 0 );</span><br><span class=\"line\">            if (statusCode == noErr)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                videoEncoder-&gt;sps = [NSData dataWithBytes:sparameterSet length:sparameterSetSize];</span><br><span class=\"line\">                videoEncoder-&gt;pps = [NSData dataWithBytes:pparameterSet length:pparameterSetSize];</span><br><span class=\"line\">                </span><br><span class=\"line\">                if(videoEncoder-&gt;enabledWriteVideoFile)&#123;</span><br><span class=\"line\">                    NSMutableData *data = [[NSMutableData alloc] init];</span><br><span class=\"line\">                    uint8_t header[] = &#123;0x00,0x00,0x00,0x01&#125;;</span><br><span class=\"line\">                    [data appendBytes:header length:4];</span><br><span class=\"line\">                    [data appendData:videoEncoder-&gt;sps];</span><br><span class=\"line\">                    [data appendBytes:header length:4];</span><br><span class=\"line\">                    [data appendData:videoEncoder-&gt;pps];</span><br><span class=\"line\">                    fwrite(data.bytes, 1,data.length,videoEncoder-&gt;fp);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    CMBlockBufferRef dataBuffer = CMSampleBufferGetDataBuffer(sampleBuffer);</span><br><span class=\"line\">    size_t length, totalLength;</span><br><span class=\"line\">    char *dataPointer;</span><br><span class=\"line\">    OSStatus statusCodeRet = CMBlockBufferGetDataPointer(dataBuffer, 0, &amp;length, &amp;totalLength, &amp;dataPointer);</span><br><span class=\"line\">    if (statusCodeRet == noErr) &#123;</span><br><span class=\"line\">        size_t bufferOffset = 0;</span><br><span class=\"line\">        static const int AVCCHeaderLength = 4;</span><br><span class=\"line\">        while (bufferOffset &lt; totalLength - AVCCHeaderLength) &#123;</span><br><span class=\"line\">            // Read the NAL unit length</span><br><span class=\"line\">            uint32_t NALUnitLength = 0;</span><br><span class=\"line\">            memcpy(&amp;NALUnitLength, dataPointer + bufferOffset, AVCCHeaderLength);</span><br><span class=\"line\">            </span><br><span class=\"line\">            NALUnitLength = CFSwapInt32BigToHost(NALUnitLength);</span><br><span class=\"line\"></span><br><span class=\"line\">            CLVideoFrame *videoFrame = [CLVideoFrame new];</span><br><span class=\"line\">            videoFrame.timestamp = timeStamp;</span><br><span class=\"line\">            videoFrame.data = [[NSData alloc] initWithBytes:(dataPointer + bufferOffset + AVCCHeaderLength) length:NALUnitLength];</span><br><span class=\"line\">            videoFrame.isKeyFrame = keyframe;</span><br><span class=\"line\">            videoFrame.sps = videoEncoder-&gt;sps;</span><br><span class=\"line\">            videoFrame.pps = videoEncoder-&gt;pps;</span><br><span class=\"line\">            </span><br><span class=\"line\">            if(videoEncoder.h264Delegate &amp;&amp; [videoEncoder.h264Delegate respondsToSelector:@selector(videoEncoder:videoFrame:)])&#123;</span><br><span class=\"line\">                [videoEncoder.h264Delegate videoEncoder:videoEncoder videoFrame:videoFrame];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            </span><br><span class=\"line\">            if(videoEncoder-&gt;enabledWriteVideoFile)&#123;</span><br><span class=\"line\">                NSMutableData *data = [[NSMutableData alloc] init];</span><br><span class=\"line\">                if(keyframe)&#123;</span><br><span class=\"line\">                    uint8_t header[] = &#123;0x00,0x00,0x00,0x01&#125;;</span><br><span class=\"line\">                    [data appendBytes:header length:4];</span><br><span class=\"line\">                &#125;else&#123;</span><br><span class=\"line\">                    uint8_t header[] = &#123;0x00,0x00,0x01&#125;;</span><br><span class=\"line\">                    [data appendBytes:header length:3];</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                [data appendData:videoFrame.data];</span><br><span class=\"line\">                fwrite(data.bytes, 1,data.length,videoEncoder-&gt;fp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            bufferOffset += AVCCHeaderLength + NALUnitLength;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"iOS软编码-待续\"><a href=\"#iOS软编码-待续\" class=\"headerlink\" title=\"iOS软编码(待续)\"></a>iOS软编码(待续)</h2><p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>"},{"title":"链式编程思想理解","date":"2016-06-20T06:04:21.000Z","_content":"先简单介绍下目前咱们已知的编程思想。  \n> * 1、面向过程：处理事情以过程为核心，一步一步的实现。  \n> * 2、面向对象：万物皆对象。  \n> * 3、链式编程思想：是将多个操作（多行代码）通过点号（.）链接在一起成为一句代码，使代码可读性好。比如：a(1).b(2).c(3)。  \n<!--more-->\n链式编程特点：方法的返回值是block、block必须有返回值（返回对象本身）、block参数（需要操作的值）。  \n代表：Masonry框架。 \n> * 4、响应式编程思想：不需要考虑调用顺序，只需要知道考虑结果，类似于蝴蝶效应，产生一个事件，会影响很多东西，这些事件像流一样的传播出去，然后影响结果，借用面向对象的一句话，万物皆是流。  \n代表：KVO运用。  \n> * 5、函数式编程思想：是把操作尽量写成一系列嵌套的函数或者方法调用。  \n函数式编程特点：每个方法必须有返回值（返回对象本身）、把函数或者Block当做参数、block参数（需要操作的值），block返回值（操作结果）。  \n代表：ReactiveCocoa。\n\n我们这里以链式编程思想代码实现一个计算器:\n\n```\n#import\n@class CaculatorMaker;\n@interface NSObject (CaculatorMaker)\n//计算\n+ (int)makeCaculators:(void(^)(CaculatorMaker *make))caculatorMaker;\n@end\n```\n\n```\n#import \"NSObject+CaculatorMaker.h\"\n#import \"CaculatorMaker.h\"\n@implementation NSObject (CaculatorMaker)\n//计算\n+ (int)makeCaculators:(void(^)(CaculatorMaker *make))block\n{\n    CaculatorMaker *mgr = [[CaculatorMaker alloc] init];\n    block(mgr);\n    return mgr.iResult;\n}\n@end\n```\n\n```\n#import\n@interface CaculatorMaker : NSObject\n@property (nonatomic, assign) int iResult;\n//加法\n- (CaculatorMaker *(^)(int))add;\n//减法\n- (CaculatorMaker *(^)(int))sub;\n//乘法\n- (CaculatorMaker *(^)(int))muilt;\n//除法\n- (CaculatorMaker *(^)(int))divide;\n@end\n```\n\n```\n#import \"CaculatorMaker.h\"\n@implementation CaculatorMaker\n- (CaculatorMaker *(^)(int))add\n{\n   return ^(int value)\n    {\n        _iResult += value;\n        return self;\n    };\n}\n@end\n```\n\n\n调用：\n\n```\nint iResult = [NSObject makeCaculators:^(CaculatorMaker *make) {\n     make.add(1).add(2).add(3).divide(2);\n   }];\n```\n\n分析下这个方法执行过程：  \n第一步：NSObject创建了一个block, 这个block里创建了一个CaculatorMaker对象make，并返回出来  \n第二步：这个对象make调用方法add时，里面持有的属性iResult做了一个加法，并且返回自己，以便可以接下去继续调用方法。   \n这就是链式编程思想的一个很小但很明了的例子。 \n [Demo](https://github.com/chenhu1001/Caculator)\n \nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","source":"_posts/链式编程思想理解.md","raw":"---\ntitle: 链式编程思想理解\ndate: 2016-06-20 14:04:21\ncategories: iOS\ntags: [iOS]\n---\n先简单介绍下目前咱们已知的编程思想。  \n> * 1、面向过程：处理事情以过程为核心，一步一步的实现。  \n> * 2、面向对象：万物皆对象。  \n> * 3、链式编程思想：是将多个操作（多行代码）通过点号（.）链接在一起成为一句代码，使代码可读性好。比如：a(1).b(2).c(3)。  \n<!--more-->\n链式编程特点：方法的返回值是block、block必须有返回值（返回对象本身）、block参数（需要操作的值）。  \n代表：Masonry框架。 \n> * 4、响应式编程思想：不需要考虑调用顺序，只需要知道考虑结果，类似于蝴蝶效应，产生一个事件，会影响很多东西，这些事件像流一样的传播出去，然后影响结果，借用面向对象的一句话，万物皆是流。  \n代表：KVO运用。  \n> * 5、函数式编程思想：是把操作尽量写成一系列嵌套的函数或者方法调用。  \n函数式编程特点：每个方法必须有返回值（返回对象本身）、把函数或者Block当做参数、block参数（需要操作的值），block返回值（操作结果）。  \n代表：ReactiveCocoa。\n\n我们这里以链式编程思想代码实现一个计算器:\n\n```\n#import\n@class CaculatorMaker;\n@interface NSObject (CaculatorMaker)\n//计算\n+ (int)makeCaculators:(void(^)(CaculatorMaker *make))caculatorMaker;\n@end\n```\n\n```\n#import \"NSObject+CaculatorMaker.h\"\n#import \"CaculatorMaker.h\"\n@implementation NSObject (CaculatorMaker)\n//计算\n+ (int)makeCaculators:(void(^)(CaculatorMaker *make))block\n{\n    CaculatorMaker *mgr = [[CaculatorMaker alloc] init];\n    block(mgr);\n    return mgr.iResult;\n}\n@end\n```\n\n```\n#import\n@interface CaculatorMaker : NSObject\n@property (nonatomic, assign) int iResult;\n//加法\n- (CaculatorMaker *(^)(int))add;\n//减法\n- (CaculatorMaker *(^)(int))sub;\n//乘法\n- (CaculatorMaker *(^)(int))muilt;\n//除法\n- (CaculatorMaker *(^)(int))divide;\n@end\n```\n\n```\n#import \"CaculatorMaker.h\"\n@implementation CaculatorMaker\n- (CaculatorMaker *(^)(int))add\n{\n   return ^(int value)\n    {\n        _iResult += value;\n        return self;\n    };\n}\n@end\n```\n\n\n调用：\n\n```\nint iResult = [NSObject makeCaculators:^(CaculatorMaker *make) {\n     make.add(1).add(2).add(3).divide(2);\n   }];\n```\n\n分析下这个方法执行过程：  \n第一步：NSObject创建了一个block, 这个block里创建了一个CaculatorMaker对象make，并返回出来  \n第二步：这个对象make调用方法add时，里面持有的属性iResult做了一个加法，并且返回自己，以便可以接下去继续调用方法。   \n这就是链式编程思想的一个很小但很明了的例子。 \n [Demo](https://github.com/chenhu1001/Caculator)\n \nClang的技术博客：[https://chenhu1001.github.io](https://chenhu1001.github.io)\n\n","slug":"链式编程思想理解","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1j0010n5xfhys9terp","content":"<p>先简单介绍下目前咱们已知的编程思想。  </p>\n<blockquote>\n<ul>\n<li>1、面向过程：处理事情以过程为核心，一步一步的实现。  </li>\n<li>2、面向对象：万物皆对象。  </li>\n<li>3、链式编程思想：是将多个操作（多行代码）通过点号（.）链接在一起成为一句代码，使代码可读性好。比如：a(1).b(2).c(3)。  <a id=\"more\"></a>\n链式编程特点：方法的返回值是block、block必须有返回值（返回对象本身）、block参数（需要操作的值）。<br>代表：Masonry框架。 </li>\n<li>4、响应式编程思想：不需要考虑调用顺序，只需要知道考虑结果，类似于蝴蝶效应，产生一个事件，会影响很多东西，这些事件像流一样的传播出去，然后影响结果，借用面向对象的一句话，万物皆是流。<br>代表：KVO运用。  </li>\n<li>5、函数式编程思想：是把操作尽量写成一系列嵌套的函数或者方法调用。<br>函数式编程特点：每个方法必须有返回值（返回对象本身）、把函数或者Block当做参数、block参数（需要操作的值），block返回值（操作结果）。<br>代表：ReactiveCocoa。</li>\n</ul>\n</blockquote>\n<p>我们这里以链式编程思想代码实现一个计算器:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import</span><br><span class=\"line\">@class CaculatorMaker;</span><br><span class=\"line\">@interface NSObject (CaculatorMaker)</span><br><span class=\"line\">//计算</span><br><span class=\"line\">+ (int)makeCaculators:(void(^)(CaculatorMaker *make))caculatorMaker;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &quot;NSObject+CaculatorMaker.h&quot;</span><br><span class=\"line\">#import &quot;CaculatorMaker.h&quot;</span><br><span class=\"line\">@implementation NSObject (CaculatorMaker)</span><br><span class=\"line\">//计算</span><br><span class=\"line\">+ (int)makeCaculators:(void(^)(CaculatorMaker *make))block</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    CaculatorMaker *mgr = [[CaculatorMaker alloc] init];</span><br><span class=\"line\">    block(mgr);</span><br><span class=\"line\">    return mgr.iResult;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import</span><br><span class=\"line\">@interface CaculatorMaker : NSObject</span><br><span class=\"line\">@property (nonatomic, assign) int iResult;</span><br><span class=\"line\">//加法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))add;</span><br><span class=\"line\">//减法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))sub;</span><br><span class=\"line\">//乘法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))muilt;</span><br><span class=\"line\">//除法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))divide;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &quot;CaculatorMaker.h&quot;</span><br><span class=\"line\">@implementation CaculatorMaker</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))add</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">   return ^(int value)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        _iResult += value;</span><br><span class=\"line\">        return self;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>调用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int iResult = [NSObject makeCaculators:^(CaculatorMaker *make) &#123;</span><br><span class=\"line\">     make.add(1).add(2).add(3).divide(2);</span><br><span class=\"line\">   &#125;];</span><br></pre></td></tr></table></figure>\n<p>分析下这个方法执行过程：<br>第一步：NSObject创建了一个block, 这个block里创建了一个CaculatorMaker对象make，并返回出来<br>第二步：这个对象make调用方法add时，里面持有的属性iResult做了一个加法，并且返回自己，以便可以接下去继续调用方法。<br>这就是链式编程思想的一个很小但很明了的例子。<br> <a href=\"https://github.com/chenhu1001/Caculator\" target=\"_blank\" rel=\"noopener\">Demo</a></p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>\n","site":{"data":{}},"excerpt":"<p>先简单介绍下目前咱们已知的编程思想。  </p>\n<blockquote>\n<ul>\n<li>1、面向过程：处理事情以过程为核心，一步一步的实现。  </li>\n<li>2、面向对象：万物皆对象。  </li>\n<li>3、链式编程思想：是将多个操作（多行代码）通过点号（.）链接在一起成为一句代码，使代码可读性好。比如：a(1).b(2).c(3)。","more":"链式编程特点：方法的返回值是block、block必须有返回值（返回对象本身）、block参数（需要操作的值）。<br>代表：Masonry框架。 </li>\n<li>4、响应式编程思想：不需要考虑调用顺序，只需要知道考虑结果，类似于蝴蝶效应，产生一个事件，会影响很多东西，这些事件像流一样的传播出去，然后影响结果，借用面向对象的一句话，万物皆是流。<br>代表：KVO运用。  </li>\n<li>5、函数式编程思想：是把操作尽量写成一系列嵌套的函数或者方法调用。<br>函数式编程特点：每个方法必须有返回值（返回对象本身）、把函数或者Block当做参数、block参数（需要操作的值），block返回值（操作结果）。<br>代表：ReactiveCocoa。</li>\n</ul>\n</blockquote>\n<p>我们这里以链式编程思想代码实现一个计算器:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import</span><br><span class=\"line\">@class CaculatorMaker;</span><br><span class=\"line\">@interface NSObject (CaculatorMaker)</span><br><span class=\"line\">//计算</span><br><span class=\"line\">+ (int)makeCaculators:(void(^)(CaculatorMaker *make))caculatorMaker;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &quot;NSObject+CaculatorMaker.h&quot;</span><br><span class=\"line\">#import &quot;CaculatorMaker.h&quot;</span><br><span class=\"line\">@implementation NSObject (CaculatorMaker)</span><br><span class=\"line\">//计算</span><br><span class=\"line\">+ (int)makeCaculators:(void(^)(CaculatorMaker *make))block</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    CaculatorMaker *mgr = [[CaculatorMaker alloc] init];</span><br><span class=\"line\">    block(mgr);</span><br><span class=\"line\">    return mgr.iResult;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import</span><br><span class=\"line\">@interface CaculatorMaker : NSObject</span><br><span class=\"line\">@property (nonatomic, assign) int iResult;</span><br><span class=\"line\">//加法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))add;</span><br><span class=\"line\">//减法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))sub;</span><br><span class=\"line\">//乘法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))muilt;</span><br><span class=\"line\">//除法</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))divide;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#import &quot;CaculatorMaker.h&quot;</span><br><span class=\"line\">@implementation CaculatorMaker</span><br><span class=\"line\">- (CaculatorMaker *(^)(int))add</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">   return ^(int value)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        _iResult += value;</span><br><span class=\"line\">        return self;</span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">@end</span><br></pre></td></tr></table></figure>\n<p>调用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">int iResult = [NSObject makeCaculators:^(CaculatorMaker *make) &#123;</span><br><span class=\"line\">     make.add(1).add(2).add(3).divide(2);</span><br><span class=\"line\">   &#125;];</span><br></pre></td></tr></table></figure>\n<p>分析下这个方法执行过程：<br>第一步：NSObject创建了一个block, 这个block里创建了一个CaculatorMaker对象make，并返回出来<br>第二步：这个对象make调用方法add时，里面持有的属性iResult做了一个加法，并且返回自己，以便可以接下去继续调用方法。<br>这就是链式编程思想的一个很小但很明了的例子。<br> <a href=\"https://github.com/chenhu1001/Caculator\" target=\"_blank\" rel=\"noopener\">Demo</a></p>\n<p>Clang的技术博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a></p>"},{"title":"函数式响应式编程（FRP）的基本理解","date":"2016-06-21T06:05:01.000Z","_content":"## 理念\n&emsp;&emsp;所有的程序都是为了完成某些任务。大多数程序员所受的训练都是命令式编程。这种模式依赖于他们希望自己的程序如何来完成这些任务：开发者编写很多的指令来修正程序的状态；如果开发者在正确的位置上编写了正确的指令，那么程序将会正确的完成任务。 \n<!--more-->\n&emsp;&emsp;这听起来很平凡。。。  \n&emsp;&emsp;为什么编程时我们思考问题的方式停留在“怎么做”这个点上？因为计算机实际上是以一条命令来工作的，CPU的程序计算尽职尽责，按部就班：读取（指令）->执行->读取->执行。。。所以理所当然的，我们只要告诉他们“怎么做”就好了（即命令式编程）。。。多么的无聊  \n&emsp;&emsp;与此相反，声明式编程（Declarative Programming）将程序员们从纷繁复杂的对如何完成某些任务的细枝末节的流程中解放出来，将关注点集中在任务到底“是什么”而非实现任务的流程。声明式编程是命令式编程之外的几种编程范式的一个总称。  \n&emsp;&emsp;声明式编程（Declarative Programming）是一种编程范性，与命令式编程相对立。它描述目标的性质，让电脑明白目标，而非流程。而指令式编程则需要用算法来明确的指出每一步该怎么做。函数式响应式编程是声明式编程的子编程范式之一。  \n\n## 函数式编程\n&emsp;&emsp;在高效地进行函数式响应式编程之前，我们首先需要理解函数式编程。\n### 1、高阶函数\n&emsp;&emsp;函数式编程的一个关键概念是“高阶函数”。从维基百科的解释来看，一个高阶函数需要满足下面两个条件： 1、一个或者多个函数作为输入。  2、有且仅有一个函数输出。  \n&emsp;&emsp;在Objective-c中我们经常使用block作为函数。我们不需要跋山涉水地去寻找‘高阶函数’，实际上，Apple为我们提供的Foundation库中就有。考虑象下面这么简单的一个NSNumber 的数组：\n\n```\nNSArray * array = @[ @(1), @(2), @(3) ];\n```\n\n我们想要枚举这个数组的内容，利用数组元素来做些事情。\n“好吧”，你说， “我将写一个for循环～”\n住手吧，伙计，停止写for循环,好好看看我之前说的，我们可以用一个NSArray的高阶函数来代替。代码如下：\n\n```\nfor (NSNumber *number in array) NSLog(@\"%@\",number);\n```\n\n这个等同于下面的高阶函数:\n\n\n```\n[array enumerateObjectsUsingBlock:^(NSNumber *number, NSUInteger idx, BOOL *stop)\n{\n    NSLog(@\"%@\",number);\n}];\n```\n\n### 2、高阶映射\n&emsp;&emsp;我们要学习的第一个高阶函数是'映射[map]'.映射是在函数的层次上把一个列表变成相同长度的另一个列表，原始列表中的每一个值，在新的列表中都有一个对应的值。如下所示是一个平方数的映射：\n\n```\nmap(1,2,3) => (1,4,9)\n```\n\n&emsp;&emsp;当然，这只是一个伪代码，一个高阶函数会返回另外一个函数而不是一个列表。那么我们要如何利用RXCollections呢?\n&emsp;&emsp;我们这么来用rx_mapWithBlock:方法：\n\n```\nNSArray * mappedArray = [array rx_mapWithBlock:^id(id each){\n    return @(pow([each integerValue],2));\n}];\n```\n\n&emsp;&emsp;这将会达成上面伪代码所完成的任务，如果我们打印出array的日志，我们将会看到如下内容:\n\n```\n(\n    1，\n    4，\n    9\n)\n```\n\n&emsp;&emsp;简直完美!请注意rx_mapWithBlock: 并不是一个真正的函数映射，因为他不是技术上的高阶函数(她没有返回一个函数)。后面提到的库(RAC)已经解决了这一点,在下一章我们将看到映射是如何在ReactiveCocoa的上下文中工作的。  \n&emsp;&emsp;注意rx_mapWithBlock:在没有对原数组元素进行任何修改的前提下返回了一个新的数组，这里Foundation的类真的是非常好用的一个例子，因为他们的类默认就是不可变的。  \n想象一下，往常(命令式编程)为了完成这个任务，我们不得不写下这样的代码:\n\n```\nNSMutableArray *mutableArray = [NSMutableArray arryaWithCapacity:array.count];\nfor (NSNumber *number in array) [mutableArray addObject:@(pow([number integerValue], 2))];\nNSArray *mappedArray = [NSArray arrayWithArray: mutableArray];\n```\n\n&emsp;&emsp;代码显然更多，而且还有一个无用的局部变量mutableArray污染了我们的作用域，简直是个毛线！  \n所以当你想把一个列表里的元素转化为另一个列表的元素时，你就能体会到映射的强大。\n### 3、高阶过滤\n&emsp;&emsp;谈到ReactiveCocoa，我们要使用的另一种关键的高阶函数就是过滤器。一个列表通过过滤能够返回一个只包含了原列表中符合条件的元素的新列表，具体我们来看实践中的例子:\n\n```\nNSArray *filteredArray = [array rx_filterWithBlock:^BOOL(id each){\n    return ([each integerValue] % 2 == 0);\n}]\n```\n\n&emsp;&emsp;过滤后，现在filteredArray等于@[ @2 ].如果没有这样的抽象方法(即高阶过滤)，我们不得不像下面这样来完成工作:\n\n```\nNSMutableArray *mutableArray = [NSMutableArray arrayWithCapacity: array.count];\nfor ( NSNumber * number in array ){\n    if ( [number integerValue] % 2 == 0 ){\n        [mutableArray addObject:number];\n    }\n}\nNSArray *filteredArray = [NSArray arrayWithArray:mutableArray];\n```\n\n&emsp;&emsp;有点明白了,对不对? 你可能像上面这样子写代码写了成百上千次。我们每一天的工作中涉及到类似这种高阶映射或者高阶过滤的事情有多少? 非常多！通过使用像高阶过滤、高阶映射类似的高阶函数，我们能够把这种繁琐又乏味的任务抽象出来，轻松工作，轻松生活。。。\n### 4、高阶折叠\n&emsp;&emsp;Flod 是一个有趣的高阶函数－她把列表中的所有元素变成一个值。一个简单的高阶折叠能够用来给数值数组求和。\n\n```\nNSNumber * sum = [array rx_foldWithBlock:^ id (id memo , id each){\n    return @([memo integerValue] + [each integerValue]);\n}];\n```\n\n&emsp;&emsp;输出的值为@6.数组中的每一个元素按顺序执行上述合并规则:[memo integerValue] + [each integerValue],其中memo参数纪录的是上一次合并后的结果，其初始值为零。这还不是很有趣，有趣的是我们还能给memo(这个参数的泛称)赋初始值:\n\n```\n[[array rx_mapWithBlock:^id (id each){\n        return [each stringValue];\n    }] rx_foldInitialValue:@\"\" block:^id (id memo , id each){\n        return [memo stringByAppendingString:each];\n}];\n```\n\n&emsp;&emsp;代码的结果:@“123”. 我们来分析一下这是怎么做到的. 首先我们对数组中的所有NSNumber对象做了映射，把他们变成了NSString对象，然后我们实现了一个高阶折叠，并给了memo变量一个空字符串。  \n       在没有RXCollections的情况下能得到这样的结果吗？当然可以。但这是一个明确的\"是什么，而不是如何\"的解决问题的方法。这种方法可以让我们不必跟CPU一样去想\"这一步要如何，下一步要如何\"类似这样的事情。写代码的时候如此，读代码的时候更是如此(意:更多地关注任务是什么，要达成什么目标)\n### 5、性能\n&emsp;&emsp;这一章有关函数式编程的事例代码可能会让你开始担心性能的问题。例如，在一个长数组中，给每个元素创建一个过渡的字符描述并把他们追加到前面的结果中去，比起命令式编程来说，可能需要消耗更长的时间。  \n&emsp;&emsp;这可能是个问题，但幸运的是，现在的计算机(甚至iPhone手机)性能已经足够强大，在大多数情况下，这种性能损耗是无关紧要的，况且当这种损耗变成一个性能瓶颈的时候，你随时都可以回头去优化她让她更加高效。CPU的时间很廉价，但是你的时间是很宝贵，因此牺牲CPU的时间会是更好的选择。\n### 6、总结\n&emsp;&emsp;我们使用RXCollections后不需要额外的可变变量就可以在列表上进行操作，虽然RXCollections可能隐式地生成了这样的可变变量来完成任务，但是这不是我们要关心的，因为它已经为我们抽象出了这样的方式，通过:mapping、filtering和folding这种方式让我们不必在意实现任务的步骤。(当然，这并不是说，我们不应该熟悉RXCollections的源码，只是告诉你不必按部就班地去完成任务了)  \n在最后，我们也看到了，使用链式操作一次可以输出一个更为复杂的逻辑操作的结果。下一章我们将谈论更多的有关链式操作的内容———实际上，它是ReactiveCocoa中的重要语法之一。\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","source":"_posts/函数式响应式编程（FRP）的基本理解.md","raw":"---\ntitle: 函数式响应式编程（FRP）的基本理解\ndate: 2016-06-21 14:05:01\ncategories: iOS\ntags: [iOS]\n---\n## 理念\n&emsp;&emsp;所有的程序都是为了完成某些任务。大多数程序员所受的训练都是命令式编程。这种模式依赖于他们希望自己的程序如何来完成这些任务：开发者编写很多的指令来修正程序的状态；如果开发者在正确的位置上编写了正确的指令，那么程序将会正确的完成任务。 \n<!--more-->\n&emsp;&emsp;这听起来很平凡。。。  \n&emsp;&emsp;为什么编程时我们思考问题的方式停留在“怎么做”这个点上？因为计算机实际上是以一条命令来工作的，CPU的程序计算尽职尽责，按部就班：读取（指令）->执行->读取->执行。。。所以理所当然的，我们只要告诉他们“怎么做”就好了（即命令式编程）。。。多么的无聊  \n&emsp;&emsp;与此相反，声明式编程（Declarative Programming）将程序员们从纷繁复杂的对如何完成某些任务的细枝末节的流程中解放出来，将关注点集中在任务到底“是什么”而非实现任务的流程。声明式编程是命令式编程之外的几种编程范式的一个总称。  \n&emsp;&emsp;声明式编程（Declarative Programming）是一种编程范性，与命令式编程相对立。它描述目标的性质，让电脑明白目标，而非流程。而指令式编程则需要用算法来明确的指出每一步该怎么做。函数式响应式编程是声明式编程的子编程范式之一。  \n\n## 函数式编程\n&emsp;&emsp;在高效地进行函数式响应式编程之前，我们首先需要理解函数式编程。\n### 1、高阶函数\n&emsp;&emsp;函数式编程的一个关键概念是“高阶函数”。从维基百科的解释来看，一个高阶函数需要满足下面两个条件： 1、一个或者多个函数作为输入。  2、有且仅有一个函数输出。  \n&emsp;&emsp;在Objective-c中我们经常使用block作为函数。我们不需要跋山涉水地去寻找‘高阶函数’，实际上，Apple为我们提供的Foundation库中就有。考虑象下面这么简单的一个NSNumber 的数组：\n\n```\nNSArray * array = @[ @(1), @(2), @(3) ];\n```\n\n我们想要枚举这个数组的内容，利用数组元素来做些事情。\n“好吧”，你说， “我将写一个for循环～”\n住手吧，伙计，停止写for循环,好好看看我之前说的，我们可以用一个NSArray的高阶函数来代替。代码如下：\n\n```\nfor (NSNumber *number in array) NSLog(@\"%@\",number);\n```\n\n这个等同于下面的高阶函数:\n\n\n```\n[array enumerateObjectsUsingBlock:^(NSNumber *number, NSUInteger idx, BOOL *stop)\n{\n    NSLog(@\"%@\",number);\n}];\n```\n\n### 2、高阶映射\n&emsp;&emsp;我们要学习的第一个高阶函数是'映射[map]'.映射是在函数的层次上把一个列表变成相同长度的另一个列表，原始列表中的每一个值，在新的列表中都有一个对应的值。如下所示是一个平方数的映射：\n\n```\nmap(1,2,3) => (1,4,9)\n```\n\n&emsp;&emsp;当然，这只是一个伪代码，一个高阶函数会返回另外一个函数而不是一个列表。那么我们要如何利用RXCollections呢?\n&emsp;&emsp;我们这么来用rx_mapWithBlock:方法：\n\n```\nNSArray * mappedArray = [array rx_mapWithBlock:^id(id each){\n    return @(pow([each integerValue],2));\n}];\n```\n\n&emsp;&emsp;这将会达成上面伪代码所完成的任务，如果我们打印出array的日志，我们将会看到如下内容:\n\n```\n(\n    1，\n    4，\n    9\n)\n```\n\n&emsp;&emsp;简直完美!请注意rx_mapWithBlock: 并不是一个真正的函数映射，因为他不是技术上的高阶函数(她没有返回一个函数)。后面提到的库(RAC)已经解决了这一点,在下一章我们将看到映射是如何在ReactiveCocoa的上下文中工作的。  \n&emsp;&emsp;注意rx_mapWithBlock:在没有对原数组元素进行任何修改的前提下返回了一个新的数组，这里Foundation的类真的是非常好用的一个例子，因为他们的类默认就是不可变的。  \n想象一下，往常(命令式编程)为了完成这个任务，我们不得不写下这样的代码:\n\n```\nNSMutableArray *mutableArray = [NSMutableArray arryaWithCapacity:array.count];\nfor (NSNumber *number in array) [mutableArray addObject:@(pow([number integerValue], 2))];\nNSArray *mappedArray = [NSArray arrayWithArray: mutableArray];\n```\n\n&emsp;&emsp;代码显然更多，而且还有一个无用的局部变量mutableArray污染了我们的作用域，简直是个毛线！  \n所以当你想把一个列表里的元素转化为另一个列表的元素时，你就能体会到映射的强大。\n### 3、高阶过滤\n&emsp;&emsp;谈到ReactiveCocoa，我们要使用的另一种关键的高阶函数就是过滤器。一个列表通过过滤能够返回一个只包含了原列表中符合条件的元素的新列表，具体我们来看实践中的例子:\n\n```\nNSArray *filteredArray = [array rx_filterWithBlock:^BOOL(id each){\n    return ([each integerValue] % 2 == 0);\n}]\n```\n\n&emsp;&emsp;过滤后，现在filteredArray等于@[ @2 ].如果没有这样的抽象方法(即高阶过滤)，我们不得不像下面这样来完成工作:\n\n```\nNSMutableArray *mutableArray = [NSMutableArray arrayWithCapacity: array.count];\nfor ( NSNumber * number in array ){\n    if ( [number integerValue] % 2 == 0 ){\n        [mutableArray addObject:number];\n    }\n}\nNSArray *filteredArray = [NSArray arrayWithArray:mutableArray];\n```\n\n&emsp;&emsp;有点明白了,对不对? 你可能像上面这样子写代码写了成百上千次。我们每一天的工作中涉及到类似这种高阶映射或者高阶过滤的事情有多少? 非常多！通过使用像高阶过滤、高阶映射类似的高阶函数，我们能够把这种繁琐又乏味的任务抽象出来，轻松工作，轻松生活。。。\n### 4、高阶折叠\n&emsp;&emsp;Flod 是一个有趣的高阶函数－她把列表中的所有元素变成一个值。一个简单的高阶折叠能够用来给数值数组求和。\n\n```\nNSNumber * sum = [array rx_foldWithBlock:^ id (id memo , id each){\n    return @([memo integerValue] + [each integerValue]);\n}];\n```\n\n&emsp;&emsp;输出的值为@6.数组中的每一个元素按顺序执行上述合并规则:[memo integerValue] + [each integerValue],其中memo参数纪录的是上一次合并后的结果，其初始值为零。这还不是很有趣，有趣的是我们还能给memo(这个参数的泛称)赋初始值:\n\n```\n[[array rx_mapWithBlock:^id (id each){\n        return [each stringValue];\n    }] rx_foldInitialValue:@\"\" block:^id (id memo , id each){\n        return [memo stringByAppendingString:each];\n}];\n```\n\n&emsp;&emsp;代码的结果:@“123”. 我们来分析一下这是怎么做到的. 首先我们对数组中的所有NSNumber对象做了映射，把他们变成了NSString对象，然后我们实现了一个高阶折叠，并给了memo变量一个空字符串。  \n       在没有RXCollections的情况下能得到这样的结果吗？当然可以。但这是一个明确的\"是什么，而不是如何\"的解决问题的方法。这种方法可以让我们不必跟CPU一样去想\"这一步要如何，下一步要如何\"类似这样的事情。写代码的时候如此，读代码的时候更是如此(意:更多地关注任务是什么，要达成什么目标)\n### 5、性能\n&emsp;&emsp;这一章有关函数式编程的事例代码可能会让你开始担心性能的问题。例如，在一个长数组中，给每个元素创建一个过渡的字符描述并把他们追加到前面的结果中去，比起命令式编程来说，可能需要消耗更长的时间。  \n&emsp;&emsp;这可能是个问题，但幸运的是，现在的计算机(甚至iPhone手机)性能已经足够强大，在大多数情况下，这种性能损耗是无关紧要的，况且当这种损耗变成一个性能瓶颈的时候，你随时都可以回头去优化她让她更加高效。CPU的时间很廉价，但是你的时间是很宝贵，因此牺牲CPU的时间会是更好的选择。\n### 6、总结\n&emsp;&emsp;我们使用RXCollections后不需要额外的可变变量就可以在列表上进行操作，虽然RXCollections可能隐式地生成了这样的可变变量来完成任务，但是这不是我们要关心的，因为它已经为我们抽象出了这样的方式，通过:mapping、filtering和folding这种方式让我们不必在意实现任务的步骤。(当然，这并不是说，我们不应该熟悉RXCollections的源码，只是告诉你不必按部就班地去完成任务了)  \n在最后，我们也看到了，使用链式操作一次可以输出一个更为复杂的逻辑操作的结果。下一章我们将谈论更多的有关链式操作的内容———实际上，它是ReactiveCocoa中的重要语法之一。\n\n转载请注明原地址，Clang的博客：https://chenhu1001.github.io 谢谢！","slug":"函数式响应式编程（FRP）的基本理解","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1l0015n5xf5da57m7m","content":"<h2 id=\"理念\"><a href=\"#理念\" class=\"headerlink\" title=\"理念\"></a>理念</h2><p>&emsp;&emsp;所有的程序都是为了完成某些任务。大多数程序员所受的训练都是命令式编程。这种模式依赖于他们希望自己的程序如何来完成这些任务：开发者编写很多的指令来修正程序的状态；如果开发者在正确的位置上编写了正确的指令，那么程序将会正确的完成任务。<br><a id=\"more\"></a><br>&emsp;&emsp;这听起来很平凡。。。<br>&emsp;&emsp;为什么编程时我们思考问题的方式停留在“怎么做”这个点上？因为计算机实际上是以一条命令来工作的，CPU的程序计算尽职尽责，按部就班：读取（指令）-&gt;执行-&gt;读取-&gt;执行。。。所以理所当然的，我们只要告诉他们“怎么做”就好了（即命令式编程）。。。多么的无聊<br>&emsp;&emsp;与此相反，声明式编程（Declarative Programming）将程序员们从纷繁复杂的对如何完成某些任务的细枝末节的流程中解放出来，将关注点集中在任务到底“是什么”而非实现任务的流程。声明式编程是命令式编程之外的几种编程范式的一个总称。<br>&emsp;&emsp;声明式编程（Declarative Programming）是一种编程范性，与命令式编程相对立。它描述目标的性质，让电脑明白目标，而非流程。而指令式编程则需要用算法来明确的指出每一步该怎么做。函数式响应式编程是声明式编程的子编程范式之一。  </p>\n<h2 id=\"函数式编程\"><a href=\"#函数式编程\" class=\"headerlink\" title=\"函数式编程\"></a>函数式编程</h2><p>&emsp;&emsp;在高效地进行函数式响应式编程之前，我们首先需要理解函数式编程。</p>\n<h3 id=\"1、高阶函数\"><a href=\"#1、高阶函数\" class=\"headerlink\" title=\"1、高阶函数\"></a>1、高阶函数</h3><p>&emsp;&emsp;函数式编程的一个关键概念是“高阶函数”。从维基百科的解释来看，一个高阶函数需要满足下面两个条件： 1、一个或者多个函数作为输入。  2、有且仅有一个函数输出。<br>&emsp;&emsp;在Objective-c中我们经常使用block作为函数。我们不需要跋山涉水地去寻找‘高阶函数’，实际上，Apple为我们提供的Foundation库中就有。考虑象下面这么简单的一个NSNumber 的数组：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray * array = @[ @(1), @(2), @(3) ];</span><br></pre></td></tr></table></figure>\n<p>我们想要枚举这个数组的内容，利用数组元素来做些事情。<br>“好吧”，你说， “我将写一个for循环～”<br>住手吧，伙计，停止写for循环,好好看看我之前说的，我们可以用一个NSArray的高阶函数来代替。代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for (NSNumber *number in array) NSLog(@&quot;%@&quot;,number);</span><br></pre></td></tr></table></figure>\n<p>这个等同于下面的高阶函数:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[array enumerateObjectsUsingBlock:^(NSNumber *number, NSUInteger idx, BOOL *stop)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    NSLog(@&quot;%@&quot;,number);</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<h3 id=\"2、高阶映射\"><a href=\"#2、高阶映射\" class=\"headerlink\" title=\"2、高阶映射\"></a>2、高阶映射</h3><p>&emsp;&emsp;我们要学习的第一个高阶函数是’映射[map]’.映射是在函数的层次上把一个列表变成相同长度的另一个列表，原始列表中的每一个值，在新的列表中都有一个对应的值。如下所示是一个平方数的映射：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map(1,2,3) =&gt; (1,4,9)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;当然，这只是一个伪代码，一个高阶函数会返回另外一个函数而不是一个列表。那么我们要如何利用RXCollections呢?<br>&emsp;&emsp;我们这么来用rx_mapWithBlock:方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray * mappedArray = [array rx_mapWithBlock:^id(id each)&#123;</span><br><span class=\"line\">    return @(pow([each integerValue],2));</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这将会达成上面伪代码所完成的任务，如果我们打印出array的日志，我们将会看到如下内容:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(</span><br><span class=\"line\">    1，</span><br><span class=\"line\">    4，</span><br><span class=\"line\">    9</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;简直完美!请注意rx_mapWithBlock: 并不是一个真正的函数映射，因为他不是技术上的高阶函数(她没有返回一个函数)。后面提到的库(RAC)已经解决了这一点,在下一章我们将看到映射是如何在ReactiveCocoa的上下文中工作的。<br>&emsp;&emsp;注意rx_mapWithBlock:在没有对原数组元素进行任何修改的前提下返回了一个新的数组，这里Foundation的类真的是非常好用的一个例子，因为他们的类默认就是不可变的。<br>想象一下，往常(命令式编程)为了完成这个任务，我们不得不写下这样的代码:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSMutableArray *mutableArray = [NSMutableArray arryaWithCapacity:array.count];</span><br><span class=\"line\">for (NSNumber *number in array) [mutableArray addObject:@(pow([number integerValue], 2))];</span><br><span class=\"line\">NSArray *mappedArray = [NSArray arrayWithArray: mutableArray];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;代码显然更多，而且还有一个无用的局部变量mutableArray污染了我们的作用域，简直是个毛线！<br>所以当你想把一个列表里的元素转化为另一个列表的元素时，你就能体会到映射的强大。</p>\n<h3 id=\"3、高阶过滤\"><a href=\"#3、高阶过滤\" class=\"headerlink\" title=\"3、高阶过滤\"></a>3、高阶过滤</h3><p>&emsp;&emsp;谈到ReactiveCocoa，我们要使用的另一种关键的高阶函数就是过滤器。一个列表通过过滤能够返回一个只包含了原列表中符合条件的元素的新列表，具体我们来看实践中的例子:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray *filteredArray = [array rx_filterWithBlock:^BOOL(id each)&#123;</span><br><span class=\"line\">    return ([each integerValue] % 2 == 0);</span><br><span class=\"line\">&#125;]</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;过滤后，现在filteredArray等于@[ @2 ].如果没有这样的抽象方法(即高阶过滤)，我们不得不像下面这样来完成工作:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSMutableArray *mutableArray = [NSMutableArray arrayWithCapacity: array.count];</span><br><span class=\"line\">for ( NSNumber * number in array )&#123;</span><br><span class=\"line\">    if ( [number integerValue] % 2 == 0 )&#123;</span><br><span class=\"line\">        [mutableArray addObject:number];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">NSArray *filteredArray = [NSArray arrayWithArray:mutableArray];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;有点明白了,对不对? 你可能像上面这样子写代码写了成百上千次。我们每一天的工作中涉及到类似这种高阶映射或者高阶过滤的事情有多少? 非常多！通过使用像高阶过滤、高阶映射类似的高阶函数，我们能够把这种繁琐又乏味的任务抽象出来，轻松工作，轻松生活。。。</p>\n<h3 id=\"4、高阶折叠\"><a href=\"#4、高阶折叠\" class=\"headerlink\" title=\"4、高阶折叠\"></a>4、高阶折叠</h3><p>&emsp;&emsp;Flod 是一个有趣的高阶函数－她把列表中的所有元素变成一个值。一个简单的高阶折叠能够用来给数值数组求和。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSNumber * sum = [array rx_foldWithBlock:^ id (id memo , id each)&#123;</span><br><span class=\"line\">    return @([memo integerValue] + [each integerValue]);</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;输出的值为@6.数组中的每一个元素按顺序执行上述合并规则:[memo integerValue] + [each integerValue],其中memo参数纪录的是上一次合并后的结果，其初始值为零。这还不是很有趣，有趣的是我们还能给memo(这个参数的泛称)赋初始值:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[[array rx_mapWithBlock:^id (id each)&#123;</span><br><span class=\"line\">        return [each stringValue];</span><br><span class=\"line\">    &#125;] rx_foldInitialValue:@&quot;&quot; block:^id (id memo , id each)&#123;</span><br><span class=\"line\">        return [memo stringByAppendingString:each];</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;代码的结果:@“123”. 我们来分析一下这是怎么做到的. 首先我们对数组中的所有NSNumber对象做了映射，把他们变成了NSString对象，然后我们实现了一个高阶折叠，并给了memo变量一个空字符串。<br>       在没有RXCollections的情况下能得到这样的结果吗？当然可以。但这是一个明确的”是什么，而不是如何”的解决问题的方法。这种方法可以让我们不必跟CPU一样去想”这一步要如何，下一步要如何”类似这样的事情。写代码的时候如此，读代码的时候更是如此(意:更多地关注任务是什么，要达成什么目标)</p>\n<h3 id=\"5、性能\"><a href=\"#5、性能\" class=\"headerlink\" title=\"5、性能\"></a>5、性能</h3><p>&emsp;&emsp;这一章有关函数式编程的事例代码可能会让你开始担心性能的问题。例如，在一个长数组中，给每个元素创建一个过渡的字符描述并把他们追加到前面的结果中去，比起命令式编程来说，可能需要消耗更长的时间。<br>&emsp;&emsp;这可能是个问题，但幸运的是，现在的计算机(甚至iPhone手机)性能已经足够强大，在大多数情况下，这种性能损耗是无关紧要的，况且当这种损耗变成一个性能瓶颈的时候，你随时都可以回头去优化她让她更加高效。CPU的时间很廉价，但是你的时间是很宝贵，因此牺牲CPU的时间会是更好的选择。</p>\n<h3 id=\"6、总结\"><a href=\"#6、总结\" class=\"headerlink\" title=\"6、总结\"></a>6、总结</h3><p>&emsp;&emsp;我们使用RXCollections后不需要额外的可变变量就可以在列表上进行操作，虽然RXCollections可能隐式地生成了这样的可变变量来完成任务，但是这不是我们要关心的，因为它已经为我们抽象出了这样的方式，通过:mapping、filtering和folding这种方式让我们不必在意实现任务的步骤。(当然，这并不是说，我们不应该熟悉RXCollections的源码，只是告诉你不必按部就班地去完成任务了)<br>在最后，我们也看到了，使用链式操作一次可以输出一个更为复杂的逻辑操作的结果。下一章我们将谈论更多的有关链式操作的内容———实际上，它是ReactiveCocoa中的重要语法之一。</p>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"理念\"><a href=\"#理念\" class=\"headerlink\" title=\"理念\"></a>理念</h2><p>&emsp;&emsp;所有的程序都是为了完成某些任务。大多数程序员所受的训练都是命令式编程。这种模式依赖于他们希望自己的程序如何来完成这些任务：开发者编写很多的指令来修正程序的状态；如果开发者在正确的位置上编写了正确的指令，那么程序将会正确的完成任务。<br>","more":"<br>&emsp;&emsp;这听起来很平凡。。。<br>&emsp;&emsp;为什么编程时我们思考问题的方式停留在“怎么做”这个点上？因为计算机实际上是以一条命令来工作的，CPU的程序计算尽职尽责，按部就班：读取（指令）-&gt;执行-&gt;读取-&gt;执行。。。所以理所当然的，我们只要告诉他们“怎么做”就好了（即命令式编程）。。。多么的无聊<br>&emsp;&emsp;与此相反，声明式编程（Declarative Programming）将程序员们从纷繁复杂的对如何完成某些任务的细枝末节的流程中解放出来，将关注点集中在任务到底“是什么”而非实现任务的流程。声明式编程是命令式编程之外的几种编程范式的一个总称。<br>&emsp;&emsp;声明式编程（Declarative Programming）是一种编程范性，与命令式编程相对立。它描述目标的性质，让电脑明白目标，而非流程。而指令式编程则需要用算法来明确的指出每一步该怎么做。函数式响应式编程是声明式编程的子编程范式之一。  </p>\n<h2 id=\"函数式编程\"><a href=\"#函数式编程\" class=\"headerlink\" title=\"函数式编程\"></a>函数式编程</h2><p>&emsp;&emsp;在高效地进行函数式响应式编程之前，我们首先需要理解函数式编程。</p>\n<h3 id=\"1、高阶函数\"><a href=\"#1、高阶函数\" class=\"headerlink\" title=\"1、高阶函数\"></a>1、高阶函数</h3><p>&emsp;&emsp;函数式编程的一个关键概念是“高阶函数”。从维基百科的解释来看，一个高阶函数需要满足下面两个条件： 1、一个或者多个函数作为输入。  2、有且仅有一个函数输出。<br>&emsp;&emsp;在Objective-c中我们经常使用block作为函数。我们不需要跋山涉水地去寻找‘高阶函数’，实际上，Apple为我们提供的Foundation库中就有。考虑象下面这么简单的一个NSNumber 的数组：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray * array = @[ @(1), @(2), @(3) ];</span><br></pre></td></tr></table></figure>\n<p>我们想要枚举这个数组的内容，利用数组元素来做些事情。<br>“好吧”，你说， “我将写一个for循环～”<br>住手吧，伙计，停止写for循环,好好看看我之前说的，我们可以用一个NSArray的高阶函数来代替。代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for (NSNumber *number in array) NSLog(@&quot;%@&quot;,number);</span><br></pre></td></tr></table></figure>\n<p>这个等同于下面的高阶函数:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[array enumerateObjectsUsingBlock:^(NSNumber *number, NSUInteger idx, BOOL *stop)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    NSLog(@&quot;%@&quot;,number);</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<h3 id=\"2、高阶映射\"><a href=\"#2、高阶映射\" class=\"headerlink\" title=\"2、高阶映射\"></a>2、高阶映射</h3><p>&emsp;&emsp;我们要学习的第一个高阶函数是’映射[map]’.映射是在函数的层次上把一个列表变成相同长度的另一个列表，原始列表中的每一个值，在新的列表中都有一个对应的值。如下所示是一个平方数的映射：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map(1,2,3) =&gt; (1,4,9)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;当然，这只是一个伪代码，一个高阶函数会返回另外一个函数而不是一个列表。那么我们要如何利用RXCollections呢?<br>&emsp;&emsp;我们这么来用rx_mapWithBlock:方法：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray * mappedArray = [array rx_mapWithBlock:^id(id each)&#123;</span><br><span class=\"line\">    return @(pow([each integerValue],2));</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;这将会达成上面伪代码所完成的任务，如果我们打印出array的日志，我们将会看到如下内容:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(</span><br><span class=\"line\">    1，</span><br><span class=\"line\">    4，</span><br><span class=\"line\">    9</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;简直完美!请注意rx_mapWithBlock: 并不是一个真正的函数映射，因为他不是技术上的高阶函数(她没有返回一个函数)。后面提到的库(RAC)已经解决了这一点,在下一章我们将看到映射是如何在ReactiveCocoa的上下文中工作的。<br>&emsp;&emsp;注意rx_mapWithBlock:在没有对原数组元素进行任何修改的前提下返回了一个新的数组，这里Foundation的类真的是非常好用的一个例子，因为他们的类默认就是不可变的。<br>想象一下，往常(命令式编程)为了完成这个任务，我们不得不写下这样的代码:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSMutableArray *mutableArray = [NSMutableArray arryaWithCapacity:array.count];</span><br><span class=\"line\">for (NSNumber *number in array) [mutableArray addObject:@(pow([number integerValue], 2))];</span><br><span class=\"line\">NSArray *mappedArray = [NSArray arrayWithArray: mutableArray];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;代码显然更多，而且还有一个无用的局部变量mutableArray污染了我们的作用域，简直是个毛线！<br>所以当你想把一个列表里的元素转化为另一个列表的元素时，你就能体会到映射的强大。</p>\n<h3 id=\"3、高阶过滤\"><a href=\"#3、高阶过滤\" class=\"headerlink\" title=\"3、高阶过滤\"></a>3、高阶过滤</h3><p>&emsp;&emsp;谈到ReactiveCocoa，我们要使用的另一种关键的高阶函数就是过滤器。一个列表通过过滤能够返回一个只包含了原列表中符合条件的元素的新列表，具体我们来看实践中的例子:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSArray *filteredArray = [array rx_filterWithBlock:^BOOL(id each)&#123;</span><br><span class=\"line\">    return ([each integerValue] % 2 == 0);</span><br><span class=\"line\">&#125;]</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;过滤后，现在filteredArray等于@[ @2 ].如果没有这样的抽象方法(即高阶过滤)，我们不得不像下面这样来完成工作:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSMutableArray *mutableArray = [NSMutableArray arrayWithCapacity: array.count];</span><br><span class=\"line\">for ( NSNumber * number in array )&#123;</span><br><span class=\"line\">    if ( [number integerValue] % 2 == 0 )&#123;</span><br><span class=\"line\">        [mutableArray addObject:number];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">NSArray *filteredArray = [NSArray arrayWithArray:mutableArray];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;有点明白了,对不对? 你可能像上面这样子写代码写了成百上千次。我们每一天的工作中涉及到类似这种高阶映射或者高阶过滤的事情有多少? 非常多！通过使用像高阶过滤、高阶映射类似的高阶函数，我们能够把这种繁琐又乏味的任务抽象出来，轻松工作，轻松生活。。。</p>\n<h3 id=\"4、高阶折叠\"><a href=\"#4、高阶折叠\" class=\"headerlink\" title=\"4、高阶折叠\"></a>4、高阶折叠</h3><p>&emsp;&emsp;Flod 是一个有趣的高阶函数－她把列表中的所有元素变成一个值。一个简单的高阶折叠能够用来给数值数组求和。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">NSNumber * sum = [array rx_foldWithBlock:^ id (id memo , id each)&#123;</span><br><span class=\"line\">    return @([memo integerValue] + [each integerValue]);</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;输出的值为@6.数组中的每一个元素按顺序执行上述合并规则:[memo integerValue] + [each integerValue],其中memo参数纪录的是上一次合并后的结果，其初始值为零。这还不是很有趣，有趣的是我们还能给memo(这个参数的泛称)赋初始值:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[[array rx_mapWithBlock:^id (id each)&#123;</span><br><span class=\"line\">        return [each stringValue];</span><br><span class=\"line\">    &#125;] rx_foldInitialValue:@&quot;&quot; block:^id (id memo , id each)&#123;</span><br><span class=\"line\">        return [memo stringByAppendingString:each];</span><br><span class=\"line\">&#125;];</span><br></pre></td></tr></table></figure>\n<p>&emsp;&emsp;代码的结果:@“123”. 我们来分析一下这是怎么做到的. 首先我们对数组中的所有NSNumber对象做了映射，把他们变成了NSString对象，然后我们实现了一个高阶折叠，并给了memo变量一个空字符串。<br>       在没有RXCollections的情况下能得到这样的结果吗？当然可以。但这是一个明确的”是什么，而不是如何”的解决问题的方法。这种方法可以让我们不必跟CPU一样去想”这一步要如何，下一步要如何”类似这样的事情。写代码的时候如此，读代码的时候更是如此(意:更多地关注任务是什么，要达成什么目标)</p>\n<h3 id=\"5、性能\"><a href=\"#5、性能\" class=\"headerlink\" title=\"5、性能\"></a>5、性能</h3><p>&emsp;&emsp;这一章有关函数式编程的事例代码可能会让你开始担心性能的问题。例如，在一个长数组中，给每个元素创建一个过渡的字符描述并把他们追加到前面的结果中去，比起命令式编程来说，可能需要消耗更长的时间。<br>&emsp;&emsp;这可能是个问题，但幸运的是，现在的计算机(甚至iPhone手机)性能已经足够强大，在大多数情况下，这种性能损耗是无关紧要的，况且当这种损耗变成一个性能瓶颈的时候，你随时都可以回头去优化她让她更加高效。CPU的时间很廉价，但是你的时间是很宝贵，因此牺牲CPU的时间会是更好的选择。</p>\n<h3 id=\"6、总结\"><a href=\"#6、总结\" class=\"headerlink\" title=\"6、总结\"></a>6、总结</h3><p>&emsp;&emsp;我们使用RXCollections后不需要额外的可变变量就可以在列表上进行操作，虽然RXCollections可能隐式地生成了这样的可变变量来完成任务，但是这不是我们要关心的，因为它已经为我们抽象出了这样的方式，通过:mapping、filtering和folding这种方式让我们不必在意实现任务的步骤。(当然，这并不是说，我们不应该熟悉RXCollections的源码，只是告诉你不必按部就班地去完成任务了)<br>在最后，我们也看到了，使用链式操作一次可以输出一个更为复杂的逻辑操作的结果。下一章我们将谈论更多的有关链式操作的内容———实际上，它是ReactiveCocoa中的重要语法之一。</p>\n<p>转载请注明原地址，Clang的博客：<a href=\"https://chenhu1001.github.io\" target=\"_blank\" rel=\"noopener\">https://chenhu1001.github.io</a> 谢谢！</p>"},{"title":"iOS直播技术分享-推流和传输（四）","date":"2016-10-25T06:06:58.000Z","_content":"推流是直播的第一公里，直播的推流对这个直播链路影响非常大，如果推流的网络不稳定，无论我们如何做优化，观众的体验都会很糟糕。所以也是我们排查问题的第一步，如何系统地解决这类问题需要我们对相关理论有基础的认识。\n<!--more-->\n推送协议\n\n下面就先介绍一下都有哪些推送协议，他们在直播领域的现状和优缺点。\nRTMP\nWebRTC\n基于 UDP 的私有协议\n\n1. RTMP\n\nRTMP 是 Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于 TCP，是一个协议族，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP 是一种设计用来进行实时数据通信的网络协议，主要用来在 Flash/AIR 平台和支持 RTMP 协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括 Adobe Media Server/Ultrant Media Server/red5 等。\nRTMP 是目前主流的流媒体传输协议，广泛用于直播领域，可以说市面上绝大多数的直播产品都采用了这个协议。\n\n优点\nCDN 支持良好，主流的 CDN 厂商都支持\n协议简单，在各平台上实现容易\n\n缺点\n基于 TCP ，传输成本高，在弱网环境丢包率高的情况下问题显著\n不支持浏览器推送\nAdobe 私有协议，Adobe 已经不再更新\n\n2. WebRTC\n\nWebRTC，名称源自网页即时通信（英语：Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的 API。它于 2011 年 6 月 1 日开源并在 Google、Mozilla、Opera 支持下被纳入万维网联盟的 W3C 推荐标准。\n\n目前主要应用于视频会议和连麦中，协议分层如下：\n\n\n\n优点\nW3C 标准，主流浏览器支持程度高\nGoogle 在背后支撑，并在各平台有参考实现\n底层基于 SRTP 和 UDP，弱网情况优化空间大\n可以实现点对点通信，通信双方延时低\n\n缺点\nICE,STUN,TURN 传统 CDN 没有类似的服务提供\n\n3. 基于 UDP 的私有协议\n\n有些直播应用会使用 UDP 做为底层协议开发自己的私有协议，因为 UDP 在弱网环境下的优势通过一些定制化的调优可以达到比较好的弱网优化效果，但同样因为是私有协议也势必有现实问题：\n\n优点\n更多空间进行定制化优化\n\n缺点\n开发成本高\nCDN 不友好，需要自建 CDN 或者和 CDN 达成协议\n独立作战，无法和社区一起演进","source":"_posts/iOS直播技术分享-推流和传输（四）.md","raw":"---\ntitle: iOS直播技术分享-推流和传输（四）\ndate: 2016-10-25 14:06:58\ncategories: 音视频\ntags: [音视频]\n---\n推流是直播的第一公里，直播的推流对这个直播链路影响非常大，如果推流的网络不稳定，无论我们如何做优化，观众的体验都会很糟糕。所以也是我们排查问题的第一步，如何系统地解决这类问题需要我们对相关理论有基础的认识。\n<!--more-->\n推送协议\n\n下面就先介绍一下都有哪些推送协议，他们在直播领域的现状和优缺点。\nRTMP\nWebRTC\n基于 UDP 的私有协议\n\n1. RTMP\n\nRTMP 是 Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于 TCP，是一个协议族，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP 是一种设计用来进行实时数据通信的网络协议，主要用来在 Flash/AIR 平台和支持 RTMP 协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括 Adobe Media Server/Ultrant Media Server/red5 等。\nRTMP 是目前主流的流媒体传输协议，广泛用于直播领域，可以说市面上绝大多数的直播产品都采用了这个协议。\n\n优点\nCDN 支持良好，主流的 CDN 厂商都支持\n协议简单，在各平台上实现容易\n\n缺点\n基于 TCP ，传输成本高，在弱网环境丢包率高的情况下问题显著\n不支持浏览器推送\nAdobe 私有协议，Adobe 已经不再更新\n\n2. WebRTC\n\nWebRTC，名称源自网页即时通信（英语：Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的 API。它于 2011 年 6 月 1 日开源并在 Google、Mozilla、Opera 支持下被纳入万维网联盟的 W3C 推荐标准。\n\n目前主要应用于视频会议和连麦中，协议分层如下：\n\n\n\n优点\nW3C 标准，主流浏览器支持程度高\nGoogle 在背后支撑，并在各平台有参考实现\n底层基于 SRTP 和 UDP，弱网情况优化空间大\n可以实现点对点通信，通信双方延时低\n\n缺点\nICE,STUN,TURN 传统 CDN 没有类似的服务提供\n\n3. 基于 UDP 的私有协议\n\n有些直播应用会使用 UDP 做为底层协议开发自己的私有协议，因为 UDP 在弱网环境下的优势通过一些定制化的调优可以达到比较好的弱网优化效果，但同样因为是私有协议也势必有现实问题：\n\n优点\n更多空间进行定制化优化\n\n缺点\n开发成本高\nCDN 不友好，需要自建 CDN 或者和 CDN 达成协议\n独立作战，无法和社区一起演进","slug":"iOS直播技术分享-推流和传输（四）","published":1,"updated":"2018-05-07T12:23:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjgz3hh1x001in5xfay0wp6yt","content":"<p>推流是直播的第一公里，直播的推流对这个直播链路影响非常大，如果推流的网络不稳定，无论我们如何做优化，观众的体验都会很糟糕。所以也是我们排查问题的第一步，如何系统地解决这类问题需要我们对相关理论有基础的认识。<br><a id=\"more\"></a><br>推送协议</p>\n<p>下面就先介绍一下都有哪些推送协议，他们在直播领域的现状和优缺点。<br>RTMP<br>WebRTC<br>基于 UDP 的私有协议</p>\n<ol>\n<li>RTMP</li>\n</ol>\n<p>RTMP 是 Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于 TCP，是一个协议族，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP 是一种设计用来进行实时数据通信的网络协议，主要用来在 Flash/AIR 平台和支持 RTMP 协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括 Adobe Media Server/Ultrant Media Server/red5 等。<br>RTMP 是目前主流的流媒体传输协议，广泛用于直播领域，可以说市面上绝大多数的直播产品都采用了这个协议。</p>\n<p>优点<br>CDN 支持良好，主流的 CDN 厂商都支持<br>协议简单，在各平台上实现容易</p>\n<p>缺点<br>基于 TCP ，传输成本高，在弱网环境丢包率高的情况下问题显著<br>不支持浏览器推送<br>Adobe 私有协议，Adobe 已经不再更新</p>\n<ol start=\"2\">\n<li>WebRTC</li>\n</ol>\n<p>WebRTC，名称源自网页即时通信（英语：Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的 API。它于 2011 年 6 月 1 日开源并在 Google、Mozilla、Opera 支持下被纳入万维网联盟的 W3C 推荐标准。</p>\n<p>目前主要应用于视频会议和连麦中，协议分层如下：</p>\n<p>优点<br>W3C 标准，主流浏览器支持程度高<br>Google 在背后支撑，并在各平台有参考实现<br>底层基于 SRTP 和 UDP，弱网情况优化空间大<br>可以实现点对点通信，通信双方延时低</p>\n<p>缺点<br>ICE,STUN,TURN 传统 CDN 没有类似的服务提供</p>\n<ol start=\"3\">\n<li>基于 UDP 的私有协议</li>\n</ol>\n<p>有些直播应用会使用 UDP 做为底层协议开发自己的私有协议，因为 UDP 在弱网环境下的优势通过一些定制化的调优可以达到比较好的弱网优化效果，但同样因为是私有协议也势必有现实问题：</p>\n<p>优点<br>更多空间进行定制化优化</p>\n<p>缺点<br>开发成本高<br>CDN 不友好，需要自建 CDN 或者和 CDN 达成协议<br>独立作战，无法和社区一起演进</p>\n","site":{"data":{}},"excerpt":"<p>推流是直播的第一公里，直播的推流对这个直播链路影响非常大，如果推流的网络不稳定，无论我们如何做优化，观众的体验都会很糟糕。所以也是我们排查问题的第一步，如何系统地解决这类问题需要我们对相关理论有基础的认识。<br>","more":"<br>推送协议</p>\n<p>下面就先介绍一下都有哪些推送协议，他们在直播领域的现状和优缺点。<br>RTMP<br>WebRTC<br>基于 UDP 的私有协议</p>\n<ol>\n<li>RTMP</li>\n</ol>\n<p>RTMP 是 Real Time Messaging Protocol（实时消息传输协议）的首字母缩写。该协议基于 TCP，是一个协议族，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种。RTMP 是一种设计用来进行实时数据通信的网络协议，主要用来在 Flash/AIR 平台和支持 RTMP 协议的流媒体/交互服务器之间进行音视频和数据通信。支持该协议的软件包括 Adobe Media Server/Ultrant Media Server/red5 等。<br>RTMP 是目前主流的流媒体传输协议，广泛用于直播领域，可以说市面上绝大多数的直播产品都采用了这个协议。</p>\n<p>优点<br>CDN 支持良好，主流的 CDN 厂商都支持<br>协议简单，在各平台上实现容易</p>\n<p>缺点<br>基于 TCP ，传输成本高，在弱网环境丢包率高的情况下问题显著<br>不支持浏览器推送<br>Adobe 私有协议，Adobe 已经不再更新</p>\n<ol start=\"2\">\n<li>WebRTC</li>\n</ol>\n<p>WebRTC，名称源自网页即时通信（英语：Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的 API。它于 2011 年 6 月 1 日开源并在 Google、Mozilla、Opera 支持下被纳入万维网联盟的 W3C 推荐标准。</p>\n<p>目前主要应用于视频会议和连麦中，协议分层如下：</p>\n<p>优点<br>W3C 标准，主流浏览器支持程度高<br>Google 在背后支撑，并在各平台有参考实现<br>底层基于 SRTP 和 UDP，弱网情况优化空间大<br>可以实现点对点通信，通信双方延时低</p>\n<p>缺点<br>ICE,STUN,TURN 传统 CDN 没有类似的服务提供</p>\n<ol start=\"3\">\n<li>基于 UDP 的私有协议</li>\n</ol>\n<p>有些直播应用会使用 UDP 做为底层协议开发自己的私有协议，因为 UDP 在弱网环境下的优势通过一些定制化的调优可以达到比较好的弱网优化效果，但同样因为是私有协议也势必有现实问题：</p>\n<p>优点<br>更多空间进行定制化优化</p>\n<p>缺点<br>开发成本高<br>CDN 不友好，需要自建 CDN 或者和 CDN 达成协议<br>独立作战，无法和社区一起演进</p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjgz3hh100005n5xf5jc80wsx","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh18000dn5xfvz51wyuc"},{"post_id":"cjgz3hh0p0000n5xf15wfhhh1","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh1a000in5xfawsejz9g"},{"post_id":"cjgz3hh120006n5xficy6axkc","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh1d000ln5xfsc6uqpmw"},{"post_id":"cjgz3hh0u0001n5xf07hcftlg","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh1e000qn5xfpftrbf9h"},{"post_id":"cjgz3hh17000cn5xfxqlrmiyn","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh1g000tn5xfqeppv1f4"},{"post_id":"cjgz3hh0z0004n5xfq0g4sa6o","category_id":"cjgz3hh18000en5xf4x0q9i7y","_id":"cjgz3hh1j000yn5xf7im64cwt"},{"post_id":"cjgz3hh1d000pn5xf1afkawzx","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1k0011n5xf7q6nzags"},{"post_id":"cjgz3hh16000an5xfc2v4w1a7","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1m0016n5xfsloqg41i"},{"post_id":"cjgz3hh1f000sn5xfa1o746xi","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1m0018n5xf5jc4z00r"},{"post_id":"cjgz3hh1h000xn5xf73mq0nto","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1n001an5xfp57aghup"},{"post_id":"cjgz3hh19000hn5xfpzhm8ftw","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1n001cn5xf7ymj10jd"},{"post_id":"cjgz3hh1j0010n5xfhys9terp","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh1o001en5xftr7ct7tu"},{"post_id":"cjgz3hh1l0015n5xf5da57m7m","category_id":"cjgz3hh0x0002n5xfyvsmjkgu","_id":"cjgz3hh1o001gn5xf4fuvrc6r"},{"post_id":"cjgz3hh1b000kn5xfji36856b","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1o001hn5xflbjphbf3"},{"post_id":"cjgz3hh1x001in5xfay0wp6yt","category_id":"cjgz3hh1d000mn5xf7o2ic4u8","_id":"cjgz3hh1y001kn5xf7eaynwxl"}],"PostTag":[{"post_id":"cjgz3hh100005n5xf5jc80wsx","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh150009n5xf57e3ryez"},{"post_id":"cjgz3hh0p0000n5xf15wfhhh1","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh17000bn5xf54mq2qma"},{"post_id":"cjgz3hh120006n5xficy6axkc","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh19000gn5xfyly4ddc5"},{"post_id":"cjgz3hh0u0001n5xf07hcftlg","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh1b000jn5xftu5c297x"},{"post_id":"cjgz3hh17000cn5xfxqlrmiyn","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh1d000on5xfogmjs6cq"},{"post_id":"cjgz3hh0z0004n5xfq0g4sa6o","tag_id":"cjgz3hh18000fn5xf5nmracwp","_id":"cjgz3hh1e000rn5xftp1efly6"},{"post_id":"cjgz3hh1d000pn5xf1afkawzx","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1h000wn5xf1axgvfwu"},{"post_id":"cjgz3hh16000an5xfc2v4w1a7","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1j000zn5xfr3gq3r1r"},{"post_id":"cjgz3hh1f000sn5xfa1o746xi","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1l0014n5xfi81w0iex"},{"post_id":"cjgz3hh1h000xn5xf73mq0nto","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1m0017n5xfn866vtzy"},{"post_id":"cjgz3hh19000hn5xfpzhm8ftw","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1n0019n5xfvvclhott"},{"post_id":"cjgz3hh1j0010n5xfhys9terp","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh1n001bn5xfhbfaysnc"},{"post_id":"cjgz3hh1l0015n5xf5da57m7m","tag_id":"cjgz3hh0z0003n5xf8u1hpaqp","_id":"cjgz3hh1n001dn5xfchuujmdj"},{"post_id":"cjgz3hh1b000kn5xfji36856b","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1o001fn5xf7aj50jas"},{"post_id":"cjgz3hh1x001in5xfay0wp6yt","tag_id":"cjgz3hh1d000nn5xf9axdhi4j","_id":"cjgz3hh1y001jn5xfkyepz1c7"}],"Tag":[{"name":"iOS","_id":"cjgz3hh0z0003n5xf8u1hpaqp"},{"name":"随笔","_id":"cjgz3hh18000fn5xf5nmracwp"},{"name":"音视频","_id":"cjgz3hh1d000nn5xf9axdhi4j"}]}}